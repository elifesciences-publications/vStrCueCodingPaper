\documentclass[11pt]{article}

% packages
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{times}
\usepackage{ifthen}
\usepackage{parskip}
\usepackage[font=sf,labelfont=bf]{caption}
\usepackage{xspace}
\usepackage{times}
\usepackage[pdftex]{color}
\usepackage{pdfcolmk}
\usepackage{fixltx2e} % for \textsubscript
\usepackage{url}


% show figures?
\newboolean{showfig}
\setboolean{showfig}{true}

\ifthenelse{\boolean{showfig}}{}{\usepackage{endfloat}}

% line numbers
\usepackage[left]{lineno}
\usepackage{blindtext}

% variable margins
\usepackage[left=2.5cm,top=2.5cm,bottom=3.5cm,right=2.5cm]{geometry}

% this helps figure placement
\renewcommand{\textfraction}{0.0}
\renewcommand{\topfraction}{1}
\renewcommand{\bottomfraction}{1}

%\usepackage{endfloat}
%\renewcommand{\figuresection}{Figure Legends}

% spacing
\setlength{\parindent}{0in} 
\setlength{\parskip}{2\baselineskip}
\linespread{2}
\renewcommand{\baselinestretch}{1.66}\normalsize

% definitions
\newcommand{\bsf}[1]{\textbf{#1}}
\newcommand{\sem}{S.E.M.\@\xspace}
\newcommand{\degree}{$^o$\@\xspace}

% bib
\bibliographystyle{apa}
\let\cite=\citep
\let\citeN=\citet
\let\citeNP=\citealt
\renewcommand{\bibfont}{\footnotesize}
\setlength{\bibsep}{2pt}

\begin{document}

%\renewcommand{\@makecaption}[2]{{\centering   \vskip\abovecaptionskip \bfseries #1} #2}

%{\Large\bf Towards the principled decoding of internally generated neural activity}
{\Large\bf Optimizing for generalization in the decoding of internally
  generated activity in the hippocampus}

{\bf Authors}: Matthijs A.\ A.\ van der Meer\textsuperscript{1*},
Alyssa A.\ Carey\textsuperscript{1}, Youki Tanaka\textsuperscript{1}

\textsuperscript{1}Department of Psychological and Brain Sciences,
Dartmouth College, USA\\

\textsuperscript{*}Correspondence should be addressed to MvdM. Current
address: Department of Psychological and Brain Sciences, Dartmouth
College, Hanover, NH 03755. E-mail: {\sffamily mvdm -at- dartmouth -dot- edu}.

{\bf Running head}: Decoding hippocampal sequences

{\bf Keywords}: encoding, replay, hippocampal sequences,
cross-validation, Bayesian

Number of pages: 31\\
Number of Figures: 9\\
Number of Tables: 1\\

\linenumbers

\newpage

\section*{Abstract}

The decoding of a sensory or motor variable from neural activity
benefits from a known ground truth against which decoding performance
can be compared. In contrast, the decoding of covert, cognitive neural
activity, such as occurs in memory recall or planning, typically
cannot be compared to a known ground truth. As a result, it is unclear
how decoders of such internally generated activity should be
configured in practice. We suggest that if the true code for covert
activity is unknown, decoders should be optimized for generalization
performance using cross-validation. Using ensemble recording data from
hippocampal place cells, we show that this cross-validation approach
results in different decoding error, different optimal decoding
parameters, and different distributions of error across the decoded
variable space. In addition, we show that a minor modification to the
commonly used Bayesian decoding procedure, which enables the use of
spike density functions, results in substantially lower decoding
errors. These results have implications for the interpretation of
covert neural activity, and suggest easy-to-implement changes to
commonly used procedures across domains, with applications to
hippocampal place cells in particular.

\newpage

\section*{Introduction}

The decoding of neural activity is a powerful and ubiquitous approach
to understanding information processing in the brain. Decoding is
typically cast as a mapping from neural data to a sensory or motor
variable, such as the identity of a visually presented object or the
reaching direction of a motor action; the same idea can be applied to
more abstract or even hidden states such as context or past history.
By comparing a decoded (``reconstructed'') variable with the actual
value, the contributions of features such as spike timing, adaptation,
and correlations to decoding accuracy can be quantified
\cite{Nirenberg2003,Panzeri2015,Schneidman2016}. Based on the nature
and accuracy of the decoder output under various conditions,
inferences may be drawn about the possible functions of neural
populations carrying such signals and the circuitry responsible for
generating them \cite{georgpop,Bialek1991,Pillow2008}. These decoding
approaches share the property that when a known stimulus value is
available along with neural data, decoding performance can be
optimized relative to a known ``ground truth'' (i.e.\ the actual
stimulus value).

Increasingly so, however, decoding is also applied to brain activity
occurring in the {\it absence of any overt stimulus or action}
\cite{Georgopoulos1989,Johnson2009b,King2014}. Such internally
generated activity occurs, for instance, during processes such as
planning, deliberation, visual imagery and perspective-taking, memory
recall and sleep. A well-studied example is provided by studies of
hippocampal activity recorded in rodents, which exhibits internally
generated sequences of neural activity that appear to depict
behavioral trajectories during sleep and wakeful rest (``replay'';
\citeNP{Skaggs1996a,Nadasdy1999,Davidson2009,Pfeiffer2013}),
       {\color{black} and during the theta rhythm while task-engaged
         (``theta sequences'',
         \citeNP{Foster2007,Gupta2012,Chadwick2015})}. Replay is thought
       to reflect an off-line consolidation process from a
       fast-learning, episodic-like short-term memory trace in the
       hippocampus into a semantic-like neocortical knowledge
       structure
       \cite{McClelland1995,Kali2004a,Girardeau2009,Carr2011}, but
       also plays a role in on-line task performance, and can depict
       trajectories that are not well explained by consolidation
       processes, such as those towards a behaviorally relevant goal
       and never-experienced paths
       \cite{O'Neill2006,Jadhav2012,Dragoi2013b,Olafsdottir2015}. {\color{black}
         Theta sequences may enable one-shot learning, and/or play a
         role in on-line prediction during behavior
         \cite{Lisman2009,Malhotra2012,Feng2015}.}

How should we interpret the {\it content} of such internally generated
activity? The intuition that replay has a clear resemblance to
activity observed during active behavior can be formalized by simply
applying the same decoder used to decode activity during overt
behavior \cite{Tatsuno2006,Kloosterman2012,Shirer2012}. However, in
the rodent hippocampus there are also obvious differences between the
two types of activity, such as the compressed timescale and different
instantaneous population firing rates
\cite{Skaggs1996a,Lee2002,Buzsaki2015a}. More generally, there is now
overwhelming evidence that hippocampal ``place cells'' are better
viewed as encoding many possible stimulus dimensions rather than just
place; these may include relatively low-level properties such as
running speed, information about objects and events, and complex
history- and context-dependence
\cite{Huxter2003,Lin2005,McKenzie2014,Allen2016}. Thus, it is unlikely
that the mapping between neural activity and encoded location (the
``encoding model'') remains the same between overt and covert epochs,
raising the possibility of biases in our ability to decode specific
stimulus values, such as different positions along a track.

To address the above issues, we provide several practical improvements
to commonly used decoding procedures, of particular use for
applications to internally generated activity. In acknowledgment of
the likely different encoding model in force during overt and covert
neural activity, we {\color{black} emphasize} that decoding performance
should be optimized for generalization performance (i.e.\ to do well
on withheld data not used to estimate the parameters of the
decoder). We compare different splits of the data, and show that these
not only result in different overall decoding accuracy, but also in
different accuracy distributions {\color{black} over the stimulus
  space. In particular, these nonuniformities (biases) in accuracy
  only become apparent when optimizing for generalization to data not
  included in the training set. Because decoding internally generated
  activity also involves such generalization, the interpretation of
  decoding such activity should be informed by the known shape of this
  bias.}  Finally, we show that regardless of the type of split used,
decoding accuracy can be improved by relaxing the assumption of
integer spike counts used in the common Bayesian decoding procedure
{\color{black} \cite{Zhang1998,johnson07jnsci,Pfeiffer2013}}.

\section*{Materials and Methods}

\subsection*{Overview}

Our aim is to describe how the output of decoding hippocampal ensemble
activity depends on the configuration of the decoder. In particular,
we examine two components: (1) the split between training and testing
data, and (2) the parameters associated with the estimation of firing
rates and tuning curves (the encoding model). Both are described in
the {\it Analysis} section. All analyses are performed on multiple
single unit data recorded from rats performing a T-maze task,
described in the {\it Behavior} section. Data acquisition, annotation,
and pre-processing steps are described in the {\it Neural data}
section.

All preprocessing and analysis code is publicly available on our
GitHub repository, \url{https://github.com/vandermeerlab/papers}. Data
files are available from our lab server on request by e-mail to the
corresponding author.

\subsection*{Neural data}

{\bf Subjects and overall timeline.} Four male Long-Evans rats
(Charles River and Harlan Laboratories), weighing 439-501 g at the
start of the experiment, were first introduced to the behavioral
apparatus (described below; 3-11 days) before being implanted with an
electrode array targeting the CA1 area of the dorsal hippocampus
(details below). Following recovery (4-9 days) rats were reintroduced
to the maze until they ran proficiently (0-3 days), at which point
daily recording sessions began. On alternate days, rats were water- or
food-restricted. In parallel with the maze task, some rats (R042,
R044, R050) were trained on a simple Pavlovian conditioning task in a
separate room (data not analyzed).

{\bf Behavioral task.} The apparatus was an elevated T-maze,
constructed from wood, painted matte black with white stripes applied
to the left arm (Figure \ref{fig:behavior}) and placed on a metal
frame {\color{black} approximately} 35 cm in height. The distance from
the start of the central stem to the ends of the arms was 272 cm
(R042) or 334 cm (R044, R050, R064; these numbers are subject
IDs). 6\% sucrose ($\sim$0.1 ml) was dispensed upon reaching the end
of the left arm, and food (5 pellets of Test Diet 5TUL 45 mg pellets)
was dispensed upon reaching the end of the right arm.

Daily recording sessions consisted of (1) a pre-behavior recording
epoch, taken as the animal rested on a recording pedestal (terracotta
pot lined with towels; 20-30 min), (2) approximately 20 trials on the
maze, with an intertrial interval (30-240 s) on the recording pedestal
after each trial, and (3) a post-behavior recording epoch (10-20
min). A trial was defined as a run from the starting point at the base
of the central stem to one of the reward locations; photobeams at the
track ends were used to find pairs of crossings defining the shortest
interval between leaving the base and arriving at an end. Only data
from runs on the track {\color{black} were} analyzed here.

Because rats were food- or water-restricted, they tended to prefer
choosing the arm leading to the {\color{black} reward} to which their access was
limited. On some sessions, access to a preferred arm was blocked with
a movable barrier to ensure sampling of the non-preferred arm (forced
choice). Trials on which the animal turned around, or exhibited other
disruptive behaviors (climbing on the barrier, extended grooming,
etc.) were excluded from analysis.

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=.9\textwidth]{./figures/behavior.jpg}}{}
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=.9\textwidth]{./figures/behaviorG.jpg}}{}
  \caption{Behavioral apparatus. In daily recording sessions, rats ran
    approximately 20 trials on an elevated T-maze. Trials were
    free-choice except for a small number of forced trials in which
    access to one of the arms was prevented by a barrier to ensure
    that at least 5 trials for both left and right arms were available
    for each session. Track dimensions were: width 10 cm (A), total
    maze height 167 cm (H), total maze width 185 cm (W), total path
    length 334 cm (white trajectory, R042 excepted, who had a shorter B
    segment for a total path length of 285 cm).}
  \label{fig:behavior}
\end{figure}

{\bf Electrode arrays and surgery.} Subjects were each implanted with
a single-bundle microelectrode array targeting the CA1 region of
dorsal hippocampus in the right hemisphere (AP -4.0mm, ML
+2.5mm). R042 and R044 were each implanted with a 15-tetrode
1-reference array, and R050 and R064 were each implanted with a
16-tetrode 4-reference array. Surgical procedures were as described
previously \cite{Malhotra2015}. Briefly, the skull was exposed and a
ground screw was placed through the contralateral parietal
bone. Arrays were lowered to the surface of the cortex through a
craniotomy, and the remaining exposed opening was sealed with a
silicone polymer (KwikSil). Then, the arrays were anchored to the
skull using small screws and acrylic cement. Rats were given a minimum
recovery period of four days, during which antibiotics and analgesics
were administered, before retraining began. Tetrodes were slowly
advanced to the CA1 layer over a period of 4-9 days. The first
recording sessions began no sooner than nine days after surgery. All
procedures were performed in accordance with the Canadian Council for
Animal Care (CCAC) guidelines, and pre-approved by the University of
Waterloo Animal Care Committee (protocol 10-06).

{\bf Recording methods.} Neural activity from all tetrodes and
references was recorded on a Neuralynx Digital Lynx SX data
acquisition system using HS-36-LED analog buffering headstages
tethered to a motorized commutator. Local field potentials, filtered
between 1-425 Hz, were continuously sampled at 2 kHz. Spike waveforms,
filtered between 600-6000 Hz, were sampled at 32 kHz for 1 ms when the
voltage exceeded an experimenter-set threshold (typically 40-50$\mu$V)
and stored for offline sorting. Acquired signals for all rats (except
R042, whose data was recorded relative to animal ground) were
referenced to an electrode located in the corpus callosum, dorsal to
the target recording site. A video tracking algorithm recorded the
rat's position based on headstage LEDs picked up by an overhead
camera, sampling at 30 Hz. All position data was linearized by mapping
each 2-dimensional position sample onto the nearest point of an ideal
linearized trajectory on the track, drawn for each session by the
experimenter. Position samples further than 25cm from this idealized
trajectory were treated as missing values.

{\bf Preprocessing and annotation.} Signals were preprocessed to
exclude intervals with chewing artifacts and high-amplitude noise
transients where necessary. All spiking data was initially clustered
into putative units automatically (KlustaKwik, K.\ D.\ Harris) and
then manually checked and sorted (MClust 3.5, A.\ D.\ Redish). Highly
unstable units and units that fired fewer than 100 spikes in a
recording session were excluded. Recording locations were
histologically confirmed to lie in the dorsal CA1 cell layer. A total
of 2017 units were recorded from 4 rats across 24 sessions (Table
\ref{tab:nUnits}); 889 of these were units were rated as questionable
isolation quality by the experimenter and kept separate for later
analysis.

\begin{table}[h]
\centering
\small
  \begin{tabular}{ l c c c c c c c c}
    \hline
    \textbf{Rat ID} & \textbf{Session 1}    &   \textbf{Session 2}    & \textbf{Session 3} & \textbf{Session 4}  & \textbf{Session 5}  & \textbf{Session 6} & \textbf{Total} \\
    \hline
    \textbf{R042}    &     \it{22 (13)}   &   74 (39)  &  107 (40)  &   64 (43)  &   73 (40)  &   59 (31)  &\textbf{399 (206)}\\ 
    \textbf{R044}    &     \it{17 (11)}   &  \it{13 (9)}  &  \it{43 (21)}  &   53 (26)  &   50 (27)  &   \it{41 (22)}  &\textbf{217 (116)}\\ 
    \textbf{R050}    &     72 (42)   &   94 (40)  &  72 (28)  &   113 (44)  &   128 (36)  &   112 (46)  &\textbf{591 (236)}\\ 
    \textbf{R064}    &     121 (59)   &   136 (47)  &  116 (52)  &   162 (45)  &   178 (68)  &   151 (60)  &\textbf{864 (331)}\\ 
    \hline
    & & & & & & & &\\ % spacing hack
  \end{tabular}
  \caption{Total neural units for each rat across each of their six
   recording sessions. Numbers in parentheses indicate how many of the
   numbers listed were units rated as questionable. Sessions listed in
   italics were excluded due to insufficient number of recorded units.}
\label{tab:nUnits}
\end{table}

{\bf Inclusion criteria.} Recording sessions with at least 20 units
firing a minimum of 25 spikes during ``run'' epochs (used for tuning
curve estimation, described below) for both left and right trials
separately were included for analysis. This left out five sessions
(four from R044, one from R042) resulting in a total of 19 sessions
eligible for analysis.

\subsection*{Analysis}

{\bf Overview}. Our main approach is to employ a standard memoryless
Bayesian decoder, common to all analyses and described below. We will
vary first, the nature of different splits in the data between
``training'' and ``testing'', and second, parameters associated with
the estimation of input firing rates (spike density functions) and
input tuning curves (the ``encoding model''). In all these cases, the
output of the decoding procedure is, for each time bin, a probability
distribution over (linearized) position, given the observed spiking
activity.

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=.95\textwidth]{./figures/decoding_schema.png}}{
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=.95\textwidth]{./figures/decoding_schemaG.png}}{}
  \caption{Schematic of the Bayesian decoding scheme. The overall
    workflow follows the canonical procedure based on the common
    assumptions of Poisson-distributed spike counts around mean firing
    rates given by stable tuning curves, and independence between
    neurons. Crucial variables in the results reported here are (1)
    the split in the data between trials used for estimating tuning
    curves (``encoding spikes'') and trials used for decoding
    (``decoding spikes''; see Figure \ref{fig:decschemes} for a
    detailed explanation), (2) the width of the Gaussian kernel
    $\sigma_{TC}$ used to smooth the tuning curves (the empirically
    determined mapping from location to firing rate for each recorded
    neuron), and (3) the width of the Gaussian kernel $\sigma_{Q}$
    used to obtain the spike density functions used as the input to
    the decoder.}
  \label{fig:decoding_schema}
\end{figure}

{\bf Bayesian decoding}. We use the canonical Bayesian decoder
\cite{Brown1998,Zhang1998}, specifically the one-step, ``memoryless''
version with a uniform spatial prior. This procedure (reviewed in
detail elsewhere;
\citeNP{Johnson2009b,VanderMeer2010c,Kloosterman2014}), along with the
key parameters varied in this study, is illustrated in Figure
\ref{fig:decoding_schema}. The decoded location $\hat{x}$ for a given
time bin we took to be the mode of the posterior (location with the
highest probability; maximum a posteriori). A decoding error can then
be defined as the distance to the true position $E_{bins}(t) =
|x(t)-\hat{x}(t)|$. Because $x$ has the unit of bins, this quantity is
converted into a worst-case error in centimeters as follows:
$E_{cm}(t) = E_{bins}*b + \frac{b}{2}$, where $b$ is the bin size in
cm (we used 3 cm for the results reported here, and a time bin $\tau$
= 25 ms). {\color{black} Both the estimation of tuning curves (the
  encoding model, described below) and the decoding of spike data were
  restricted to data when the animal was running ($\ge$ 5 cm/s).}

We use this decoding procedure here because it has become the {\it de
  facto} standard in the hippocampal place cell literature
\cite{Kloosterman2014,Silva2015,Grosmark2016}; however, the
manipulations in the present study (discussed below) are general and
can be straightforwardly applied to other decoding methods such as
optimal linear decoding, regression-based methods and general-purpose
classifiers such as support vector machines, et cetera
\cite{Pereira2009,Pillow2011,Deng2015}.

{\bf Cross-validation}. The data used for the estimation of the
encoding model (tuning curves; ``training data'') may be the same as
the data used for decoding and error estimation (``testing data''),
but this need not be the case (Figure \ref{fig:decschemes}). We
systematically compare different splits between training and testing
data, focusing on three specific cases: same-trial decoding (decode
each individual trial based on tuning curves obtained from that same
trial; Figure \ref{fig:decschemes}A), next-trial decoding (decode each
individual trial based on tuning curves from the {\it next} trial;
Figure \ref{fig:decschemes}C) and leave-one-out decoding (decode each
trial based on tuning curves from all trials except the one being
decoded; Figure \ref{fig:decschemes}D). Decoding errors reported are
always for a specific split and this will be reported in the text;
note that for all splits used here, each trial is decoded separately,
using tuning curves obtained from a set of encoding trials specific to
the trial being decoded (this is unlike all-to-all decoding, Figure
\ref{fig:decschemes}B, in which the same set of all encoding trials is
used for every decoding trial). Left and right trials were always
treated separately, i.e.\ only left trials are used to decode left
trials, and the same for right trials.

\begin{figure}[h]
  \centering
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=.5\textwidth]{./figures/decSchemes.png}}{}
  \caption{Schematic of different splits between data used for
    estimating the encoding model (tuning curves, ``training data'')
    and data used for evaluating decoding accuracy (``testing
    data''). Data splits in the \bsf{top row} are ``tautological'' in
    that tuning curves are estimated on the same data used for
    decoding. In contrast, data splits on the \bsf{bottom row} measure
    generalization performance (cross-validation) in the sense that
    the decoding data was not included in the data used for estimating
    the encoding model. \bsf{Black} cells in the matrices shown
    indicate trials used to estimate the encoding model. Thus, for
    instance, the left column in {\bsf C} shows that to decode trial
    1, tuning curves were estimated from trial 2.}
  \label{fig:decschemes}
\end{figure}

{\bf Firing rate estimation}. Strictly speaking, Bayesian decoding
based on the assumption that firing rates are Poisson-distributed
requires integer spike counts for the estimation of $P(s|x)$ (Figure
\ref{fig:decoding_schema}). However, this means that there will be
effects of binning, which will become more prominent as the time
window (bin) size $\tau$ becomes smaller. For instance, if bins only
contain 0 or 1 spike, then which side of a bin edge a spike falls on
can potentially have a large effect. This issue is prominent in many
aspects of spike train analysis, and is typically addressed by
convolving the raw spike train to obtain a {\it spike density function
  (SDF)}, an estimate of firing rate which varies continuously in time
\cite{Cunningham2009a,kass2014analysis}.

To make the standard Bayesian decoding equations compatible with
non-integer spike density functions, we note that the denominator
$n_i!$ does not depend on $x$ and can therefore be absorbed into a
normalization constant $C$ which guarantees that $\sum_{x} P(n_i|x) =
1$ (Eq.\ 36 in \citeNP{Zhang1998}). For the results presented here, we
obtain spike density functions by convolving raw spike trains with a
Gaussian kernel with SD $\sigma_Q$, discretized at a resolution of 25
ms (the $\tau$ in Figure \ref{fig:decoding_schema}).

A possible side effect of using this procedure on the decoding spikes
only (i.e.\ not on the spikes used to estimate the tuning curves,
described below) is that firing rate-stimulus combinations that are
inconsistent across the ensemble become more likely, e.g.\ for every
individual location $x_i$ in space, there is at least one neuron that
assigns $P(x_i|n) = 0$ (such cases result in the white areas in Figure
\ref{fig:decAcc}; only sessions in which at least 80\% of samples
could be decoded were included, except when indicated explicitly in
the text). This can be avoided by simply convolving all spikes with
the same kernel $\sigma_Q$; here we did not do so in order to show the
effects of convolving the decoding spikes independently of the
encoding model estimation. Smoothing the tuning curves, as described
in the next section, is another effective method of avoiding this
issue.

{\bf Encoding model estimation}. Bayesian decoding requires an
estimate of $P(s|x)$, the probability of observing a firing rate
vector $s$ for a given stimulus value $x$. As in previous work, we
assume firing rates are independent between neurons and
Poisson-distributed around some mean rate $\lambda$; this
simplification means that we only need to know the mean firing rate as
a function of the stimulus variable, $\lambda(x)$, for each
neuron. These are the {\it tuning curves}, which taken together across
all neurons can be thought of as an {\it encoding model}, i.e.\ the
mapping from stimulus values to neural activity. We estimate tuning
curves non-parametrically from the data by (1) restricting the data to
intervals when the animal was running on the track ($\ge$ 5 cm/s; {\it
  encoding spikes} in Figure \ref{fig:decoding_schema}), (2)
linearizing the position data and binning in bins of 3 cm, (3)
obtaining a firing rate histogram by dividing spike count by occupancy
for all bins, and (4) optionally smoothing the resulting tuning curve
with a Gaussian kernel of standard deviation $\sigma_{TC}$ (with units
in cm).

{\color{black}{\bf Inventory of behavioral and neural measures used.}
  Figure \ref{fig:behavTuning} shows the distribution, across
  locations, of a number of behavioral and neural measures which we
  relate to decoding accuracy. We explain how these are computed in
  turn.

\begin{itemize}
\item{{\it Occupancy} (in seconds; time spent at each location on the
  track) is computed simply by binning video tracking samples and
  multiplying the sample counts by the length of each video frame
  (1/30 s).}
\item{{\it Place fields} are detected based on session tuning curves,
  when a contiguous area of at least 15cm is associated with a minimum
  firing rate of 5 Hz, and a mean firing rate of no more than 10
  Hz. For each field (contiguous area) the location of the field is
  taken to be the neuron's maximum firing rate in in the field.}
\item{{\it Tuning curve variability across trials} (Figure
  \ref{fig:behavTuning}E-F) is obtained by taking the standard
  deviation, across trials within each session, of single-trial tuning
  curves.}
\item{{\it Bootstrapped tuning curve variability} (Figure
  \ref{fig:behavTuning}G-H) is computed by generating a distribution
  of 1000 resampled tuning curves, with each sample using a random
  90\% of the position and spiking data. Specifically, every spike is
  assigned to the position sample closest in time. Then, after
  selecting a random 90\% of position samples, those samples and the
  associated spikes are removed before computing a tuning curve. A
  measure of tuning curve variability is then obtained by taking the
  standard deviation across the distribution of resampled tuning
  curves.}
\item{{\it Population vector (PV) correlations} are obtained by
  correlating, for each location on the track, the tuning curve firing
  rates (across cells) either between tuning curves obtained from each
  pair of trials (Figure \ref{fig:behavTuning}I-J) or between tuning
  curves from a single trial and the complementary tuning curve of all
  trials except that one (Figure \ref{fig:behavTuning}K-L).}
\end{itemize}
}

\section*{Results}

We sought to determine how different configurations of the commonly
used one-step Bayesian decoder \cite{Brown1998,Zhang1998} relate to
the decoding accuracy of position based on ensembles of hippocampal
place cells. In particular, we applied different splits to the data,
partitioning it into ``training'' data from which tuning curves were
estimated, and ``testing'' data from which decoding accuracy was
determined (a type of cross-validation). In addition, we varied
parameters associated with the estimation of tuning curves and firing
rates ($\sigma_{TC}$ and $\sigma_Q$ in Figure
\ref{fig:decoding_schema}).

Our motivation for exploring different data splits is the question of
how internally generated sequences (e.g.\ ``replays'') of neural
activity can be decoded in a principled manner. For such sequences,
the true mapping from neural activity to stimulus space is generally
unknown; after all, there is no true stimulus value to which decoded
output can be compared. Under these conditions, decoders should be
optimized for generalization performance, i.e.\ performance on
``testing'' data not used to ``train'' the decoder. In statistics and
machine learning, such cross-validation is routinely used to prevent
overfitting \cite{Hawkins2004,alpaydin2014introduction}. Applied to
the problem of decoding covert sequences, this concept suggests that
we choose the decoder which performs best on input data from trials
not included in the estimation of tuning curves. Thus, we use data
from withheld trials as a proxy for internally generated sequences,
such that we can estimate how well various decoders are likely to
perform on actual covert sequences.

Specifically, applied to decoding neural data collected across a
number of repeated trials, as is the case here in rats running a
T-maze task (Figure \ref{fig:behavior}), a number of different splits
between testing and training data are possible, illustrated in Figure
\ref{fig:decschemes}. A commonly used approach in the hippocampal
place cell literature is to not perform any split at all, i.e.\ to
estimate tuning curves based on the full data set, and use those to
decode the full data set (Figure \ref{fig:decschemes}B,
\citeNP{johnson07jnsci,Karlsson2009,Pfeiffer2013,Zheng2016}). We refer
to this approach as ``tautological'' because the same data is used for
both. It is possible to do this at different levels of granularity,
for instance going down to the single trial level by decoding each
individual trial based on tuning curves from that trial (Figure
\ref{fig:decschemes}A), while maintaining the property that the same
data is used for tuning curve estimation and decoding.

\subsection*{Overall effects of different decoding configurations on accuracy}

We found that the best outright decoding performance (as quantified by
the error relative to true location) was obtained using such
tautological decoding. ``Same-trial'' decoding performed best of all
data splits tested (Figure \ref{fig:decAcc}A; average decoding error
5.42 $\pm$ 1.02 cm for the best-performing parameters; standard error
across subjects). However, if the goal is to optimize decoding
performance on trials not included in the training set, the picture
changes. Decoding using the {\it next trial} resulted in a decoding
error $\sim$4-fold worse than the same-trial decoding (19.19 $\pm$
2.85 cm; Figure \ref{fig:decAcc}B). Leave-one-out decoding was
intermediate between these two (11.25 $\pm$ 1.58 cm; Figure
\ref{fig:decAcc}C), a pattern that held across a wide range of
decoding parameters (see also Figure \ref{fig:decAcc2} for specific
comparisons).

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=\textwidth]{./figures/decQuantify_multi1.png}}{}
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=\textwidth]{./figures/decQuantify_multi1G.png}}{}
    \caption{Decoding accuracy for different data splits (\bsf{left}:
      same trial, \bsf{middle}: next trial, \bsf{right}:
      leave-one-out) and decoder parameters (vertical axis: standard
      deviation of Gaussian kernel (in s) used to convolve spike
      trains, horizontal axis: standard deviation of Gaussian kernel
      used to convolve tuning curves (in 3 cm bins). Grayscale shows
      the mean decoding error (in cm) for different parameter and data
      split combinations. Note that decoding accuracy for some
      parameter combinations cannot be estimated if temporal smoothing
      results in decoding spike counts inconsistent with the encoding
      model (empty data points; see {\it Methods} for
      details). Results shown were obtained with a decoding time bin
      size ($\tau$) of 25 ms; only sessions with at least 20 cells for
      both left and right trials on the T-maze were included,
      averaging across left and right trials (19 sessions total). The
      white \protect{{\color{black} asterisk}} indicates the parameter
      combination resulting in the lowest mean decoding error; this is
      the value reported here for each data split, along with the
      standard error over subjects (n = 4).}
  \label{fig:decAcc}
\end{figure}

Several other features of Figure \ref{fig:decAcc}A-C are worth
noting. First, performing no smoothing at all on either the spike
trains or the tuning curves (0/0, the data point on the top left of
each panel) results in large decoding error. Previous results
manipulating the width of the time window indicated minimum error for
a time window in the $\sim$0.5-1s range \cite{Zhang1998} this is
confirmed here by the error minimum at 0.2 or 0.5 s SD smoothing
kernels. Surprisingly however, even very minimal temporal smoothing of
the spike trains to be decoded (e.g.\ a kernel with 5 ms SD) can
result in substantial improvements in decoding performance compared to
no temporal smoothing (up to 2-fold; see Figure \ref{fig:decAcc2} for
a close-up of this effect). Second, best decoding accuracy almost
invariably required some smoothing of the tuning curves, even when the
leave-one-out procedure ensured many trials were used for tuning curve
estimation. Third, the parameters yielding optimal decoding accuracy
differed between data splits; note for instance how the dark gray area
(corresponding to low decoding error) is shifted towards the top left
for Figure \ref{fig:decAcc}A compared to Figure
\ref{fig:decAcc}C. Thus, different data splits interact with decoding
parameters to produce overall decoding accuracy.

To show more clearly the data in Figure \ref{fig:decAcc} for selected
parameter combinations of interest, we plotted separately the raw
decoding error (Figure \ref{fig:decAcc2}A-C) and decoding error
normalized to same-trial decoding within each recording session (Figure
\ref{fig:decAcc2}D). Including units with questionable isolation
quality decreased decoding error across all conditions (compare Figure
\ref{fig:decAcc2}A-B; see Methods and Table \ref{tab:nUnits} for unit
counts), and we therefore used the full set of units including
questionable units for all other analyses. Regardless of the set of
units used, however, Figure {\color{black} \ref{fig:decAcc2}}
illustrates clearly the large improvement in decoding accuracy of very
minimal smoothing (e.g.\ {\color{black} light dashed} line, 5 ms kernel)
compared to no smoothing ({\color{black} dark dashed} line). Also
evident is the performance improvement of the leave-one-out data split
over the next-trial data split; this improvement was particularly large
for larger smoothing (for which, in turn, overall decoding accuracy
was better), for no or minimal smoothing, next-trial and leave-one-out
decoding tended not to differ.

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=\textwidth]{./figures/decQuantify_qCompare.png}}{}
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=\textwidth]{./figures/decQuantify_qCompareG.png}}{}
   \caption{Decoding error for selected parameter and data
    combinations. Panels \bsf{A} and \bsf{B} show decoding error run
    on all sessions (n = 24, i.e.\ without requiring a minimum number
    of cells to be active) to compare decoding error when only
    well-isolated units are used (\bsf{A}) or when units of
    questionable isolation quality are included (\bsf{B}). Panels
    \bsf{C} and \bsf{D} are replots of the same data as in Figure
    \ref{fig:decAcc}, i.e.\ for sessions with at least 20 cells that
    met inclusion criteria (n = 19; see Methods). For panel \bsf{D},
    decoding error is normalized on a single-session basis to the
    same-trial decoding. Errorbars indicate SEM over subjects (n =
    4).}
  \label{fig:decAcc2}
\end{figure}

\subsection*{Effect of trial numbers on decoding accuracy}

Given that leave-one-out decoding performed as well or better than
next-trial decoding, we can ask how this effect depends on the number
of trials included in the leave-one-out procedure. This can be of
practical importance in determining the number of trials of behavioral
sampling will be sufficient for decoding during internally generated
activity. Leave-one-out and next-trial decoding can be seen as
opposite ends of a spectrum along which the number of trials used to
estimate tuning curves is systematically varied. Overall, decoding
performance increased as more trials were included, with diminishing
returns for larger numbers of trials (Figure
\ref{fig:decAccByLap}). As expected from the results in the previous
sections, these overall performance gains in absolute and relative
decoding accuracy depended on the amount of smoothing, with the
largest gains for larger smoothing.

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.75\textwidth]{./figures/decAcc_loocv_lap.png}}{}
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.75\textwidth]{./figures/decAcc_loocv_lapG.png}}{}
  \caption{Raw decoding error (\bsf{A}) or within-session normalized
    decoding error (to next-trial decoding error, \bsf{B}) as a
    function of the number of trials included in the
    cross-validation. Overall, decoding error tended to decrease as
    more trials were included, but the magnitude of this effect
    depended on the degree of smoothing used, with stronger smoothing
    (associated with lower decoding error) benefiting more from
    including more trials.}
  \label{fig:decAccByLap}
\end{figure}

The results up to this point raise an obvious question: {\it why} does
decoding performance depend on the way the data is split between
encoding and decoding (training and testing) sets? There are two major
possibilities. The first one is overfitting, which assumes that
estimating encoding models from a single trial includes fitting a
certain amount of noise which generalizes poorly to other trials. In
this scenario, including more trials would lead to averaging out of
some of this noise, improving performance as shown above (Figure
\ref{fig:decAccByLap}). However, a further, non-exclusive possibility
is that the encoding model (the mapping between position along the
track and neural activity) is not constant across trials. To test this
idea, we plotted single-trial decoding performance as a function of
the ``distance'' between the encoding and decoding trials (this can be
visualized by shifting the matrix in Figure \ref{fig:decschemes}C
horizontally, away from its shown configuration with a distance of
{\color{black} one trial to distances of multiple trials}).

Figure \ref{fig:decAccSingleLap} shows that both raw and relative
decoding error (normalized within-session to same-trial decoding) tended
to increase with larger distance between the encoding and decoding
trial (linear mixed model with subject-specific intercepts; effect of
trial distance $F$ = 10.13, $p$ = 0.0017 for parameters with the
smallest effect). {\color{black} In other words, decoding was more
  accurate when using tuning curves estimated from a ``near'' trial,
  compared to using tuning curves from a ``far'' trial.} However, it
should be noted that pinpointing the source of this effect is
challenging, given that aspects of behavior such as average running
speed and path stereotypy tend to change over the course of a session,
in a manner likely correlated with trial distance (elapsed time) in
this experiment. {\color{black} In attempt to control for such changes,
  we fitted linear mixed models with subject-specific intercepts to
  the data with decoding error as the dependent variable for each pair
  of trials (a decoding ``target'' trial, and an encoding ``source''
  trial). For each such pair we included not only (1) the trial
  distance (number of trials) and (2) the time difference (between
  trial start times) as the key regressors of interest, but also (3)
  the difference in distance run, and (4) the difference in length (in
  time) between the trials in the pair. Even after the behavioral
  variables (3) and (4) were included in the model, either trial
  distance (1) or time difference (2) dramatically improved model fits
  (nuisance variables only log likelihood -595.2, pseudo-$R^2$ 0.22;
  trial distance added -566.39, pseudo-$R^2$ 0.40, time difference
  added -563.71, pseudo-$R^2$ 0.42; all model comparisons $p <$
  0.001 for parameters with the smallest effect). This effect suggests
  that individual trials are associated with distinguishable ensemble
  firing patterns, potentially reflecting trial-unique aspects of
  experience (consistent with results from
  \citeNP{Manns2007,Mankin2012,Allen2012,Ziv2013a}). In turn, this observation
  raises the possibility that a given covert sequence may be best
  decoded by an encoding model associated with a specific trial.}

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.8\textwidth]{./figures/decAcc_singleLapDist.png}}{}
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.8\textwidth]{./figures/decAcc_singleLapDistG.png}}{}
  \caption{Decoding error as a function of the distance (in number of
    trials) for single-trials decoding. A trial distance of 0 means
    that the same trial is used for encoding (estimating tuning
    curves) and decoding; a trial distance of +1 means that the next
    trial is used for encoding, and so on. Raw decoding error
    (\bsf{A}) and decoding error normalized within sessions to
    same-trial decoding error (\bsf{B}) tended to increase with larger
    trial distances. \bsf{C} and \bsf{D} show the same data but for
    absolute distance, i.e.\ previous and next-trial decoding are both
    distance 1. In order to have sufficient numbers of trial pairs to
    perform this analysis, trial pairs on which at least 20\% of
    samples could be decoded were included (unlike the 80\% threshold
    used for all other results; see {\it Methods}).}
  \label{fig:decAccSingleLap}
\end{figure}

\subsection*{Decoding accuracy for different locations}

The overall decoding error measure examined so far averages across
different stimulus (location) values. However, it is possible that
different data splits and decoding parameters differentially affect
decoding accuracy for specific locations. Testing whether any such
nonuniformity exists in the data is crucial when making comparisons
between decoding covert variables (replay) across different stimulus
ranges, such as different parts of a track. To test if this occurs, we
computed the decoding error as a function of location on the track
(Figure \ref{fig:decAccSpace}A-B). Apart from the overall difference
in raw decoding error across data splits, there were clear differences
in how error was distributed {\it across} locations: for next-trial
and leave-one-out decoding, error tended to increase at the start and
end of the track. In contrast, for same-trial decoding, this effect
was not apparent at the start of the track. Smaller differences
between the same-trial and leave-one-out were also apparent, such as
an increase in decoding error around the choice point. Next, we
plotted the confusion matrix of actual and decoded locations for the
different data splits (Figure \ref{fig:decAccSpace}C). Apart from the
overall difference in decoding accuracy, visible as the width of the
diagonal, distortions are visible for the leave-one-out case in
particular. The point indicated by the white arrow shows relatively
poor decoding at the choice point of the T-maze, an effect not
apparent for the other data splits.

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.8\textwidth]{./figures/decQuantify_space.png}}{}
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.8\textwidth]{./figures/decQuantify_spaceG.png}}{}
  \caption{Average decoding error, by location along the track, for
    the best-performing decoding parameters (starred in Figure
    \ref{fig:decAcc}). Column layout is as in Figure
    \ref{fig:decAcc}), with same-trial decoding on the left,
    next-trial in the center, and leave-one-out on the right. \bsf{A}
    shows the raw decoding error, \bsf{B} shows within-session
    Z-scored (across space) error. {\color{black} Importantly}, these
    distributions are different; for instance, the next-trial and
    leave-one-out distributions show increases in error at the start
    and end of the track not seen in the same-trial
    distribution. \bsf{C}: confusion matrices for actual and decoded
    position, averaged across sessions. {\color{black} Note the
      distortion away from the diagonal apparent in the leave-one-out
      distribution (white arrow) not present in the same-trial case.}}
  \label{fig:decAccSpace}
\end{figure}

{\color{black} In general, there are a number of obvious potential
  explanations for non-uniform distributions of decoding accuracy,
  such as differences in the density of place fields and variability
  in behavior. However, these would be expected to affect both
  tautological and cross-validated decoding, when the results show
  strikingly different patterns of decoding accuracy for those cases
  (Figure \ref{fig:decAccSpace}B). To determine what aspects of the
  data could help account for the observed nonuniformity in
  cross-validated decoding, we plotted several quantities related to
  behavior and neural activity as a function of location (Figure
  \ref{fig:behavTuning}). Both average occupancy and its variability
  across trials were non-uniform (Figure \ref{fig:behavTuning}A-B)
  with more sampling around the midpoint of the track compared to the
  start and end. The average firing rate of neurons with place fields
  and the number of place fields across the track also showed
  distributions that did not seem clearly related to decoding accuracy
  (Figure \ref{fig:behavTuning}C-D).

Based on the intuition that cross-validated decoding accuracy depends
on the degree of consistency in behavior and neural activity across
trials, we computed a number of measures designed to quantify this:
(1) the variability in single-trial tuning curves, estimated across trials
for each cell individually and then averaged (Figure
\ref{fig:behavTuning}E-F), (2) the variability in entire-session
tuning curves, as estimated by a resampling (bootstrap) procedure
(Figure \ref{fig:behavTuning}G-H), and (3) the population vector
correlation (i.e.\ mean firing rates across all cells for a given
location), either across single-trial tuning curves or between
single-trial tuning curves and the complementary leave-one-out set of
tuning curves (Figure \ref{fig:behavTuning}I-L). These measures showed
different distributions across the track, with variability in
estimating session tuning curves (Figure \ref{fig:behavTuning}G-H)
showing a distribution most similar to the observed cross-validated
decoding accuracy (Figure \ref{fig:decAccSpace}B). Thus, although
multiple factors contribute to decoding accuracy, tuning curve
variability (as obtained by a bootstrap) may underlie decoding
accuracy differences specific to cross-validated decoding.}

\begin{figure}[h]
  \centering
%  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.8\textwidth]{./figures/decQuantify_space.png}}{}
  \ifthenelse{\boolean{showfig}}{\includegraphics[width=0.8\textwidth]{./figures/behavTuningVariables.png}}{}
  \caption{Among several behavioral and neural measures, tuning curve
    variability as estimated by a bootstrapping procedure is most
    similar to cross-validated decoding accuracy. \bsf{A}: Normalized
    occupancy (time spent) and its standard deviation across trials
    within each session (\bsf{B}). \bsf{C}: Mean firing rate of all
    cells with at least one place field, and distribution of place
    field peaks (\bsf{D}). \bsf{E}: Standard deviation of single-trial
    tuning curves, computed across trials within a session (raw) or
    normalized by the mean (\bsf{F}). \bsf{G}: Entire-session tuning
    curve variability, estimated by a bootstrapping procedure (raw) or
    normalized by the mean (\bsf{H}). \bsf{I}: Raw, and z-scored
    (\bsf{J}) population vector correlation between tuning curves
    estimated across every pair of trials. \bsf{K}: Raw, and z-scored
    (\bsf{L}) population vector correlation between tuning curves
    estimated from each trial and the complementary leave-one-out
    tuning curves.}
  \label{fig:behavTuning}
\end{figure}

\section*{Discussion}

This study contributes two advances to the methodology for decoding
internally generated neural activity. First, we show that using
different data splits for the estimation of the encoding model (tuning
curves) and the decoding of hippocampal place cell activity affects
decoding performance. Specifically, although same-trial decoding was
the clear winner in terms of absolute decoding error, single-trial
decoding generalizes poorly, leading to large decoding errors when
applied to trials other than the one used to obtain tuning
curves. Best generalization performance is obtained with leave-one-out
cross-validation. These observations are in line with standard
practice in the fields of machine learning and statistics
\cite{bishop2006pattern}; here we explore the implications for the
interpretation of covert activity. Specifically, different data splits
did not affect decoding performance uniformly across different
positions, resulting in biases that need to be taken into account when
interpreting decoded ``replay'' data. The second contribution of this
study is that for all data splits, decoding error can be substantially
reduced by relatively minimal smoothing, {\color{red} an observation
  well known in other fields, but not yet systematically applied to
  hippocampal data.}

Both these contributions help address the question of how we should
decode {\color{red} and interpret} internally generated, covert
activity such as occurs in hippocampal ``replay'' during rest and
offline states. The analyses presented here were performed on data
from rats running on a T-maze, rather than on covert activity
directly. However, the crucial conceptual connection between these two
is the following: because the true mapping from neural activity to
{\color{red} decoded} locations {\color{red} that applies to}
internally generated activity is typically unknown (see the section
below for further discussion), this mapping should be optimized for
generalization performance. Operationally, we mimic the decoding of
such covert sequences by pretending that we do not know the true
encoding model for specific trials on the track {\color{red} --} by
leaving out these trials in our analysis {\color{red} --} essentially
  treating them as covert sequences{\color{red},} but with the
  advantage that in this case, we can go back and evaluate decoding
  performance.

To provide a specific example of how insights obtained from this
procedure {\color{red} apply} to the interpretation of decoding
internally generated activity: suppose we used such decoded locations
to detect sequences depicting coherent trajectories along the
track. We may find that these ``replays'' preferentially included the
decision point {\color{red} at the middle of the track}, rather than
the ends of the track. We may be tempted to report this as a finding
of interest, perhaps with an interpretation {\color{red} emphasizing
  prioritized replay as a mechanism useful for reinforcement learning
  \cite{Schaul2015,Gershman2017a}. However, Figure
  \ref{fig:decAccSpace} should make it clear that, in the data set
  used here, such a bias is a straightforward consequence of the
  increase in cross-validated decoding error at both ends of the
  track. Crucially,} if we had used same-trial decoding error instead,
there would not be any indication of a bias favoring the decision
point.

Similar to the above example, it is common to use decoding analyses to
support a comparison between ``replay'' of different experimental
conditions or spatially distinct areas on the track, such as the left
and right arms of a T-maze
\cite{Gupta2010,Bendor2012,Olafsdottir2015}. In such comparisons, it
is crucial to ensure that differences {\color{red} of interest} in
decoded trajectory counts cannot be attributed to intrinsic
differences in ability to decode such sequences (e.g.\ as a result of
different distributions of firing fields across locations, firing
rates, etc). A common way to control for this is to compare decoding
accuracy {\color{red} during behavior across} the conditions to be
compared; our results show that such measures can differ substantially
when based on tautological or cross-validated decoding. {\color{red}
  Thus, in this setting, as in the previous example, {\it the cross-validated
  decoding error provides an important null hypothesis}: the
  distribution of replay content expected from the decoder's ability
  to generalize to neural activity not in the training set.

Note that we are not suggesting any changes to the decoding of
``replay'' activity itself: this can be done with tuning curves
obtained from the full set of behavioral data, because replay activity
is not included in the tuning curves. Rather, we point out that the
{\it interpretation} of the replay decoding results should take the
cross-validated, not tautological, decoding accuracy during behavior
on into account. Whether or not any observed bias in cross-validated
decoding error presents a problem depends on the alternative
hypothesis to be tested against the potentially non-uniform null
hypothesis provided by cross-validated decoding error. Following the
example above: the observed bias in cross-validated decoding error to
be lower around the choice point of the T-maze casts doubt on the
alternative hypothesis that uniform experience is transformed into
preferential replay of choice points. However, this same bias may not
matter for determining whether there exists a difference between the
number of observed ``left'' and ``right'' replays.}

We found that generalization error depends on the number of trials
used to estimate the encoding model, with trial numbers up to the 10
tested generally resulting in lower error. {\color{red} This is
  intuitive, as a noisy, corrupted tuning curve will lead to a less
  effective decoder than an accurate one. Note that this implies that
  when comparing replay content across conditions as in the examples
  above, the amount of data used to estimate tuning curves should be
  equalized to eliminate bias due to this effect}. As the number of trials used
for cross-validation becomes larger, the difference with all-to-all
decoding becomes proportionally smaller. Thus, the importance of
reporting cross-validated error is especially key when smaller numbers
of encoding trials are used, {\color{red} a situation we expect to
  become more common due to factors such as more complex environments
  that limit behavioral sampling, and limitations in imaging time
  due to photobleaching of reporter molecules \cite{Rubin2015,Malvache2016}.

More trials do not always make for a better encoding model, however;
this is illustrated by our observation that decoding error increased
when using trials that occurred further apart in time (Figure
\ref{fig:decAccSingleLap}). As we could not explain this effect based
on changes in behavioral variables}, this suggests a certain amount of
trial-unique content, as has been shown previously with different
analyses \cite{Manns2007,Mankin2012,Ziv2013a}. If the contribution of
time, or trial-unique features more generally, to internally generated
sequences is large \cite{takahashi2015,Schwindel2016a}, then averaging
across many trials may limit and/or bias the detection of
trial-specific replay content. {\color{red} As it is not yet
  clear to what extent internally generated sequences reflect
  trial-unique experience, it is difficult to convert this possibility
  into specific recommendations when interpreting decoded replay
  data. A conservative approach would be to verify the robustness of
  a decoding result against variations in the encoding model used
  (e.g.\ by using different subsets of trials for decoding; we thank
  one of the referees for this suggestion).}

Finally, beyond the comparison of different data splits discussed
above, we show that regardless of split, decoding error can be reduced
substantially by decoding spike density functions (SDFs) rather than
binned spike counts. Such temporal smoothing has been shown to improve
decoding of arm reaching direction from motor cortex activity
(\citeNP{Cunningham2009a}; see also
\citeNP{Kass2003,Shimazaki2010,Prerau2011} for a more general
treatment of statistical issues in spike rate estimation) but to our
knowledge this approach has not been used in studies of hippocampal
place cell activity. Although numerous studies have examined the
effects of the size of the time window on decoding accuracy ($\tau$;
e.g.\ \citeNP{Wilson1993,Zhang1998,Resnik2012,Chen2016a}), this is
different from our spike density function (SDF) estimation approach:
the Gaussian kernel width used in SDF estimation can be manipulated
independently from the window size. Thus, for a given window size,
such as the 25 ms used here, a variable amount of smoothing can be
applied. This modification can be straightforwardly accommodated in
commonly used Bayesian decoding procedures
\cite{Zhang1998}. Remarkably, decoding performance improves even when
estimating SDFs with very narrow kernels (e.g.\ with a standard
deviation of 2 or 5 ms). {\color{red} Using narrow kernels} is
particularly important for applications in decoding covert activity,
which in the case of hippocampal place cells is temporally compressed
relative to behavioral experience
\cite{Nadasdy1999,Lee2002,Dragoi2006,Buzsaki2015a}.

\subsection*{Limitations}

Our suggestion that decoders intended for covert neural activity
should be optimized for cross-validated (generalization) performance
is based on the assumption that the ``true'', correct decoder for such
activity is unknown. Clearly, the approach taken here cannot itself
determine the true mapping from covert neural activity to stimulus
space. Demonstrating the nature of this mapping is a challenging
problem, which may require grounding in experimental observations. Two
promising directions may include (1) obtaining access to a
brain-internal decoder, such as a downstream projection target, making
it possible to determine what aspects of presynaptic activity are
distinguished at a next processing stage {\color{red}
  \cite{Ji2007,Lansink2009,Olafsdottir2016,Jadhav2016a}}; and (2)
applying experimental manipulations contingent on decoded content,
such that any behavioral effects relative to an appropriate control
would constitute evidence that the decoder captures something
relevant {\color{red}(clusterless decoding is a promising approach for
  this; \citeNP{Kloosterman2014,Deng2015})}. A different approach is
to construct generative models in an attempt to reproduce
experimentally observed activity
\cite{johnson2008holscherbk,Pfeiffer2015,Chen2016a}. In the limit of a
perfect match between the model output and the experimentally observed
data, then the optimal decoder can be determined from what is now a
known ground truth (the generative model). {\color{red} However, these
  approaches are not yet mature, and may remain impractical for the
  purpose of determining the most suitable decoder in any given
  experiment. Thus, we provide more practical recommendations in the
  final section.}

A {\color{red} different} limitation of this study is that although
encoding model parameters can be optimized for decoding error when the
true location is known, it is unclear how the parameters obtained in
this way should be applied to decoding covert activity. Estimates of
the temporal compression in internally generated vs.\ overt activity
range from 7-20x \cite{Lee2002,Davidson2009,Buzsaki2015a}, thus a
practical starting point would be to simply reduce the $\sigma_Q$
found to be optimal for decoding overt behavior by a factor in that
range. For the data set used here this would suggest a value of
$\sigma_Q$ = 5 ms to be a conservative estimate. Future work could
provide a more principled estimate of this parameter by, for instance,
using generative models as outlined above.

Similarly, our current estimation method for tuning curves uses a
relatively {\it ad hoc} approach of non-parametrically obtaining
firing rates from the data, {\color{red} followed by smoothing}. Other
work has used parametric approaches such as fitting Gaussians or
Zernike polynomials \cite{Barbieri2002}; such methods are completely
compatible with the approach we take here. Our goal in this study was
not to determine which method for tuning curve estimation works best;
rather, the main purpose of {\color{red} not using raw, unsmoothed
  tuning curves} here was to prevent inconsistent combinations of
spike counts. Looking forward, however, there are clearly
opportunities for improving the estimation of tuning curves, such as
propagating uncertainty about estimated firing rates throughout the
decoding procedure, correcting for the blurring effects of theta phase
precession \cite{Lisman2009}, and taking the presence of different
gamma oscillations into account \cite{Zheng2016}.

Finally, the results provided here are based on one specific data
set. However, we emphasize that the specific optimal parameters and
decoding error distributions found here are not meant to be imported
verbatim to analysis of other data sets for which they may or may not
work well; if this was the purpose of the study it would indeed be
important to test how consistent the inferred optima are. Rather,
these results illustrate the importance of choosing parameters and
data splits in a principled manner, and suggests specific steps that
can be applied to other data sets to find parameters appropriate for
that data.

More generally, although we used hippocampal place cell data from
rodents, the ideas developed here can also be applied to other systems
in which covert activity can be meaningfully decoded. In rodents,
these include the head direction system \cite{Peyrache2015}, areas
involved in the processing of decision variables such as orbitofrontal
cortex and ventral striatum \cite{Stott2014}, {\color{red} and
  internal representations of time
  \cite{Pastalkova2008,MacDonald2013,Mello2015}}. Non-human primate
studies prominently explore the generation of motor activity related
to upcoming reaching movements \cite{Wu2006,Yu2009a}, and ensemble
recording and analysis methods are becoming increasingly common in
studies of decision making \cite{Rich2016}. In human subjects, MEG
studies have started to explore the fast dynamics of thought
\cite{King2014,Bellmund2016,Kurth-Nelson2016}, and MVPA has revealed
structure in internally generated activity in a wide range of domains
\cite{Reddy2010,Brown2016}. The present study suggests that the
analysis of internally generated sequences of hippocampal activity in
rodents can interact productively with statistical approaches
developed across domains.

\subsection*{Summary: three practical guidelines for the decoding
  and interpretation of internally generated neural activity}

The use of cross-validation for decoding is commonplace in human
neuroimaging studies
\cite{Pereira2009,Shirer2012,Varoquaux2016}. Several studies
performing position decoding on rodent hippocampus data have used a
split between training and testing data
(e.g.\ \citeNP{Zhang1998,Rutishauser2006,Davidson2009,Resnik2012,Agarwal2014}),
but this practice has not been consistently applied in this
field. Moreover, the motivation for reporting decoding errors based on
cross-validation, and its particular importance for the interpretation
of internally generated activity, is typically not made explicit. For
the decoding of hippocampal place cell data for this purpose, we
suggest the following:

\begin{itemize}
\item{Report cross-validated, not tautological, decoding error on
  ``running'' data. This is good practice in general, but particularly
  crucial when using decoding accuracy to reveal possible bias in the
  ability to decode different conditions or trajectories. {\color{red}
    The cross-validated decoding error distribution should be viewed
    as a null hypothesis for comparison with alternative hypotheses
    about the decoded content of internally generated activity, such
    as replay.}}
\item{{\color{red} Because cross-validated decoding error depends (1)
    on the amount of data (e.g.\ number of trials) used to estimate
    tuning curves, and (2) temporal distance between trials used to
    estimate tuning curves and the time of decoding. Thus, these
    factors should be equalized, either by design or by subsampling,
    when comparing replay content across conditions.}}
\item{Even very mild smoothing of the spike trains to be decoded, such
  as a 5 ms Gaussian kernel for spike density functions, and a 3 cm
  kernel for tuning curves, can substantially improve
  decoding performance. {\color{red} However, due to the compression
    of hippocampal replay relative to behavioral experience, excessive
    smoothing is discouraged.}}
\end{itemize}


\section*{Acknowledgments}

This work was supported by NWO, HFSP, and the Templeton Foundation
(MvdM). We are grateful to Loren Frank, Margaret Carr, and Caleb
Kemere for sharing the original design upon which our electrode arrays
were based. We thank Nancy Gibson, Jean Flanagan, and Martin Ryan for
assistance with animal care, Harmen VanderHeide, Jacek Szubra, Andrew
Dub\'e, and Zhenwhen Zhang for technical assistance, and Min-Ching Kuo
for assistance with surgery. We thank Adam Johnson, Elyot Grant and
Alireza Soltani for helpful comments on an earlier version of the
manuscript, and the referees for insightful suggestions.

Author contributions: MvdM designed and supervised research. AAC
performed experiments, preprocessed and annotated the data. AAC, YT
and MvdM wrote analysis code. MvdM performed analysis. MvdM wrote the
manuscript with input from AAC and YT.


%\bibliography{C:/Users/mvdm/Documents/library/Decoding} % isidro
\bibliography{D:/My_Documents/library/Decoding} % bergkamp

\end{document}

