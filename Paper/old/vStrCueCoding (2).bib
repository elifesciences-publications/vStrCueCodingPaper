Automatically generated by Mendeley Desktop 1.17.12
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{ChiYiuYim1982,
abstract = {Extracellular single unit recordings were obtained from the nucleus accumbens of urethane anesthetized rats. It was found that electrical stimulation of the basal lateral and basal medial nuclei of the amygdala produced strong excitatory responses in neurons of the nucleus accumbens, in particular the medial region. Latencies of activation were relatively short with a mean of 10.7 ms. Dopamine applied iontophoretically had a marked attenuating effect on the excitatory response of nucleus accumbens neurons to amygdala stimulation. The spontaneous activity of all neurons recorded from the nucleus accumbens was also suppressed by dopamine, but the excitatory response was more sensitive to dopamine inhibition than the spontaneous activity. Neurons in the nucleus accumbens showed a variety of responses to single-pulse electrical stimulation of the ventral tegmental area (VTA). Some units in the nucleus accumbens received convergent inputs from both the amygdala and the VTA. Stimulation of the VTA also attenuated the response of nucleus accumbens neurons to excitatory inputs from the amygdala. A train of 10 pulses (0.15 ms, 200-600 ??A) at 10 Hz delivered to the VTA at 100 ms before stimulation of the amygdala caused attenuation of the original excitatory response. The attenuating effect could be observed irrespective of whether individual single-pulse stimulation of the VTA elicited a response in that particular accumbens neuron or not. 6-Hydroxydopamine injected into the VTA 2 days prior to the recording experiment, or haloperidol injected intraperitoneally 1 h before the recording session, abolished this attenuating effect. However, responses to single-pulse stimulations of the VTA were not abolished. The results suggest that the attenuation of the excitatory response to amygdala stimulation was due to the release of dopamine from mesolimbic dopaminergic neurons. Responses to single-pulse stimulations of the VTA were probably due to activation of non-dopaminergic neurons projecting from the same area. It is suggested as a working hypothesis that this inhibitory effect of dopamine may be an important function of the mesolimbic dopamine pathway in modulating the extent to which limbic structures can exert an influence on the motor system through the accumbens. ?? 1982.},
author = {{Chi Yiu Yim} and Mogenson, Gordon J.},
doi = {10.1016/0006-8993(82)90518-2},
isbn = {0006-8993 (Print)$\backslash$r0006-8993 (Linking)},
issn = {00068993},
journal = {Brain Research},
keywords = {amygdala,dopamine,neuromodulation,nucleus accumbens,ventral tegmental area},
month = {may},
number = {2},
pages = {401--415},
pmid = {6284305},
title = {{Response of nucleus accumbens neurons to amygdala stimulation and its modification by dopamine}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0006899382905182},
volume = {239},
year = {1982}
}
@article{Asaad2017,
abstract = {To adapt successfully to our environments, we must use the outcomes of our choices to guide future behavior. Critically, we must be able to correctly assign credit for any particular outcome to the causal features which preceded it. In some cases, the causal features may be immediately evident, whereas in others they may be separated in time or intermingled with irrelevant environmental stimuli, creating a potentially nontrivial credit-assignment problem. We examined the neuronal representation of information relevant for credit assignment in the dorsolateral prefrontal cortex (dlPFC) of two male rhesus macaques performing a task that elicited key aspects of this problem. We found that neurons conveyed the information necessary for credit assignment. Specifically, neuronal activity reflected both the relevant cues and outcomes at the time of feedback and did so in a manner that was stable over time, in contrast to prior reports of representational instability in the dlPFC. Furthermore, these representations were most stable early in learning, when credit assignment was most needed. When the same features were not needed for credit assignment, these neuronal representations were much weaker or absent. These results demonstrate that the activity of dlPFC neurons conforms to the basic requirements of a system that performs credit assignment, and that spiking activity can serve as a stable mechanism that links causes and effects.SIGNIFICANCE STATEMENT Credit assignment is the process by which we infer the causes of our successes and failures. We found that neuronal activity in the dorsolateral prefrontal cortex conveyed the necessary information for performing credit assignment. Importantly, while there are various potential mechanisms to retain a "trace" of the causal events over time, we observed that spiking activity was sufficiently stable to act as the link between causes and effects, in contrast to prior reports that suggested spiking representations were unstable over time. In addition, we observed that this stability varied as a function of learning, such that the neural code was more reliable over time during early learning, when it was most needed.},
author = {Asaad, Wael F. and Lauro, Peter M. and Perge, J{\'{a}}nos A. and Eskandar, Emad N.},
doi = {10.1523/JNEUROSCI.3311-16.2017},
isbn = {1529-2401 (Electronic)0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {credit assignment,learning,monkey,population coding,prefrontal cortex,single neuron},
month = {jul},
number = {29},
pages = {6995--7007},
pmid = {28634307},
publisher = {Society for Neuroscience},
title = {{Prefrontal Neurons Encode a Solution to the Credit-Assignment Problem}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3311-16.2017},
volume = {37},
year = {2017}
}
@article{Wheeler2009,
abstract = {An important goal of cocaine addiction research is to understand the neurobiological mechanisms underlying this disease state. Here, we review studies from our laboratory that examined nucleus accumbens (NAc) cell firing and rapid dopamine signaling using electrophysiological and electrochemical recordings in behaving rodents. A major advantage of these techniques is that they allow for the characterization of NAc activity and rapid dopamine release during specific phases of motivated behavior. Moreover, each approach enables an examination of the dynamic nature of NAc signaling as a function of factors such as hedonics and associative learning. We show that NAc neurons differentially respond to rewarding and aversive stimuli and their predictors in a bivalent manner. This differential responding is modifiable and can be altered by the presentation of other natural rewards or cocaine. Likewise, the dynamic nature of NAc cell firing is also reflected in the differential activation of distinct populations of NAc neurons during goal-directed behaviors for natural versus drug rewards, and the heightened activation of some NAc neurons following cocaine abstinence. Our electrochemical data also show that rapid dopamine signaling in the NAc reflects primary rewards and their predictors and appears to modulate specific NAc neuronal responses. In some cases, these influences are observed in a regionally specific manner that matches previous pharmacological manipulations. Collectively, these findings provide critical insight into the functional organization of the NAc that can be used to guide additional studies aimed at dissecting the neural code underlying compulsive drug-seeking behavior. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Wheeler, Robert A. and Carelli, Regina M.},
doi = {10.1016/j.neuropharm.2008.06.028},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wheeler, Carelli - 2009 - Dissecting motivational circuitry to understand substance abuse.pdf:pdf},
isbn = {9199628775},
issn = {00283908},
journal = {Neuropharmacology},
keywords = {Aversion,Cocaine,Drug abuse,Nucleus accumbens,Reward,Taste},
month = {jan},
number = {SUPPL. 1},
pages = {149--159},
pmid = {18625253},
publisher = {Pergamon},
title = {{Dissecting motivational circuitry to understand substance abuse}},
url = {http://www.sciencedirect.com/science/article/pii/S0028390808002189},
volume = {56},
year = {2009}
}
@article{Hamid2016,
abstract = {Dopamine cell firing can encode errors in reward prediction, providing a learning signal to guide future behavior. Yet dopamine is also a key modulator of motivation, invigorating current behavior. Existing theories propose that fast (phasic) dopamine fluctuations support learning, whereas much slower (tonic) dopamine changes are involved in motivation. We examined dopamine release in the nucleus accumbens across multiple time scales, using complementary microdialysis and voltammetric methods during adaptive decision-making. We found that minute-by-minute dopamine levels covaried with reward rate and motivational vigor. Second-by-second dopamine release encoded an estimate of temporally discounted future reward (a value function). Changing dopamine immediately altered willingness to work and reinforced preceding action choices by encoding temporal-difference reward prediction errors. Our results indicate that dopamine conveys a single, rapidly evolving decision variable, the available reward for investment of effort, which is employed for both learning and motivational functions.},
author = {Hamid, Arif A and Pettibone, Jeffrey R and Mabrouk, Omar S and Hetrick, Vaughn L and Schmidt, Robert and {Vander Weele}, Caitlin M and Kennedy, Robert T and Aragona, Brandon J and Berke, Joshua D},
doi = {10.1038/nn.4173},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {15461726},
journal = {Nature Neuroscience},
month = {jan},
number = {1},
pages = {117--126},
pmid = {26595651},
title = {{Mesolimbic dopamine signals the value of work}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26595651 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4696912 http://www.nature.com/articles/nn.4173},
volume = {19},
year = {2015}
}
@article{Lansink2012,
abstract = {Forming place-reward associations critically depends on the integrity of the hippocampal-ventral striatal system. The ventral striatum (VS) receives a strong hippocampal input conveying spatial-contextual information, but it is unclear how this structure integrates this information to invigorate reward-directed behavior. Neuronal ensembles in rat hippocampus (HC) and VS were simultaneously recorded during a conditioning task in which navigation depended on path integration. In contrast to HC, ventral striatal neurons showed low spatial selectivity, but rather coded behavioral task phases toward reaching goal sites. Outcome-predicting cues induced a remapping of firing patterns in the HC, consistent with its role in episodic memory. VS remapped in conjunction with the HC, indicating that remapping can take place in multiple brain regions engaged in the same task. Subsets of ventral striatal neurons showed a "flip" from high activity when cue lights were illuminated to low activity in intertrial intervals, or vice versa. The cues induced an increase in spatial information transmission and sparsity in both structures. These effects were paralleled by an enhanced temporal specificity of ensemble coding and a more accurate reconstruction of the animal's position from population firing patterns. Altogether, the results reveal strong differences in spatial processing between hippocampal area CA1 and VS, but indicate similarities in how discrete cues impact on this processing.},
author = {Lansink, C. S. and Jackson, J. C. and Lankelma, J. V. and Ito, R. and Robbins, T. W. and Everitt, B. J. and Pennartz, C. M. A.},
doi = {10.1523/JNEUROSCI.0593-12.2012},
isbn = {0270-6474; 1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {sep},
number = {36},
pages = {12444--12459},
pmid = {22956836},
publisher = {Society for Neuroscience},
title = {{Reward Cues in Space: Commonalities and Differences in Neural Coding by Hippocampal and Ventral Striatal Ensembles}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0593-12.2012},
volume = {32},
year = {2012}
}
@article{Lansink2009,
abstract = {Associating spatial locations with rewards is fundamental to survival in natural environments and requires the integrity of the hippocampus and ventral striatum. In joint multineuron recordings from these areas, hippocampal-striatal ensembles reactivated together during sleep. This process was especially strong in pairs in which the hippocampal cell processed spatial information and ventral striatal firing correlated to reward. Replay was dominated by cell pairs in which the hippocampal "place" cell fired preferentially before the striatal reward-related neuron. Our results suggest a plausible mechanism for consolidating place-reward associations and are consistent with a central tenet of consolidation theory, showing that the hippocampus leads reactivation in a projection area.},
author = {Lansink, Carien S. and Goltstein, Pieter M. and Lankelma, Jan V. and McNaughton, Bruce L. and Pennartz, Cyriel M.A.},
doi = {10.1371/journal.pbio.1000173},
editor = {Stevens, Charles F.},
isbn = {1545-7885 (Electronic) 1544-9173 (Linking)},
issn = {15449173},
journal = {PLoS Biology},
month = {aug},
number = {8},
pages = {e1000173},
pmid = {19688032},
publisher = {Public Library of Science},
title = {{Hippocampus leads ventral striatum in replay of place-reward information}},
url = {http://dx.plos.org/10.1371/journal.pbio.1000173},
volume = {7},
year = {2009}
}
@article{Stefani2006,
abstract = {The midbrain dopamine system has been ascribed roles in reward expectancy, error detection, prediction, and memory. However, these theories typically do not differentiate between dopamine response and action in different forebrain terminal fields. We measured dopamine release in the prefrontal cortex (PFC), nucleus accumbens (NAc), and dorsal striatum (DS) of rats exposed to the same maze apparatus under three behavioral conditions: a set-shift task in which reward depended on discrimination learning and extradimensional set-shifting, a yoked condition in which reward was intermittent and not under the control of the subject, and a "reward-retrieval" variant in which reward was certain on every trial. We found dissociable patterns of dopamine release associated with learning, uncertainty, and reward. Dopamine increased in all three regions when reward was contingent on rule learning and shifting or was uncertain. These increases were sustained after behavior. There was a significant correlation between the magnitude of increase in PFC dopamine and the rapidity with which rats shifted between discrimination rules. In the yoke condition, in which the receipt of reward was always uncertain, the opposite relationship between dopamine levels and likelihood of reward was observed. Predictable, noncontingent reward was associated with increased dopamine levels in the NAc and DS. In contrast, PFC dopamine did not increase significantly above baseline levels. Thus, the dopaminergic projections to the PFC and nucleus accumbens were selectively, yet differentially, activated in situations of uncertainty and cognitive demand, whereas the dopaminergic projection to the DS responded independently of task differences in learning and reward.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Stefani, M. R.},
doi = {10.1523/JNEUROSCI.1656-06.2006},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stefani, Moghaddam - 2006 - Rule learning and reward contingency are associated with dissociable patterns of dopamine activation in the.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {aug},
number = {34},
pages = {8810--8818},
pmid = {16928870},
publisher = {Society for Neuroscience},
title = {{Rule Learning and Reward Contingency Are Associated with Dissociable Patterns of Dopamine Activation in the Rat Prefrontal Cortex, Nucleus Accumbens, and Dorsal Striatum}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1656-06.2006},
volume = {26},
year = {2006}
}
@article{Koob2010,
abstract = {Drug addiction is a chronically relapsing disorder that has been characterized by (1) compulsion to seek and take the drug, (2) loss of control in limiting intake, and (3) emergence of a negative emotional state (eg, dysphoria, anxiety, irritability) reflecting a motivational withdrawal syndrome when access to the drug is prevented. Drug addiction has been conceptualized as a disorder that involves elements of both impulsivity and compulsivity that yield a composite addiction cycle composed of three stages: 'binge/intoxication', 'withdrawal/negative affect', and 'preoccupation/anticipation' (craving). Animal and human imaging studies have revealed discrete circuits that mediate the three stages of the addiction cycle with key elements of the ventral tegmental area and ventral striatum as a focal point for the binge/intoxication stage, a key role for the extended amygdala in the withdrawal/negative affect stage, and a key role in the preoccupation/anticipation stage for a widely distributed network involving the orbitofrontal cortex-dorsal striatum, prefrontal cortex, basolateral amygdala, hippocampus, and insula involved in craving and the cingulate gyrus, dorsolateral prefrontal, and inferior frontal cortices in disrupted inhibitory control. The transition to addiction involves neuroplasticity in all of these structures that may begin with changes in the mesolimbic dopamine system and a cascade of neuroadaptations from the ventral striatum to dorsal striatum and orbitofrontal cortex and eventually dysregulation of the prefrontal cortex, cingulate gyrus, and extended amygdala. The delineation of the neurocircuitry of the evolving stages of the addiction syndrome forms a heuristic basis for the search for the molecular, genetic, and neuropharmacological neuroadaptations that are key to vulnerability for developing and maintaining addiction.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Koob, George F. and Volkow, Nora D.},
doi = {10.1038/npp.2009.110},
eprint = {NIHMS150003},
isbn = {1740-634X},
issn = {0893133X},
journal = {Neuropsychopharmacology},
month = {jan},
number = {1},
pages = {217--238},
pmid = {19710631},
publisher = {Nature Publishing Group},
title = {{Neurocircuitry of addiction}},
url = {http://www.nature.com/articles/npp2009110},
volume = {35},
year = {2010}
}
@article{Wiener2003,
abstract = {In order to better understand the impact of hippocampal processing on downstream neural structures and cognitive functions, neurons were simultaneously recorded in the hippocampus and in basal ganglia zones receiving inputs from hippocampus directly (the nucleus accumbens shell) or indirectly via the prefrontal cortex (nucleus accumbens core and ventromedial caudate nucleus) in rats performing spatial orientation tasks. In one series of experiments, the animals alternated between using intramaze and extramaze cues to find water rewards. In a second series, the rats were required to learn the distribution of different reward quantities provided at the respective goal boxes in a plus maze. Correct performance in the latter task has been shown to be impaired by lesions of the accumbens shell. Hippocampal place responses were anchored to the extramaze cues and were independent of reward values provided near or in the firing fields. While no hippocampal-like firing fields were found in accumbens neurons, neuronal activity during pre-reward, post-reward and reward approach behaviors was more intense at some locations than at others. This is consistent with anatomical and physiological observations corresponding to the convergence of hippocampal position information with reward related signals from the amygdala and ventral tegmental area (VTA). {\textcopyright} 2003, Elsevier Inc. All rights reserved.},
author = {Wiener, Sidney I. and Shibata, Ryoko and Tabuchi, Eiichi and Trullier, Olivier and Albertin, Sergey V. and Mulder, Antonius B.},
doi = {10.1016/S0531-5131(03)00978-6},
issn = {05315131},
journal = {International Congress Series},
keywords = {Limbic system,Navigation,Place cells,Spatial orientation,Striatum},
month = {oct},
number = {C},
pages = {275--292},
publisher = {Elsevier},
title = {{Spatial and behavioral correlates in nucleus accumbens neurons in zones receiving hippocampal or prefrontal cortical inputs}},
url = {https://www.sciencedirect.com/science/article/pii/S0531513103009786},
volume = {1250},
year = {2003}
}
@article{Estes1943,
abstract = {"A series of presentations of a tone followed by food to a group of rats resulted in the conditioning of an anticipatory state to the tone, the primary index being the discriminative effect of the tone upon a lever-pressing response which had previously been reinforced with food but in no way associated with the tone. During a test period subsequent to the series of tone-food combinations, the rate of lever pressing was markedly increased during intervals when the tone was sounding and depressed during silent intervals, although the response had never been associated with the tone prior to the test period." (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Estes, W. K.},
doi = {10.1037/h0058316},
issn = {00221015},
journal = {Journal of Experimental Psychology},
keywords = {CONDITIONING, DISCRIMINATION, RAT,DISCRIMINATION, CONDITIONING, RAT,LEARNING, CONDITIONING, INTELLIGENCE (INCL. ATTENT,RAT, DISCRIMINATION, CONDITIONING},
number = {2},
pages = {150--155},
title = {{Discriminative conditioning. I. A discriminative property of conditioned anticipation}},
url = {http://content.apa.org/journals/xge/32/2/150},
volume = {32},
year = {1943}
}
@article{Lavoie1994,
abstract = {Previous behavioral and acute electrophysiological data have lead researchers to speculate that the nucleus accumbens integrates limbic, reward and motor information [5,12,22,31]. The present study examined the behavioral correlates to single unit activity of the nucleus accumbens and surrounding ventral striatum as a means of evaluating the integrative functioning of this region in an awake animal. Medial ventral striatum (mVS) activity was recorded as rats completed multiple trials on an eight arm radial maze. Neuronal activity was found to correlate with spatial, reward- and movement-related behavioral conditions. While the majority of cells demonstrated correlates of a single type (i.e. either spatial or reward correlates), 6 cells encoded multiple correlates of different types (i.e. spatial and reward correlates). The data suggests that this integrative process can be active both at the level of the individual neuron, and at the structural level. These results are consistent with the hypothesis that the mVS integrates spatial and reward-related information, which in turn influences voluntary motor output structures in order to achieve accurate navigational behavior. {\textcopyright} 1994.},
author = {Lavoie, A. M. and Mizumori, S. J.Y.},
doi = {10.1016/0006-8993(94)90645-9},
isbn = {0006-8993 (Print)},
issn = {00068993},
journal = {Brain Research},
keywords = {Amygdala,Hippocampus,Single unit activity,Spatial memory,Ventral striatum},
month = {feb},
number = {1-2},
pages = {157--168},
pmid = {8199856},
publisher = {Elsevier},
title = {{Spatial, movement- and reward-sensitive discharge by medial ventral striatum neurons of rats}},
url = {https://www.sciencedirect.com/science/article/pii/0006899394906459},
volume = {638},
year = {1994}
}
@article{Yun2004,
abstract = {Reward-predictive cues exert powerful control over behavioral choice and may be a critical factor in drug addiction. Reward-seeking elicited by predictive cues is facilitated by the release of dopamine in the nucleus accumbens (NAc), yet the contribution of dopamine to the specific NAc firing patterns that underlie goal-directed behavior has remained elusive. We present evidence that subpopulations of NAc neurons that respond to predictive cues require the dopaminergic projection from the ventral tegmental area (VTA) to promote reward-seeking behavior. Rats trained to perform an operant response to a cue to obtain a sucrose reward were implanted with both multiunit recording electrodes in the NAc and microinjection cannulas in the VTA. Both the behavioral response to cues and the cue-evoked firing of NAc neurons were blocked by injection of the GABA(B) agonist baclofen into the VTA. An additional group of rats was trained on the same task and then implanted with microinjection cannulas in the NAc. Like VTA baclofen injection, injection of dopamine receptor antagonists into the NAc profoundly reduced cue-elicited reward seeking. Together, these results support the conclusion that both the behavioral response to the cue and the specific NAc neuronal firing that promotes the response depend on dopamine release within the NAc. Our findings suggest a neural mechanism by which the dopamine-dependent firing of NAc neurons mediates goal-directed behavior.},
author = {Yun, Irene A and Wakabayashi, Ken T and Fields, Howard L and Nicola, Saleem M},
doi = {10.1523/JNEUROSCI.5282-03.2004},
isbn = {1529-2401 (Electronic)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {basal ganglia,discrim-inative stimulus,dopamine,goal-directed behavior,motivation,nucleus accumbens,operant,reward,ventral striatum},
number = {12},
pages = {2923--2933},
pmid = {15044531},
title = {{The Ventral Tegmental Area Is Required for the Behavioral and Nucleus Accumbens Neuronal Firing Responses to Incentive Cues}},
url = {http://www.jneurosci.org/content/jneuro/24/12/2923.full.pdf http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5282-03.2004},
volume = {24},
year = {2004}
}
@article{Hearst,
author = {Hearst, E. and Jenkins, H. M.},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text.pdf:pdf},
title = {{Full Text}}
}
@article{Chang2013a,
abstract = {Certain Pavlovian conditioned stimuli (CSs) paired with food unconditioned stimuli (USs) come to elicit approach and even consumption-like behaviors in rats (sign-tracking). We investigated the effects of lesions of the nucleus accumbens core (ACbC) or shell (ACbS) on the acquisition of sign-tracking in a discriminative autoshaping procedure in which presentation of one lever CS was followed by delivery of sucrose, and another was not. Although we previously found that bilateral lesions of the whole ACb disrupted the initial acquisition of sign-tracking, neither ACbC or ACbS lesions affected the rate or percentage of trials in which rats pressed the CS+. In addition, detailed video analysis showed no effect of either lesion on the topography of the sign-tracking conditioned response (CR). These and other results from lesion studies of autoshaping contrast with those from previous sign-tracking experiments that used purely visual cues (Parkinson et al., 2000a,b), suggesting that the neural circuitry involved in assigning incentive value depends upon the nature of the CS. {\textcopyright} 2013 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Chang, Stephen E. and Holland, Peter C.},
doi = {10.1016/j.bbr.2013.07.046},
eprint = {NIHMS150003},
isbn = {1872-7549},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {Autoshaping,Incentive salience,Nucleus accumbens core,Nucleus accumbens shell},
month = {nov},
pages = {36--42},
pmid = {23933141},
title = {{Effects of nucleus accumbens core and shell lesions on autoshaped lever-pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23933141 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3815957 http://linkinghub.elsevier.com/retrieve/pii/S0166432813004580},
volume = {256},
year = {2013}
}
@article{VanderMeer2011,
abstract = {A functional interaction between the hippocampal formation and the ventral striatum is thought to contribute to the learning and expression of associations between places and rewards. However, the mechanism of how such associations may be learned and used is currently unknown. We recorded neural ensembles and local field potentials from the ventral striatum and CA1 simultaneously as rats ran a modified T-maze. Theta-modulated cells in ventral striatum almost invariably showed firing phase precession relative to the hippocampal theta rhythm. Across the population of ventral striatal cells, phase precession was preferentially associated with an antic- ipatory ramping of activity up to the reward sites. In contrast, CA1 population activity and phase precession were distributed more uniformly. Ventral striatal phase precession was stronger to hippocampal than ventral striatal theta and was accompanied by increased theta coherence with hippocampus, suggesting that this effect is hippocampally derived. These results suggest that the firing phase of ventral striatal neurons contains motivationally relevant information and that phase precession serves to bind hippocampal place representations to ventral striatal representations of reward.},
author = {van der Meer, M. A. A. and Redish, A. D.},
doi = {10.1523/JNEUROSCI.4869-10.2011},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {8},
pages = {2843--2854},
pmid = {21414906},
title = {{Theta Phase Precession in Rat Ventral Striatum Links Place and Reward Information}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4869-10.2011},
volume = {31},
year = {2011}
}
@article{Berridge2012,
abstract = {Reward contains separable psychological components of learning, incentive motivation and pleasure. Most computational models have focused only on the learning component of reward, but the motivational component is equally important in reward circuitry, and even more directly controls behavior. Modeling the motivational component requires recognition of additional control factors besides learning. Here I discuss how mesocorticolimbic mechanisms generate the motivation component of incentive salience. Incentive salience takes Pavlovian learning and memory as one input and as an equally important input takes neurobiological state factors (e.g. drug states, appetite states, satiety states) that can vary independently of learning. Neurobiological state changes can produce unlearned fluctuations or even reversals in the ability of a previously learned reward cue to trigger motivation. Such fluctuations in cue-triggered motivation can dramatically depart from all previously learned values about the associated reward outcome. Thus, one consequence of the difference between incentive salience and learning can be to decouple cue-triggered motivation of the moment from previously learned values of how good the associated reward has been in the past. Another consequence can be to produce irrationally strong motivation urges that are not justified by any memories of previous reward values (and without distorting associative predictions of future reward value). Such irrationally strong motivation may be especially problematic in addiction. To understand these phenomena, future models of mesocorticolimbic reward function should address the neurobiological state factors that participate to control generation of incentive salience.},
author = {Berridge, Kent C.},
doi = {10.1111/j.1460-9568.2012.07990.x},
isbn = {0953-816X},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Dopamine,Incentive salience,Learning,Mesolimbic,Nucleus accumbens,Prediction error},
month = {apr},
number = {7},
pages = {1124--1143},
pmid = {22487042},
publisher = {NIH Public Access},
title = {{From prediction error to incentive salience: Mesolimbic computation of reward motivation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22487042 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3325516},
volume = {35},
year = {2012}
}
@article{Gradin2011,
abstract = {The dopamine system has been linked to anhedonia in depression and both the positive and negative symptoms of schizophrenia, but it remains unclear how dopamine dysfunction could mechanistically relate to observed symptoms. There is considerable evidence that phasic dopamine signals encode prediction error (differences between expected and actual outcomes), with reinforcement learning theories being based on prediction error-mediated learning of associations. It has been hypothesized that abnormal encoding of neural prediction error signals could underlie anhedonia in depression and negative symptoms in schizophrenia by disrupting learning and blunting the salience of rewarding events, and contribute to psychotic symptoms by promoting aberrant perceptions and the formation of delusions. To test this, we used model based functional magnetic resonance imaging and an instrumental reward-learning task to investigate the neural correlates of prediction errors and expected-reward values in patients with depression (n=15), patients with schizophrenia (n=14) and healthy controls (n=17). Both patient groups exhibited abnormalities in neural prediction errors, but the spatial pattern of abnormality differed, with the degree of abnormality correlating with syndrome severity. Specifically, reduced prediction errors in the striatum and midbrain were found in depression, with the extent of signal reduction in the bilateral caudate, nucleus accumbens and midbrain correlating with increased anhedonia severity. In schizophrenia, reduced prediction error signals were observed in the caudate, thalamus, insula and amygdala-hippocampal complex, with a trend for reduced prediction errors in the midbrain, and the degree of blunting in the encoding of prediction errors in the insula, amygdala-hippocampal complex and midbrain correlating with increased severity of psychotic symptoms. Schizophrenia was also associated with disruption in the encoding of expected-reward values in the bilateral amygdala-hippocampal complex and parahippocampal gyrus, with the degree of disruption correlating with psychotic symptom severity. Neural signal abnormalities did not correlate with negative symptom severity in schizophrenia. These findings support the suggestion that a disruption in the encoding of prediction error signals contributes to anhedonia symptoms in depression. In schizophrenia, the findings support the postulate of an abnormality in error-dependent updating of inferences and beliefs driving psychotic symptoms. Phasic dopamine abnormalities in depression and schizophrenia are suggested by our observation of prediction error abnormalities in dopamine-rich brain areas, given the evidence for dopamine encoding prediction errors. The findings are consistent with proposals that psychiatric syndromes reflect different disorders of neural valuation and incentive salience formation, which helps bridge the gap between biological and phenomenological levels of understanding.},
author = {Gradin, Victoria B. and Kumar, Poornima and Waiter, Gordon and Ahearn, Trevor and Stickle, Catriona and Milders, Marteen and Reid, Ian and Hall, Jeremy and Steele, J. Douglas},
doi = {10.1093/brain/awr059},
isbn = {0006-8950},
issn = {14602156},
journal = {Brain},
keywords = {dopamine,major depression,model based fMRI,prediction error,schizophrenia},
month = {jun},
number = {6},
pages = {1751--1764},
pmid = {21482548},
title = {{Expected value and prediction error abnormalities in depression and schizophrenia}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21482548 https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awr059},
volume = {134},
year = {2011}
}
@book{hearst1974sign,
author = {Hearst, E and Jenkins, H M},
booktitle = {Psychonomic Society},
pages = {1--49},
publisher = {Psychonomic Society},
title = {{Sign-tracking: the stimulus-reinforcer relation and directed action}},
year = {1974}
}
@article{Berridge2012a,
abstract = {Reward contains separable psychological components of learning, incentive motivation and pleasure. Most computational models have focused only on the learning component of reward, but the motivational component is equally important in reward circuitry, and even more directly controls behavior. Modeling the motivational component requires recognition of additional control factors besides learning. Here I discuss how mesocorticolimbic mechanisms generate the motivation component of incentive salience. Incentive salience takes Pavlovian learning and memory as one input and as an equally important input takes neurobiological state factors (e.g. drug states, appetite states, satiety states) that can vary independently of learning. Neurobiological state changes can produce unlearned fluctuations or even reversals in the ability of a previously learned reward cue to trigger motivation. Such fluctuations in cue-triggered motivation can dramatically depart from all previously learned values about the associated reward outcome. Thus, one consequence of the difference between incentive salience and learning can be to decouple cue-triggered motivation of the moment from previously learned values of how good the associated reward has been in the past. Another consequence can be to produce irrationally strong motivation urges that are not justified by any memories of previous reward values (and without distorting associative predictions of future reward value). Such irrationally strong motivation may be especially problematic in addiction. To understand these phenomena, future models of mesocorticolimbic reward function should address the neurobiological state factors that participate to control generation of incentive salience.},
author = {Berridge, Kent C.},
doi = {10.1111/j.1460-9568.2012.07990.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berridge - 2012 - From prediction error to incentive salience mesolimbic computation of reward motivation.pdf:pdf},
isbn = {0953-816X},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Dopamine,Incentive salience,Learning,Mesolimbic,Nucleus accumbens,Prediction error},
month = {apr},
number = {7},
pages = {1124--1143},
pmid = {22487042},
publisher = {Blackwell Publishing Ltd},
title = {{From prediction error to incentive salience: Mesolimbic computation of reward motivation}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2012.07990.x},
volume = {35},
year = {2012}
}
@article{Ikemoto2007a,
abstract = {Anatomical and functional refinements of the meso-limbic dopamine system of the rat are discussed. Present experiments suggest that dopaminergic neurons localized in the posteromedial ventral tegmental area (VTA) and central linear nucleus raphe selectively project to the ventromedial striatum (medial olfactory tubercle and medial nucleus accumbens shell), whereas the anteromedial VTA has few if any projections to the ventral striatum, and the lateral VTA largely projects to the ventrolateral striatum (accumbens core, lateral shell and lateral tubercle). These findings complement the recent behavioral findings that cocaine and amphetamine are more rewarding when administered into the ventromedial striatum than into the ventrolateral striatum. Drugs such as nicotine and opiates are more rewarding when administered into the posterior VTA or the central linear nucleus than into the anterior VTA. A review of the literature suggests that (1) the midbrain has corresponding zones for the accumbens core and medial shell; (2) the striatal portion of the olfactory tubercle is a ventral extension of the nucleus accumbens shell; and (3) a model of two dopamine projection systems from the ventral midbrain to the ventral striatum is useful for understanding reward function. The medial projection system is important in the regulation of arousal characterized by affect and drive and plays a different role in goal-directed learning than the lateral projection system, as described in the variation-selection hypothesis of striatal functional organization.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ikemoto, Satoshi},
doi = {10.1016/j.brainresrev.2007.05.004},
eprint = {NIHMS150003},
isbn = {0165-0173},
issn = {01650173},
journal = {Brain Research Reviews},
keywords = {Arousal,Autoshaping,Caudal linear nucleus,Reinforcement,Ventral striatum,Ventral tegmental area},
month = {nov},
number = {1},
pages = {27--78},
pmid = {17574681},
title = {{Dopamine reward circuitry: Two projection systems from the ventral midbrain to the nucleus accumbens-olfactory tubercle complex}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17574681 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2134972 http://linkinghub.elsevier.com/retrieve/pii/S0165017307000756},
volume = {56},
year = {2007}
}
@article{Ito2008,
abstract = {The nucleus accumbens (NAc) has been implicated in a variety of associative processes that are dependent on the integrity of the amygdala and hippocampus (HPC). However, the extent to which the two subregions of the NAc, the core and shell, form differentiated circuits within the amygdala- and hippocampal-ventral striatal circuitry remains unclear. The present study investigated the effects of selective excitotoxic lesions of the nucleus accumbens shell or core subregion on appetitive elemental cue and context conditioning, shown previously to be dependent on the basolateral amygdala and hippocampus, respectively. Rats were trained sequentially to acquire discrete conditioned stimulus-sucrose conditioning, followed by spatial context-sucrose conditioning in a place preference apparatus characterized by three topographically identical chambers, the chambers being discriminable only on the basis of path integration. NAc shell lesions selectively impaired the acquisition of conditioned place preference and the use of spatial information to retrieve information about a discrete cue, whereas, as expected, NAc core lesions attenuated the acquisition of cue conditioning compared with sham rats. In a subsequent experiment, disconnection of the HPC from the NAc shell using unilateral asymmetric lesions of each structure resulted in a pattern of impairment in place conditioning and context-dependent cue retrieval similar to that produced by NAc shell lesions. These data not only suggest that the NAc core and shell subregions subserve distinct associative processes but also that the NAc shell and HPC are important functional components of a limbic corticostriatal network involved in spatial context conditioning.},
author = {Ito, R. and Robbins, T. W. and Pennartz, C. M. and Everitt, B. J.},
doi = {10.1523/JNEUROSCI.1615-08.2008},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ito et al. - 2008 - Functional interaction between the hippocampus and nucleus accumbens shell is necessary for the acquisition of appet.pdf:pdf},
isbn = {1529-2401 (Electronic)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jul},
number = {27},
pages = {6950--6959},
pmid = {18596169},
publisher = {Society for Neuroscience},
title = {{Functional Interaction between the Hippocampus and Nucleus Accumbens Shell Is Necessary for the Acquisition of Appetitive Spatial Context Conditioning}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1615-08.2008},
volume = {28},
year = {2008}
}
@article{Peters2008,
abstract = {The rat prelimbic prefrontal cortex and nucleus accumbens core are critical for initiating cocaine seeking. In contrast, the neural circuitry responsible for inhibiting cocaine seeking during extinction is unknown. The present findings using inhibition of selected brain nuclei with GABA agonists show that the suppression of cocaine seeking produced by previous extinction training required activity in the rat infralimbic cortex. Conversely, the reinstatement of drug seeking by a cocaine injection in extinguished animals was suppressed by increasing neuronal activity in infralimbic cortex with the glutamate agonist AMPA. The cocaine seeking induced by inactivating infralimbic cortex resembled other forms of reinstated drug seeking by depending on activity in prelimbic cortex and the basolateral amygdala. A primary efferent projection from the infralimbic cortex is to the nucleus accumbens shell. Akin to infralimbic cortex, inhibition of the accumbens shell induced cocaine seeking in extinguished rats. However, bilateral inhibition of the shell also elicited increased locomotor activity. Nonetheless, unilateral inhibition of the accumbens shell did not increase motor activity, and simultaneous unilateral inactivation of the infralimbic cortex and shell induced cocaine seeking, suggesting that an interaction between these two structures is necessary for extinction training to inhibit cocaine seeking. The infralimbic cortex and accumbens shell appear to be recruited by extinction learning because inactivation of these structures before extinction training did not alter cocaine seeking. Together, these findings suggest that a neuronal network involving the infralimbic cortex and accumbens shell is recruited by extinction training to suppress cocaine seeking.},
author = {Peters, J. and LaLumiere, R. T. and Kalivas, P. W.},
doi = {10.1523/JNEUROSCI.1045-08.2008},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jun},
number = {23},
pages = {6046--6053},
pmid = {18524910},
publisher = {Society for Neuroscience},
title = {{Infralimbic Prefrontal Cortex Is Responsible for Inhibiting Cocaine Seeking in Extinguished Rats}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1045-08.2008},
volume = {28},
year = {2008}
}
@article{Jog1999,
abstract = {Memories for habits and skills ("implicit or procedural memory") and memories for facts ("explicit or episodic memory") are built up in different brain systems and are vulnerable to different neurodegenerative disorders in humans. So that the striatum-based mechanisms underlying habit formation could be studied, chronic recordings from ensembles of striatal neurons were made with multiple tetrodes as rats learned a T-maze procedural task. Large and widely distributed changes in the neuronal activity patterns occurred in the sensorimotor striatum during behavioral acquisition, culminating in task-related activity emphasizing the beginning and end of the automatized procedure. The new ensemble patterns remained stable during weeks of subsequent performance of the same task. These results suggest that the encoding of action in the sensorimotor striatum undergoes dynamic reorganization as habit learning proceeds.},
author = {Jog, Mandar S. and Kubota, Yasuo and Connolly, Christopher I. and Graybiel, Ann M.},
doi = {10.1126/science.286.5445.1745},
isbn = {0036-8075},
issn = {00368075},
journal = {Science},
month = {nov},
number = {5445},
pages = {1745--1749},
pmid = {10576743},
publisher = {American Association for the Advancement of Science},
title = {{Building neural representations of habits}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10576743 http://www.sciencemag.org/cgi/doi/10.1126/science.286.5445.1745},
volume = {286},
year = {1999}
}
@article{Niv2007,
abstract = {RATIONALE: Dopamine neurotransmission has long been known to exert a powerful influence over the vigor, strength, or rate of responding. However, there exists no clear understanding of the computational foundation for this effect; predominant accounts of dopamine's computational function focus on a role for phasic dopamine in controlling the discrete selection between different actions and have nothing to say about response vigor or indeed the free-operant tasks in which it is typically measured. OBJECTIVES: We seek to accommodate free-operant behavioral tasks within the realm of models of optimal control and thereby capture how dopaminergic and motivational manipulations affect response vigor. METHODS: We construct an average reward reinforcement learning model in which subjects choose both which action to perform and also the latency with which to perform it. Optimal control balances the costs of acting quickly against the benefits of getting reward earlier and thereby chooses a best response latency. RESULTS: In this framework, the long-run average rate of reward plays a key role as an opportunity cost and mediates motivational influences on rates and vigor of responding. We review evidence suggesting that the average reward rate is reported by tonic levels of dopamine putatively in the nucleus accumbens. CONCLUSIONS: Our extension of reinforcement learning models to free-operant tasks unites psychologically and computationally inspired ideas about the role of tonic dopamine in striatum, explaining from a normative point of view why higher levels of dopamine might be associated with more vigorous responding.},
author = {Niv, Yael and Daw, Nathaniel D. and Joel, Daphna and Dayan, Peter},
doi = {10.1007/s00213-006-0502-4},
isbn = {0033-3158},
issn = {00333158},
journal = {Psychopharmacology},
keywords = {Dopamine,Energizing,Free operant,Motivation,Reinforcement learning,Response rate},
month = {mar},
number = {3},
pages = {507--520},
pmid = {17031711},
title = {{Tonic dopamine: Opportunity costs and the control of response vigor}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17031711 http://link.springer.com/10.1007/s00213-006-0502-4},
volume = {191},
year = {2007}
}
@article{Markou2013,
abstract = {The present review article summarizes and expands upon the discussions that were initiated during a meeting of the Cognitive Neuroscience Treatment Research to Improve Cognition in Schizophrenia (CNTRICS; http://cntrics.ucdavis.edu) meeting. A major goal of the CNTRICS meeting was to identify experimental procedures and measures that can be used in laboratory animals to assess psychological constructs that are related to the psychopathology of schizophrenia. The issues discussed in this review reflect the deliberations of the Motivation Working Group of the CNTRICS meeting, which included most of the authors of this article as well as additional participants. After receiving task nominations from the general research community, this working group was asked to identify experimental procedures in laboratory animals that can assess aspects of reinforcement learning and motivation that may be relevant for research on the negative symptoms of schizophrenia, as well as other disorders characterized by deficits in reinforcement learning and motivation. The tasks described here that assess reinforcement learning are the Autoshaping Task, Probabilistic Reward Learning Tasks, and the Response Bias Probabilistic Reward Task. The tasks described here that assess motivation are Outcome Devaluation and Contingency Degradation Tasks and Effort-Based Tasks. In addition to describing such methods and procedures, the present article provides a working vocabulary for research and theory in this field, as well as an industry perspective about how such tasks may be used in drug discovery. It is hoped that this review can aid investigators who are conducting research in this complex area, promote translational studies by highlighting shared research goals and fostering a common vocabulary across basic and clinical fields, and facilitate the development of medications for the treatment of symptoms mediated by reinforcement learning and motivational deficits. {\textcopyright} 2013 Elsevier Ltd.},
author = {Markou, Athina and Salamone, John D. and Bussey, Timothy J. and Mar, Adam C. and Brunner, Daniela and Gilmour, Gary and Balsam, Peter},
doi = {10.1016/j.neubiorev.2013.08.007},
isbn = {1873-7528 (Electronic)$\backslash$r0149-7634 (Linking)},
issn = {01497634},
journal = {Neuroscience and Biobehavioral Reviews},
keywords = {Cognition,Learning,Motivation,Reinforcement,Reward},
month = {nov},
number = {9},
pages = {2149--2165},
pmid = {23994273},
publisher = {Pergamon},
title = {{Measuring reinforcement learning and motivation constructs in experimental animals: Relevance to the negative symptoms of schizophrenia}},
url = {https://www.sciencedirect.com/science/article/pii/S0149763413001978},
volume = {37},
year = {2013}
}
@article{Weiner1996,
abstract = {Latent inhibition (LI) consists of retardation in conditioning to a stimulus as a consequence of its prior non-reinforced preexposure. In view of findings that LI is disrupted in acute schizophrenic patients and evidence from animal experiments pointing to the involvement of the mesolimbic dopamine (DA) system in this phenomenon, the present study investigated the effects of electrolytic lesions to the shell and core subterritories of the nucleus accumbens on LI in rats (Expt. 1). LI was indexed by the amount of suppression of drinking in the presence of a tone that was either pre-exposed or not prior to its pairing with reinforcement (a foot shock). Expt. 2 tested the effects of the DA antagonist, haloperidol, on LI in shell- and core-lesioned animals. Expt. 3 tested the effects of shell and core lesions on spontaneous and amphetamine-induced locomotion. In Expt. 1, LI, i.e., lower suppression of drinking in the pre-exposed as compared to the non-pre-exposed animals, was obtained in the sham-operated condition. Core and shell lesions produced distinct effects on LI. Animals with core lesions developed LI, but exhibited an overall lower suppression of drinking in comparison to the sham-operated animals. In contrast, shell lesions led to a disappearance of LI. Expt. 2 replicated the differential effects of shell and core lesions on LI, although in this experiment, core lesion did not attenuate suppression of drinking. Haloperidol prevented shell-induced abolition of LI. In Expt. 3, shell- but not core-lesioned animals were more active than sham controls following amphetamine administration. These results provide evidence for functional differences between the shell and core subregions, as well as for the involvement of the mesolimbic DA system in LI.},
author = {Weiner, I. and Gal, G. and Rawlins, J. N.P. and Feldon, J.},
doi = {10.1016/S0166-4328(96)00051-4},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weiner et al. - 1996 - Differential involvement of the shell and core subterritories of the nucleus accumbens in latent inhibition and a.pdf:pdf},
isbn = {0166-4328 (Print)$\backslash$r0166-4328 (Linking)},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {activity,core,latent inhibition,nucleus accumbens,rat,shell},
month = {nov},
number = {1-2},
pages = {123--133},
pmid = {8950008},
publisher = {Society for Neuroscience},
title = {{Differential involvement of the shell and core subterritories of the nucleus accumbens in latent inhibition and amphetamine-induced activity}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8950008},
volume = {81},
year = {1996}
}
@article{Saddoris2011,
abstract = {During Pavlovian-to-instrumental transfer (PIT), learned Pavlovian cues significantly modulate ongoing instrumental actions. This phenomenon is suggested as a mechanism under which conditioned stimuli may lead to relapse in addicted populations. Following discriminative Pavlovian learning and instrumental conditioning with sucrose, one group of rats (naive) underwent electrophysiological recordings in the nucleus accumbens core and shell during a single PIT session. Other groups, following Pavlovian and instrumental conditioning, were subsequently trained to self-administer cocaine with nosepoke responses, or received yoked saline infusions and nosepoked for water rewards, and then performed PIT while electrophysiological recordings were taken in the nucleus accumbens. Behaviorally, although both naive and saline-treated groups showed increases in lever pressing during the conditioned stimulus cue, this effect was significantly enhanced in the cocaine-treated group. Neurons in the core and shell tracked these behavioral changes. In control animals, core neurons were significantly more likely to encode general information about cues, rewards and responses than those in the shell, and positively correlated with behavioral PIT performance, whereas PIT-specific encoding in the shell, but not core, tracked PIT performance. In contrast, following cocaine exposure, there was a significant increase in neural encoding of all task-relevant events that was selective to the shell. Given that cocaine exposure enhanced both behavior and shell-specific task encoding, these findings suggest that, whereas the core is important for acquiring the information about cues and response contingencies, the shell is important for using this information to guide and modulate behavior and is specifically affected following a history of cocaine self-administration.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Saddoris, Michael P. and Stamatakis, Alice and Carelli, Regina M.},
doi = {10.1111/j.1460-9568.2011.07683.x},
eprint = {NIHMS150003},
isbn = {1460-9568},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Electrophysiology,Natural reward,Operant,Rat,Striatum,Sucrose},
month = {jun},
number = {12},
pages = {2274--2287},
pmid = {21507084},
publisher = {Blackwell Publishing Ltd},
title = {{Neural correlates of Pavlovian-to-instrumental transfer in the nucleus accumbens shell are selectively potentiated following cocaine self-administration}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2011.07683.x},
volume = {33},
year = {2011}
}
@article{Takahashi2016a,
abstract = {Dopamine neurons signal reward prediction errors. This requires accurate reward predictions. It has been suggested that the ventral striatum provides these predictions. Here we tested this hypothesis by recording from putative dopamine neurons in the VTA of rats performing a task in which prediction errors were induced by shifting reward timing or number. In controls, the neurons exhibited error signals in response to both manipulations. However, dopamine neurons in rats with ipsilateral ventral striatal lesions exhibited errors only to changes in number and failed to respond to changes in timing of reward. These results, supported by computational modeling, indicate that predictions about the temporal specificity and the number of expected reward are dissociable and that dopaminergic prediction-error signals rely on the ventral striatum for the former but not the latter.},
author = {Takahashi, Yuji K. and Langdon, Angela J. and Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1016/j.neuron.2016.05.015},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
month = {jul},
number = {1},
pages = {182--193},
pmid = {27292535},
title = {{Temporal Specificity of Reward Prediction Errors Signaled by Putative Dopamine Neurons in Rat VTA Depends on Ventral Striatum}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27292535 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4938771 http://linkinghub.elsevier.com/retrieve/pii/S0896627316301751},
volume = {91},
year = {2016}
}
@article{McDannald2011,
abstract = {In many cases, learning is thought to be driven by differences between the value of rewards we expect and rewards we actually receive. Yet learning can also occur when the identity of the reward we receive is not as expected, even if its value remains unchanged. Learning from changes in reward identity implies access to an internal model of the environment, from which information about the identity of the expected reward can be derived. As a result, such learning is not easily accounted for by model-free reinforcement learning theories such as temporal difference reinforcement learning (TDRL), which predicate learning on changes in reward value, but not identity. Here, we used unblocking procedures to assess learning driven by value- versus identity-based prediction errors. Rats were trained to associate distinct visual cues with different food quantities and identities. These cues were subsequently presented in compound with novel auditory cues and the reward quantity or identity was selectively changed. Unblocking was assessed by presenting the auditory cues alone in a probe test. Consistent with neural implementations of TDRL models, we found that the ventral striatum was necessary for learning in response to changes in reward value. However, this area, along with orbitofrontal cortex, was also required for learning driven by changes in reward identity. This observation requires that existing models of TDRL in the ventral striatum be modified to include information about the specific features of expected outcomes derived from model-based representations, and that the role of orbitofrontal cortex in these models be clearly delineated.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {McDannald, M. A. and Lucantonio, F. and Burke, K. A. and Niv, Y. and Schoenbaum, G.},
doi = {10.1523/JNEUROSCI.5499-10.2011},
eprint = {NIHMS150003},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {feb},
number = {7},
pages = {2700--2705},
pmid = {21325538},
title = {{Ventral Striatum and Orbitofrontal Cortex Are Both Required for Model-Based, But Not Model-Free, Reinforcement Learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21325538 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3079289 http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5499-10.2011},
volume = {31},
year = {2011}
}
@article{VanderMeer2010,
abstract = {Decision-making studies across different domains suggest that decisions can arise from multiple, parallel systems in the brain: a flexible system utilizing action-outcome expectancies and a more rigid system based on situation-action associations. The hippocampus, ventral striatum, and dorsal striatum make unique contributions to each system, but how information processing in each of these structures supports these systems is unknown. Recent work has shown covert representations of future paths in hippocampus and of future rewards in ventral striatum. We developed analyses in order to use a comparative methodology and apply the same analyses to all three structures. Covert representations of future paths and reward were both absent from the dorsal striatum. In contrast, dorsal striatum slowly developed situation representations that selectively represented action-rich parts of the task. This triple dissociation suggests that the different roles these structures play are due to differences in information-processing mechanisms. {\textcopyright} 2010 Elsevier Inc.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {van der Meer, Matthijs A A and Johnson, Adam and Schmitzer-Torbert, Neil C. and Redish, A. David},
doi = {10.1016/j.neuron.2010.06.023},
eprint = {NIHMS150003},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
month = {jul},
number = {1},
pages = {25--32},
pmid = {20624589},
title = {{Triple dissociation of information processing in dorsal striatum, ventral striatum, and hippocampus on a learned spatial decision task}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627310005076},
volume = {67},
year = {2010}
}
@article{Schultz1993,
abstract = {The present investigation had two aims: (1) to study responses of dopamine neurons to stimuli with attentional and motivational significance during several steps of learning a behavioral task, and (2) to study the activity of dopamine neurons during the performance of cognitive tasks known to be impaired after lesions of these neurons. Monkeys that had previously learned a simple reaction time task were trained to perform a spatial delayed response task via two intermediate tasks. During the learning of each new task, a total of 25{\%} of 76 dopamine neurons showed phasic responses to the delivery of primary liquid reward, whereas only 9{\%} of 163 neurons responded to this event once task performance was established. This produced an average population response during but not after learning of each task. Reward responses during learning were significantly more numerous and pronounced in area A10, as compared to areas A8 and A9. Dopamine neurons also showed phasic responses to the two conditioned stimuli. These were the instruction cue, which was the first stimulus in each trial and indicated the target of the upcoming arm movement (58{\%} of 76 neurons during and 44{\%} of 163 neurons after learning), and the trigger stimulus, which was a conditioned incentive stimulus predicting reward and eliciting a saccadic eye movement and an arm reaching movement (38{\%} of neurons during and 40{\%} after learning). None of the dopamine neurons showed sustained activity in the delay between the instruction and trigger stimuli that would resemble the activity of neurons in dopamine terminal areas, such as the striatum and frontal cortex. Thus, dopamine neurons respond phasically to alerting external stimuli with behavioral significance whose detection is crucial for learning and performing delayed response tasks. The lack of sustained activity suggests that dopamine neurons do not encode representational processes, such as working memory, expectation of external stimuli or reward, or preparation of movement. Rather, dopamine neurons are involved with transient changes of impulse activity in basic attentional and motivational processes underlying learning and cognitive behavior.},
author = {Schultz, W and Apicella, P and Ljungberg, T},
doi = {8441015},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schultz, Apicella, Ljungbergb - 1993 - Responses of Monkey Dopamine Neurons to Reward and Conditioned Stimuli during Successive Steps of.pdf:pdf},
isbn = {0270-6474},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
number = {3},
pages = {900--13},
pmid = {8441015},
title = {{Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8441015},
volume = {13},
year = {1993}
}
@article{Chau2015,
abstract = {Recent studies have challenged the view that orbitofrontal cortex (OFC) and amygdala mediate flexible reward-guided behavior. We trained macaques to perform an object discrimination reversal task during fMRI sessions and identified a lateral OFC (lOFC) region in which activity predicted adaptive win-stay/lose-shift behavior. Amygdala and lOFC activity was more strongly coupled on lose-shift trials. However, lOFC-amygdala coupling was also modulated by the relevance of reward information in a manner consistent with a role in establishing how credit for reward should be assigned. Day-to-day fluctuations in signals and signal coupling were correlated with day-to-day fluctuation in performance. A second experiment confirmed the existence of signals for adaptive stay/shift behavior in lOFC and reflecting irrelevant reward in the amygdala in a probabilistic learning task. Our data demonstrate that OFC and amygdala each make unique contributions to flexible behavior and credit assignment.},
author = {Chau, Bolton K H and Sallet, J{\'{e}}r{\^{o}}me and Papageorgiou, Georgios K. and Noonan, Mary Ann P and Bell, Andrew H. and Walton, Mark E. and Rushworth, Matthew F S},
doi = {10.1016/j.neuron.2015.08.018},
isbn = {0896-6273},
issn = {10974199},
journal = {Neuron},
month = {sep},
number = {5},
pages = {1106--1118},
pmid = {26335649},
publisher = {Cell Press},
title = {{Contrasting Roles for Orbitofrontal Cortex and Amygdala in Credit Assignment and Learning in Macaques}},
url = {https://www.sciencedirect.com/science/article/pii/S0896627315007126},
volume = {87},
year = {2015}
}
@article{Khamassi2008,
abstract = {It has been proposed that the striatum plays a crucial role in learning to select appropriate actions, optimizing rewards according to the principles of 'Actor-Critic' models of trial-and-error learning. The ventral striatum (VS), as Critic, would employ a temporal difference (TD) learning algorithm to predict rewards and drive dopaminergic neurons. This study examined this model's adequacy for VS responses to multiple rewards in rats. The respective arms of a plus-maze provided rewards of varying magnitudes; multiple rewards were provided at 1-s intervals while the rat stood still. Neurons discharged phasically prior to each reward, during both initial approach and immobile waiting, demonstrating that this signal is predictive and not simply motor-related. In different neurons, responses could be greater for early, middle or late droplets in the sequence. Strikingly, this activity often reappeared after the final reward, as if in anticipation of yet another. In contrast, previous TD learning models show decremental reward-prediction profiles during reward consumption due to a temporal-order signal introduced to reproduce accurate timing in dopaminergic reward-prediction error signals. To resolve this inconsistency in a biologically plausible manner, we adapted the TD learning model such that input information is nonhomogeneously distributed among different neurons. By suppressing reward temporal-order signals and varying richness of spatial and visual input information, the model reproduced the experimental data. This validates the feasibility of a TD-learning architecture where different groups of neurons participate in solving the task based on varied input information.},
author = {Khamassi, Mehdi and Mulder, Antonius B. and Tabuchi, Eiichi and Douchamps, Vincent and Wiener, Sidney I.},
doi = {10.1111/j.1460-9568.2008.06480.x},
isbn = {1460-9568 (Electronic)$\backslash$r0953-816X (Linking)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Accumbens,Actor-Critic,Reinforcement learning,Striatum,TD learning},
month = {nov},
number = {9},
pages = {1849--1866},
pmid = {18973599},
publisher = {Blackwell Publishing Ltd},
title = {{Anticipatory reward signals in ventral striatal neurons of behaving rats}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2008.06480.x},
volume = {28},
year = {2008}
}
@article{Kaczkurkin2013,
abstract = {Generalization of conditioned fear refers to the transfer of the conditioned fear response to stimuli that resemble the original conditioned stimulus. Overgeneralization of conditioned fear has been associated with panic disorder and generalized anxiety disorder and may be relevant to obsessive-compulsive (OC) symptoms as well. This study represents the first attempt to determine the degree to which individuals with high versus low OC traits over generalize conditioned fear. We hypothesized that the high OC individuals, particularly those characterized by overestimation of threat, would show overgeneralization of conditioned fear compared to controls as measured by behavioral and psychophysiological (fear-potentiated startle) measures. The results of this study show an interaction between the high and low Threat Estimation groups as measured by the Obsessive Beliefs Questionnaire, which suggests that those who have a tendency to overestimate threat show overgeneralization of conditioned fear. This finding suggests that the relation between OC symptoms and overgeneralization of conditioned fear may be specific to the high threat estimation component of OC symptoms.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {{Shmuel Lissek}, Antonia N Kaczkurkin},
doi = {10.4172/2161-0487.S7-003},
eprint = {NIHMS150003},
isbn = {2122633255},
issn = {21610487},
journal = {Journal of Psychology {\&} Psychotherapy},
keywords = {Fear conditioning,Fear-potentiated startle,Generalization,Obsessive-compulsive disorder},
pages = {3},
pmid = {1000000221},
publisher = {NIH Public Access},
title = {{Generalization of Conditioned Fear and Obsessive-Compulsive Traits}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24567864 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3932061 https://www.omicsonline.org/generalization-of-conditioned-fear-and-obsessive-compulsive-traits-2161-0487.S7-003.php?aid=17795},
volume = {7},
year = {2013}
}
@misc{VanDerMeer2010,
abstract = {Decisions can arise in different ways, such as from a gut feeling, doing what worked last time, or planful deliberation. Different decision-making systems are dissociable behaviorally, map onto distinct brain systems, and have different computational demands. For instance, "model-free" decision strategies use prediction errors to estimate scalar action values from previous experience, while "model-based" strategies leverage internal forward models to generate and evaluate potentially rich outcome expectancies. Animal learning studies indicate that expectancies may arise from different sources, including not only forward models but also Pavlovian associations, and the flexibility with which such representations impact behavior may depend on how they are generated. In the light of these considerations, we review the results of van der Meer and Redish (2009a), who found that ventral striatal neurons that respond to reward delivery can also be activated at other points, notably at a decision point where hippocampal forward representations were also observed. These data suggest the possibility that ventral striatal reward representations contribute to model-based expectancies used in deliberative decision making.},
author = {{Van der Meer}, Matthijs A.A. and Redish, A. David},
booktitle = {Frontiers in Neuroscience},
doi = {10.3389/neuro.01.006.2010},
isbn = {1662-453X (Electronic)$\backslash$r1662-453X (Linking)},
issn = {16624548},
keywords = {Actor-critic,Pavlovian-instrumental transfer,Planning,Reinforcement learning,Reward},
number = {MAY},
pages = {29--37},
pmid = {21221409},
title = {{Expectancies in decision making, reinforcement learning, and ventral striatum}},
url = {http://www.frontiersin.org/Journal/Abstract.aspx?f=55{\&}name=neuroscience{\&}ART{\_}DOI=10.3389/neuro.01.006.2010},
volume = {4},
year = {2010}
}
@article{Roesch2009a,
abstract = {The ventral striatum (VS) is thought to serve as a gateway whereby associative information from the amygdala and prefrontal regions can influence motor output to guide behavior. If VS mediates this "limbic-motor" interface, then one might expect neural correlates in VS to reflect this information. Specifically, neural activity should reflect the integration of motivational value with subsequent behavior. To test this prediction, we recorded from single units in VS while rats performed a choice task in which different odor cues indicated that reward was available on the left or on the right. The value of reward associated with a left or rightward movement was manipulated in separate blocks of trials by either varying the delay preceding reward delivery or by changing reward size. Rats' behavior was influenced by the value of the expected reward and the response required to obtain it, and activity in the majority of cue-responsive VS neurons reflected the integration of these two variables. Unlike similar cue-evoked activity reported previously in dopamine neurons, these correlates were only observed if the directional response was subsequently executed. Furthermore, activity was correlated with the speed at which the rats' executed the response. These results are consistent with the notion that VS serves to integrate information about the value of an expected reward with motor output during decision making.},
author = {Roesch, M. R. and Singh, T. and Brown, P. L. and Mullins, S. E. and Schoenbaum, G.},
doi = {10.1523/JNEUROSCI.2572-09.2009},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {oct},
number = {42},
pages = {13365--13376},
pmid = {19846724},
publisher = {Society for Neuroscience},
title = {{Ventral Striatal Neurons Encode the Value of the Chosen Action in Rats Deciding between Differently Delayed or Sized Rewards}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2572-09.2009},
volume = {29},
year = {2009}
}
@article{Tabuchi2000,
abstract = {To understand how hippocampal signals are processed by downstream neurons, we analyzed the relative timing between neuronal discharges in simultaneous recordings in the hippocampus and nucleus accumbens of rats performing in a plus maze. In all, 154 pairs of cells (composed of 65 hippocampal and 56 accumbens neurons) were examined during the 1 s period prior to reward delivery. Cross-correlation analyses over a +/- 300-ms window with 10-ms bins revealed that 108 pairs had at least one significant histogram bin (P {\textless} 0.01). The most frequently occurring peaks of hippocampal firing prior to accumbens discharges appeared at latencies from -30-0 ms, corresponding to published values of the latency of the hippocampal pathway to the nucleus accumbens. Other peaks appeared most often at latencies multiples of about 110 ms prior to and after this, corresponding to theta rhythmicity. Since firing synchronization can result from several types of connectivity patterns (such as common inputs), a group of 18 hippocampus-accumbens pairs was selected as those most likely to have monosynaptic connections. The criterion was the presence of at least one highly significant peak (P {\textless} 0.001) at latencies corresponding to field potentials evoked in the accumbens by hippocampal stimulation. A significant peak occurred on all four maze arms for only one of these cell pairs, indicating positional modulation for the others. In addition, behavior dependence of the synchrony between these nucleus accumbens and hippocampus neurons was examined by studying data in relation to three different synchronization points: reward box arrival, box departure, and arrival at the center of the maze. This indicates that the functional connectivity between hippocampal and accumbens neurons was stronger when the rat was near reward areas. Ten of the hippocampal neurons in these 18 cell pairs showed 9-Hz (theta) rhythmic activity in autocorrelation analyses. Of these 10 cells, cross-correlograms from eight hippocampal-accumbens pairs also showed theta rhythmicity. Overall, these results indicate that the synchrony between hippocampus and nucleus accumbens neurons is modulated by spatial position and behavior, and theta rhythm may play an important role for this synchronization.},
author = {Tabuchi, E. T. and Mulder, A. B. and Wiener, S. I.},
doi = {10.1002/1098-1063(2000)10:6<717::AID-HIPO1009>3.0.CO;2-3},
isbn = {1050-9631 (Print)},
issn = {10509631},
journal = {Hippocampus},
keywords = {Basal ganglia,Brain circuit analysis,Cross-correlations,Limbic},
month = {jan},
number = {6},
pages = {717--728},
pmid = {11153717},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Position and behavioral modulation of synchronization of hippocampal and accumbens neuronal discharges in freely moving rats}},
url = {http://doi.wiley.com/10.1002/1098-1063{\%}282000{\%}2910{\%}3A6{\%}3C717{\%}3A{\%}3AAID-HIPO1009{\%}3E3.0.CO{\%}3B2-3},
volume = {10},
year = {2000}
}
@article{Deserno2015,
abstract = {Dual system theories suggest that behavioral control is parsed be- tween a deliberative “model-based” and a more reflexive “model- free” system. A balance of control exerted by these systems is thought to be related to dopamine neurotransmission. However, in the absence of direct measures of human dopamine, it remains unknown whether this reflects a quantitative relation with dopa- mine either in the striatum or other brain areas. Using a sequential decision task performed during functional magnetic resonance imaging, combined with striatal measures of dopamine using [18F]DOPA positron emission tomography, we show that higher presynaptic ventral striatal dopamine levels were associated with a behavioral bias toward more model-based control. Higher pre- synaptic dopamine in ventral striatum was associated with greater coding of model-based signatures in lateral prefrontal cortex and di- minished coding of model-free prediction errors in ventral striatum. Thus, interindividual variability in ventral striatal presynaptic dopa- mine reflects a balance in the behavioral expression and the neural signatures of model-free and model-based control. Our data provide a novel perspective on how alterations in presynaptic dopamine levels might be accompanied by a disruption of behavioral control as observed in aging or neuropsychiatric diseases such as schizo- phrenia and addiction. dopamine},
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Deserno, Lorenz and Huys, Quentin J. M. and Boehme, Rebecca and Buchert, Ralph and Heinze, Hans-Jochen and Grace, Anthony A. and Dolan, Raymond J. and Heinz, Andreas and Schlagenhauf, Florian},
doi = {10.1073/pnas.1417219112},
eprint = {arXiv:1408.1149},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Deserno et al. - 2015 - Ventral striatal dopamine reflects behavioral and neural signatures of model-based control during sequential dec.pdf:pdf},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {PET,decision making,dopamine,fMRI,reinforcement learning},
month = {feb},
number = {5},
pages = {1595--1600},
pmid = {25605941},
publisher = {National Academy of Sciences},
title = {{Ventral striatal dopamine reflects behavioral and neural signatures of model-based control during sequential decision making}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1417219112},
volume = {112},
year = {2015}
}
@article{Chang2012a,
abstract = {Initially-neutral cues paired with rewards are thought to acquire motivational significance, as if the incentive motivational value of the reward is transferred to the cue. Such cues may serve as secondary reinforcers to establish new learning, modulate the performance of instrumental action (Pavlovian-instrumental transfer, PIT), and be the targets of approach and other cue-directed behaviors. Here we examined the effects of lesions of the ventral striatal nucleus accumbens (ACb) and the basolateral amygdala (BLA) on the acquisition of discriminative autoshaped lever-pressing in rats. Insertion of one lever into the experimental chamber was reinforced by sucrose delivery, but insertion of another lever was not reinforced. Although sucrose was delivered independently of the rats' behavior, sham-lesioned rats rapidly came to press the reinforced but not the nonreinforced lever. Bilateral ACb lesions impaired the initial acquisition of sign-tracking but not its terminal levels. In contrast, BLA lesions produced substantial deficits in terminal levels of sign-tracking. Furthermore, whereas ACb lesions primarily affected the probability of lever press responses, BLA lesions mostly affected the rate of responding once it occurred. Finally, disconnection lesions that disrupted communication between ACb and BLA produced both sets of deficits. We suggest that ACb is important for initial acquisition of consummatory-like responses that incorporate hedonic aspects of the reward, while BLA serves to enhance such incentive salience once it is acquired. {\textcopyright} 2012 Elsevier Inc.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Chang, Stephen E. and Wheeler, Daniel S. and Holland, Peter C.},
doi = {10.1016/j.nlm.2012.03.008},
eprint = {NIHMS150003},
isbn = {1095-9564 (Electronic)$\backslash$r1074-7427 (Linking)},
issn = {10747427},
journal = {Neurobiology of Learning and Memory},
keywords = {Accumbens,Amygdala,Autoshaping,Incentive salience,Sign-tracking},
month = {may},
number = {4},
pages = {441--451},
pmid = {22469749},
title = {{Roles of nucleus accumbens and basolateral amygdala in autoshaped lever pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22469749 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3358568 http://linkinghub.elsevier.com/retrieve/pii/S107474271200038X},
volume = {97},
year = {2012}
}
@article{Floresco2015,
abstract = {Nearly 40 years of research on the function of the nucleus accumbens (NAc) has provided a wealth of information on its contributions to behavior but has also yielded controversies and misconceptions regarding these functions. A primary tenet of this review is that, rather than serving as a “reward” center, the NAc plays a key role in action selection, integrating cognitive and affective information processed by frontal and temporal lobe regions to augment the efficiency and vigor of appetitively or aversively motivated behaviors. Its involvement in these functions is most prominent when the appropriate course of action is ambiguous, uncertain, laden with distractors, or in a state of flux. To this end, different subregions of the NAc play dissociable roles in refining action selection, promoting approach toward motivationally relevant stimuli, suppressing inappropriate actions so that goals may be obtained more efficiently, and encoding action outcomes that guide the direction of subsequent ones.},
author = {Floresco, Stan B.},
doi = {10.1146/annurev-psych-010213-115159},
isbn = {0066-4308},
issn = {0066-4308},
journal = {Annual Review of Psychology},
keywords = {action selection,animal models,dopamine,fMRI,ventral striatum},
month = {jan},
number = {1},
pages = {25--52},
pmid = {25251489},
publisher = { Annual Reviews },
title = {{The Nucleus Accumbens: An Interface Between Cognition, Emotion, and Action}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-psych-010213-115159},
volume = {66},
year = {2015}
}
@article{Berke2009,
abstract = {The striatum and hippocampus are widely held to be components of distinct memory systems that can guide competing behavioral strategies. However, some electrophysiological studies have suggested that neurons in both structures encode spatial information and may therefore make similar contributions to behavior. In rats well trained to perform a win-stay radial maze task, we recorded simultaneously from dorsal hippocampus and from multiple striatal subregions, including both lateral areas implicated in motor responses to cues and medial areas that work cooperatively with hippocampus in cognitive operations. In each brain region, movement through the maze was accompanied by the continuous sequential activation of sets of projection neurons. Hippocampal neurons overwhelmingly were active at a single spatial location (place cells). Striatal projection neurons were active at discrete points within the progression of every trial-especially during choices or following reward delivery-regardless of spatial position. Place-cell-type firing was not observed even for medial striatal cells entrained to the hippocampal theta rhythm. We also examined neural coding in earlier training sessions, when rats made use of spatial working memory to guide choices, and again found that striatal cells did not show place-cell-type firing. Prospective or retrospective encoding of trajectory was not observed in either hippocampus or striatum, at either training stage. Our results indicate that, at least in this task, dorsal hippocampus uses a spatial foundation for information processing that is not substantially modulated by spatial working memory demands. By contrast, striatal cells do not use such a spatial foundation, even in medial subregions that cooperate with hippocampus in the selection of spatial strategies. The progressive dominance of a striatum-dependent strategy does not appear to be accompanied by large changes in striatal or hippocampal single-cell representations, suggesting that the conflict between strategies may be resolved elsewhere.},
author = {Berke, J. D. and Breck, J. T. and Eichenbaum, H.},
doi = {10.1152/jn.91106.2008},
isbn = {0022-3077 (Print) 0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
month = {mar},
number = {3},
pages = {1575--1587},
pmid = {19144741},
publisher = {American Physiological Society},
title = {{Striatal Versus Hippocampal Representations During Win-Stay Maze Performance}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.91106.2008},
volume = {101},
year = {2009}
}
@article{Chang2012,
abstract = {Initially-neutral cues paired with rewards are thought to acquire motivational significance, as if the incentive motivational value of the reward is transferred to the cue. Such cues may serve as secondary reinforcers to establish new learning, modulate the performance of instrumental action (Pavlovian-instrumental transfer, PIT), and be the targets of approach and other cue-directed behaviors. Here we examined the effects of lesions of the ventral striatal nucleus accumbens (ACb) and the basolateral amygdala (BLA) on the acquisition of discriminative autoshaped lever-pressing in rats. Insertion of one lever into the experimental chamber was reinforced by sucrose delivery, but insertion of another lever was not reinforced. Although sucrose was delivered independently of the rats' behavior, sham-lesioned rats rapidly came to press the reinforced but not the nonreinforced lever. Bilateral ACb lesions impaired the initial acquisition of sign-tracking but not its terminal levels. In contrast, BLA lesions produced substantial deficits in terminal levels of sign-tracking. Furthermore, whereas ACb lesions primarily affected the probability of lever press responses, BLA lesions mostly affected the rate of responding once it occurred. Finally, disconnection lesions that disrupted communication between ACb and BLA produced both sets of deficits. We suggest that ACb is important for initial acquisition of consummatory-like responses that incorporate hedonic aspects of the reward, while BLA serves to enhance such incentive salience once it is acquired. {\textcopyright} 2012 Elsevier Inc.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Chang, Stephen E. and Wheeler, Daniel S. and Holland, Peter C.},
doi = {10.1016/j.nlm.2012.03.008},
eprint = {NIHMS150003},
isbn = {1095-9564 (Electronic)$\backslash$r1074-7427 (Linking)},
issn = {10747427},
journal = {Neurobiology of Learning and Memory},
keywords = {Accumbens,Amygdala,Autoshaping,Incentive salience,Sign-tracking},
month = {may},
number = {4},
pages = {441--451},
pmid = {22469749},
title = {{Roles of nucleus accumbens and basolateral amygdala in autoshaped lever pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22469749 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3358568 http://linkinghub.elsevier.com/retrieve/pii/S107474271200038X},
volume = {97},
year = {2012}
}
@article{Strait2015,
abstract = {The ventral striatum (VS), like its cortical afferents, is closely associated with processing of rewards, but the relative contributions of striatal and cortical reward systems remains unclear. Most theories posit distinct roles for these structures, despite their similarities. We compared responses of VS neurons to those of ventromedial prefrontal cortex (vmPFC) Area 14 neurons, recorded in a risky choice task. Five major response patterns observed in vmPFC were also observed in VS: (1) offer value encoding, (2) value difference encoding, (3) preferential encoding of chosen relative to unchosen value, (4) a correlation between residual variance in responses and choices, and (5) prominent encoding of outcomes. We did observe some differences as well; in particular, preferential encoding of the chosen option was stronger and started earlier in VS than in vmPFC. Nonetheless, the close match between vmPFC and VS suggests that cortex and its striatal targets make overlapping contributions to economic choice.},
author = {Strait, Caleb E. and Sleezer, Brianna J. and Hayden, Benjamin Y.},
doi = {10.1371/journal.pbio.1002173},
isbn = {1545-7885 (Electronic)$\backslash$r1544-9173 (Linking)},
issn = {15457885},
journal = {PLoS Biology},
month = {jun},
number = {6},
pages = {1--22},
pmid = {26086735},
publisher = {Public Library of Science},
title = {{Signatures of value comparison in ventral striatum neurons}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26086735 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4472856},
volume = {13},
year = {2015}
}
@article{Koya2009,
abstract = {Learned associations between effects of abused drugs and the drug administration environment are important in drug addiction. Histochemical and electrophysiological studies suggest that these associations are encoded in sparsely distributed nucleus accumbens neurons that are selectively activated by drugs and drug-associated cues. Although correlations have been observed between nucleus accumbens neuronal activity and responsivity to drugs and drug cues, no technique exists for selectively manipulating these activated neurons and establishing their causal role in behavioral effects of drugs and drug cues. Here we describe a new approach, which we term the 'Daun02 inactivation method', that selectively inactivates a minority of neurons previously activated by cocaine in an environment repeatedly paired with cocaine to demonstrate a causal role for these activated neurons in context-specific cocaine-induced psychomotor sensitization in rats. This method provides a new tool for studying the causal roles of selectively activated neurons in behavioral effects of drugs and drug cues and in other learned behaviors.},
author = {Koya, Eisuke and Golden, Sam A. and Harvey, Brandon K. and Guez-Barber, Danielle H. and Berkow, Alexander and Simmons, Danielle E. and Bossert, Jennifer M. and Nair, Sunila G. and Uejima, Jamie L. and Marin, Marcelo T. and Mitchell, Timothy B. and Farquhar, David and Ghosh, Sukhen C. and Mattson, Brandi J. and Hope, Bruce T.},
doi = {10.1038/nn.2364},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {8},
pages = {1069--1073},
pmid = {19620976},
title = {{Targeted disruption of cocaine-activated nucleus accumbens neurons prevents context-specific sensitization}},
volume = {12},
year = {2009}
}
@article{Dejean2017,
abstract = {Affective memories associated with the negative emotional state experienced during opiate withdrawal are central in maintaining drug taking, seeking, and relapse. Nucleus accumbens (NAC) is a key structure for both acute withdrawal and withdrawal memories reactivation, but the NAC neuron coding properties underpinning the expression of these memories remain largely unknown. Here we aimed at deciphering the role of NAC neurons in the encoding and retrieval of opiate withdrawal memory. Chronic single neuron and local field potentials recordings were performed in morphine-dependent rats and placebo controls. Animals were subjected to an unbiased conditioned placed aversion protocol with one compartment (CS+) paired with naloxone-precipitated withdrawal, a second compartment with saline injection (CS-), and a third being neutral (no pairing). After conditioning, animals displayed a typical place aversion for CS+ and developed a preference for CS- characteristic of safety learning. We found that distinct NAC neurons code for CS+ or CS-. Both populations also displayed highly specific oscillatory dynamics, CS+ and CS- neurons, respectively, following 80 Hz (G80) and 60 Hz (G60) local field potential gamma rhythms. Finally, we found that the balance between G60 and G80 rhythms strongly correlated both with the ongoing behavior of the animal and the strength of the conditioning. We demonstrate here that the aversive and preferred environments are underpinned by distinct groups of NAC neurons as well as specific oscillatory dynamics. This suggest that G60/G80 interplay-established through the conditioning process-serves as a robust and versatile mechanism for a fine coding of the environment emotional weight.},
author = {Dejean, Cyril and Sitko, Mathieu and Girardeau, Paul and Bennabi, Amine and Caill{\'{e}}, St{\'{e}}phanie and Cador, Martine and Boraud, Thomas and {Le Moine}, Catherine},
doi = {10.1038/npp.2016.272},
issn = {1740634X},
journal = {Neuropsychopharmacology},
keywords = {Classical conditioning},
month = {apr},
number = {5},
pages = {1157--1168},
pmid = {27922595},
publisher = {Nature Publishing Group},
title = {{Memories of Opiate Withdrawal Emotional States Correlate with Specific Gamma Oscillations in the Nucleus Accumbens}},
url = {http://www.nature.com/doifinder/10.1038/npp.2016.272},
volume = {42},
year = {2017}
}
@article{Joel2002,
abstract = {A large number of computational models of information processing in the basal ganglia have been developed in recent years. Prominent in these are actor-critic models of basal ganglia functioning, which build on the strong resemblance between dopamine neuron activity and the temporal difference prediction error signal in the critic, and between dopamine-dependent long-term synaptic plasticity in the striatum and learning guided by a prediction error signal in the actor. We selectively review several actor-critic models of the basal ganglia with an emphasis on two important aspects: the way in which models of the critic reproduce the temporal dynamics of dopamine firing, and the extent to which models of the actor take into account known basal ganglia anatomy and physiology. To complement the efforts to relate basal ganglia mechanisms to reinforcement learning (RL), we introduce an alternative approach to modeling a critic network, which uses Evolutionary Computation techniques to 'evolve' an optimal RL mechanism, and relate the evolved mechanism to the basic model of the critic. We conclude our discussion of models of the critic by a critical discussion of the anatomical plausibility of implementations of a critic in basal ganglia circuitry, and conclude that such implementations build on assumptions that are inconsistent with the known anatomy of the basal ganglia. We return to the actor component of the actor-critic model, which is usually modeled at the striatal level with very little detail. We describe an alternative model of the basal ganglia which takes into account several important, and previously neglected, anatomical and physiological characteristics of basal ganglia-thalamocortical connectivity and suggests that the basal ganglia performs reinforcement-biased dimensionality reduction of cortical inputs. We further suggest that since such selective encoding may bias the representation at the level of the frontal cortex towards the selection of rewarded plans and actions, the reinforcement-driven dimensionality reduction framework may serve as a basis for basal ganglia actor models. We conclude with a short discussion of the dual role of the dopamine signal in RL and in behavioral switching. Copyright {\textcopyright} 2002 Elsevier Science Ltd.},
author = {Joel, Daphna and Niv, Yael and Ruppin, Eytan},
doi = {10.1016/S0893-6080(02)00047-3},
isbn = {9723640899},
issn = {08936080},
journal = {Neural Networks},
keywords = {Actor-critic,Basal ganglia,Behavioral switching,Dimensionality reduction,Dopamine,Evolutionary computation,Reinforcement learning,Striosomes/patches},
month = {jun},
number = {4-6},
pages = {535--547},
pmid = {12371510},
publisher = {Pergamon},
title = {{Actor-critic models of the basal ganglia: new anatomical and computational perspectives}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608002000473},
volume = {15},
year = {2002}
}
@article{Roitman2005,
abstract = {The nucleus accumbens (NAc) is a key component of the brain's reward pathway, yet little is known of how NAc cells respond to primary rewarding or aversive stimuli. Here, naive rats received brief intraoral infusions of sucrose and quinine paired with cues in a classical conditioning paradigm while the electrophysiological activity of individual NAc neurons was recorded. NAc neurons (102) were typically inhibited by sucrose (39 of 52, 75{\%}) or excited by quinine (30 of 40, 75{\%}) infusions. Changes in firing rate were correlated with the oromotor response to intraoral infusions. Most taste-responsive neurons responded to only one of the stimuli. NAc neurons developed responses to the cues paired with sucrose and quinine. Thus, NAc neurons are innately tuned to rewarding and aversive stimuli and rapidly develop responses to predictive cues. The results indicate that the output of the NAc is very different when rats taste rewarding versus aversive stimuli.},
author = {Roitman, Mitchell F. and Wheeler, Robert A. and Carelli, Regina M.},
doi = {10.1016/j.neuron.2004.12.055},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
month = {feb},
number = {4},
pages = {587--597},
pmid = {15721244},
title = {{Nucleus accumbens neurons are innately tuned for rewarding and aversive taste stimuli, encode their predictors, and are linked to motor output}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627305000681},
volume = {45},
year = {2005}
}
@article{Chang2013,
abstract = {Certain Pavlovian conditioned stimuli (CSs) paired with food unconditioned stimuli (USs) come to elicit approach and even consumption-like behaviors in rats (sign-tracking). We investigated the effects of lesions of the nucleus accumbens core (ACbC) or shell (ACbS) on the acquisition of sign-tracking in a discriminative autoshaping procedure in which presentation of one lever CS was followed by delivery of sucrose, and another was not. Although we previously found that bilateral lesions of the whole ACb disrupted the initial acquisition of sign-tracking, neither ACbC or ACbS lesions affected the rate or percentage of trials in which rats pressed the CS+. In addition, detailed video analysis showed no effect of either lesion on the topography of the sign-tracking conditioned response (CR). These and other results from lesion studies of autoshaping contrast with those from previous sign-tracking experiments that used purely visual cues (Parkinson et al., 2000a,b), suggesting that the neural circuitry involved in assigning incentive value depends upon the nature of the CS. {\textcopyright} 2013 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Chang, Stephen E. and Holland, Peter C.},
doi = {10.1016/j.bbr.2013.07.046},
eprint = {NIHMS150003},
isbn = {1872-7549},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {Autoshaping,Incentive salience,Nucleus accumbens core,Nucleus accumbens shell},
month = {nov},
pages = {36--42},
pmid = {23933141},
title = {{Effects of nucleus accumbens core and shell lesions on autoshaped lever-pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23933141 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3815957 http://linkinghub.elsevier.com/retrieve/pii/S0166432813004580},
volume = {256},
year = {2013}
}
@article{Goldstein2012,
abstract = {The ventral striatum (VS) is thought to signal the predicted value of expected outcomes. However, it is still unclear whether VS can encode value independently from variables often yoked to value such as response direction and latency. Expectations of high value reward are often associated with a particular action and faster latencies. To address this issue we trained rats to perform a task in which the size of the predicted reward was signaled before the instrumental response was instructed. Instrumental directional cues were presented briefly at a variable onset to reduce accuracy and increase reaction time. Rats were more accurate and slower when a large versus small reward was at stake. We found that activity in VS was high during odors that predicted large reward even though reaction times were slower under these conditions. In addition to these effects, we found that activity prior to the reward predicting cue reflected past and predicted reward. These results demonstrate that VS can encode value independent of motor contingencies and that VS's role in goal-directed behavior is not just to increase vigor of specific actions when more is at stake.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Goldstein, B. L. and Barnett, B. R. and Vasquez, G. and Tobia, S. C. and Kashtelyan, V. and Burton, A. C. and Bryden, D. W. and Roesch, M. R.},
doi = {10.1523/JNEUROSCI.5349-11.2012},
eprint = {NIHMS150003},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {feb},
number = {6},
pages = {2027--2036},
pmid = {22323717},
publisher = {Society for Neuroscience},
title = {{Ventral Striatum Encodes Past and Predicted Value Independent of Motor Contingencies}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5349-11.2012},
volume = {32},
year = {2012}
}
@article{Hart2014,
abstract = {Making predictions about the rewards associated with environmental stimuli and updating those predictions through feedback is an essential aspect of adaptive behavior. Theorists have argued that dopamine encodes a reward prediction error (RPE) signal that is used in such a reinforcement learning process. Recent work with fMRI has demonstrated that the BOLD signal in dopaminergic target areas meets both necessary and sufficient conditions of an axiomatic model of the RPE hypothesis. However, there has been no direct evidence that dopamine release itself also meets necessary and sufficient criteria for encoding an RPE signal. Further, the fact that dopamine neurons have low tonic firing rates that yield a limited dynamic range for encoding negative RPEs has led to significant debate about whether positive and negative prediction errors are encoded on a similar scale. To address both of these issues, we used fast-scan cyclic voltammetry to measure reward-evoked dopamine release at carbon fiber electrodes chronically implanted in the nucleus accumbens core of rats trained on a probabilistic decision-making task. We demonstrate that dopamine concentrations transmit a bidirectional RPE signal with symmetrical encoding of positive and negative RPEs. Our findings strengthen the case that changes in dopamine concentration alone are sufficient to encode the full range of RPEs necessary for reinforcement learning.},
author = {Hart, Andrew S and Rutledge, Robb B and Glimcher, Paul W and Phillips, Paul E M},
doi = {10.1523/JNEUROSCI.2489-13.2014},
isbn = {0270-6474},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
month = {jan},
number = {3},
pages = {698--704},
pmid = {24431428},
publisher = {Society for Neuroscience},
title = {{Phasic Dopamine Release in the Rat Nucleus Accumbens Symmetrically Encodes a Reward Prediction Error Term}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24431428 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3891951 http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2489-13.2014},
volume = {34},
year = {2014}
}
@article{Goto2008,
abstract = {The nucleus accumbens regulates goal-directed behaviors by integrating information from limbic structures and the prefrontal cortex. Here, we review recent studies in an attempt to provide an integrated view of the control of information processing in the nucleus accumbens in terms of the regulation of goal-directed behaviors and how disruption of these functions might underlie the pathological states in drug addiction and other psychiatric disorders. We propose a model that could account for the results of several studies investigating limbic-system interactions in the nucleus accumbens and their modulation by dopamine and provide testable hypotheses for how these might relate to the pathophysiology of major psychiatric disorders. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Goto, Yukiori and Grace, Anthony A.},
doi = {10.1016/j.tins.2008.08.002},
eprint = {NIHMS150003},
isbn = {0166-2236 (Print)$\backslash$n0166-2236 (Linking)},
issn = {01662236},
journal = {Trends in Neurosciences},
month = {nov},
number = {11},
pages = {552--558},
pmid = {18786735},
title = {{Limbic and cortical information processing in the nucleus accumbens}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18786735 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2884964 http://linkinghub.elsevier.com/retrieve/pii/S0166223608001884},
volume = {31},
year = {2008}
}
@article{Wyvell2000,
abstract = {Amphetamine microinjection into the nucleus accumbens shell enhanced the ability of a Pavlovian reward cue to trigger increased instrumental performance for sucrose reward in a pure conditioned incentive paradigm. Rats were first trained to press one of two levers to obtain sucrose pellets. They were separately conditioned to associate a Pavlovian cue (30 sec light) with free sucrose pellets. On test days, the rats received bilateral microinjection of intra-accumbens vehicle or amphetamine (0.0, 2.0, 10.0, or 20.0 microgram/0.5 microliter), and lever pressing was tested in the absence of any reinforcement contingency, while the Pavlovian cue alone was freely presented at intervals throughout the session. Amphetamine microinjection selectively potentiated the cue-elicited increase in sucrose-associated lever pressing, although instrumental responding was not reinforced by either sucrose or the cue during the test. Intra-accumbens amphetamine can therefore potentiate cue-triggered incentive motivation for reward in the absence of primary or secondary reinforcement. Using the taste reactivity measure of hedonic impact, it was shown that intra-accumbens amphetamine failed to increase positive hedonic reaction patterns elicited by sucrose (i.e., sucrose "liking") at doses that effectively increase sucrose "wanting." We conclude that nucleus accumbens dopamine specifically mediates the ability of reward cues to trigger "wanting" (incentive salience) for their associated rewards, independent of both hedonic impact and response reinforcement.},
author = {Wyvell, C L and Berridge, K C},
doi = {http://www.jneurosci.org/content/21/19/7831},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wyvell, Berridge - 2000 - Intra-accumbens amphetamine increases the conditioned incentive salience of sucrose reward enhancement of rewa.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {ability,addiction,conditioned stimulus,dopamine,hedonia,incen-,incentive salience,instrumental,learning,limbic,mesolimbic,motivation,palat-,pavlovian,reinforcement,reward,shell,taste reactivity,tive,ventral striatum},
month = {nov},
number = {21},
pages = {8122--8130},
pmid = {11050134},
publisher = {Society for Neuroscience},
title = {{Intra-accumbens amphetamine increases the conditioned incentive salience of sucrose reward: enhancement of reward "wanting" without enhanced "liking" or response reinforcement}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11050134},
volume = {20},
year = {2000}
}
@article{Flint1991,
abstract = {A number of psychiatric phenomena complicate dementia. The author suggests that if we are to understand and manage these noncognitive, neuropsychiatric manifestations, they need to be studied individually rather than in a global fashion. As one example of these phenomena, delusions complicating dementia are reviewed. Nosology, phenomenology, epidemiology, clinical characteristics, treatment, and course are discussed. Ideas for future research are suggested.;},
author = {Flint, A J},
doi = {10.1176/jnp.3.2.121},
issn = {0895-0172},
journal = {The Journal Of Neuropsychiatry And Clinical Neurosciences},
keywords = {Alzheimer Disease/*psychology,Alzheimer Disease/diagnosis,Alzheimer Disease/drug therapy,Antipsychotic Agents/therapeutic use,Delusions/*psychology,Delusions/diagnosis,Delusions/drug therapy,Dementia/*psychology,Dementia/diagnosis,Dementia/drug therapy,Humans,Neuropsychological Tests,Psychiatric Status Rating Scales},
month = {may},
number = {2},
pages = {121--130},
pmid = {1687962},
title = {{Delusions in dementia: a review.}},
url = {http://psychiatryonline.org/doi/abs/10.1176/jnp.3.2.121 http://search.ebscohost.com/login.aspx?direct=true{\&}db=cmedm{\&}AN=1687962{\&}site=ehost-live},
volume = {3},
year = {1991}
}
@article{Carelli2004,
abstract = {An understanding of the neurobiological basis of drug addiction requires examination of real-time (subsecond) cellular and chemical responses in the brain reward system during drug-seeking and drug-taking behavior. Electrophysiological and electrochemical studies in the rodent nucleus accumbens have examined changes in cell firing and rapid dopamine signaling during crucial periods of behavioral responding for drugs, and show the associative nature of those signals. These findings are considered with respect to the functional microcircuitry in the nucleus accumbens that underlies goal-directed behavior and the role of this circuit in drug addiction.},
author = {Carelli, Regina M. and Wightman, R. Mark},
doi = {10.1016/j.conb.2004.10.001},
isbn = {0959-4388 (Print)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {dec},
number = {6},
pages = {763--768},
pmid = {15582381},
publisher = {Elsevier Current Trends},
title = {{Functional microcircuitry in the accumbens underlying drug addiction: Insights from real-time signaling during behavior}},
url = {http://www.sciencedirect.com/science/article/pii/S0959438804001539},
volume = {14},
year = {2004}
}
@article{Mulder2005,
abstract = {To study how hippocampal output signals conveying spatial and other contextual information might be integrated in the nucleus accumbens, tonically active accumbens neurons were recorded in three unrestrained rats as they performed spatial orientation tasks on an elevated round rotatable platform with four identical reward boxes symmetrically placed around the edge. The partially water-deprived rats were required to shuttle either between the pair of reward boxes indicated by beacon cues (lights in the boxes) or between the pair of boxes occupying particular locations in relation to environmental landmark cues. In 43/82 neurons, behaviorally correlated phasic modulations in discharge activity occurred, primarily prior to or after water was provided at the reward boxes. Twenty-two had inhibitory modulation, 12 excitatory, and nine were mixed excitatory and inhibitory. Although tonically active neurons (TANs) have rarely been reported in the rodent, the inhibitory and mixed responses correspond to previously reports in the macaque accumbens of tonically active neurons with activity correlated with reward delivery and, following conditioning, to sensory stimuli associated with rewards. Eighteen of the 43 tonically active accumbens neurons showed spatial selectivity, i.e., behaviorally correlated increases or decreases in firing rate were of different magnitudes at the respective reward boxes. This is the first demonstration that the configuration of environmental sensory cues associated with reward sites are also an effective stimulus for these neurons and that different neurons are selective for different places. These results are consistent with a role for the nucleus accumbens in the initiation of goal-directed displacement behaviors.},
author = {Mulder, A. B. and Shibata, R. and Trullier, O. and Wiener, S. I.},
doi = {10.1007/s00221-004-2135-3},
isbn = {0014-4819 (Print)$\backslash$r0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Basal ganglia,Reward,TANs,Tonically active neurons,Ventral striatum},
month = {may},
number = {1},
pages = {32--43},
pmid = {15654593},
publisher = {Springer-Verlag},
title = {{Spatially selective reward site responses in tonically active neurons of the nucleus accumbens in behaving rats}},
url = {http://link.springer.com/10.1007/s00221-004-2135-3},
volume = {163},
year = {2005}
}
@article{Frank2004,
abstract = {To what extent do we learn from the positive versus negative outcomes of our decisions? The neuromodulator dopamine plays a key role in these reinforcement learning processes. Patients with Parkinson's disease, who have depleted dopamine in the basal ganglia, are impaired in tasks that require learning from trial and error. Here, we show, using two cognitive procedural learning tasks, that Parkinson's patients off medication are better at learning to avoid choices that lead to negative outcomes than they are at learning from positive outcomes. Dopamine medication reverses this bias, making patients more sensitive to positive than negative outcomes. This pattern was predicted by our biologically based computational model of basal ganglia-dopamine interactions in cognition, which has separate pathways for "Go" and "NoGo" responses that are differentially modulated by positive and negative reinforcement.},
author = {Frank, Michael J. and Seeberger, Lauren C and O'Reilly, Randall C.},
doi = {10.1126/science.1102941},
isbn = {1095-9203 (Electronic)$\backslash$n0036-8075 (Linking)},
issn = {00368075},
journal = {Science},
month = {dec},
number = {5703},
pages = {1940--1943},
pmid = {15528409},
title = {{By carrot or by stick: Cognitive reinforcement learning in Parkinsonism}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15528409 http://www.sciencemag.org/cgi/doi/10.1126/science.1102941},
volume = {306},
year = {2004}
}
@article{Bowman1996,
abstract = {1. The results of neuropsychological, neuropharmacological, and neurophysiological experiments have implicated the ventral striatum in reward-related processes. We designed a task to allow us to separate the effects of sensory, motor, and internal signals so that we could study the correlation between the activity of neurons in the ventral striatum and different motivational states. In this task, a visual stimulus was used to cue the monkeys as to their progress toward earning a reward. The monkeys performed more quickly and with fewer mistakes in the rewarded trials. After analyzing the behavioral results from three monkeys, we recorded from 143 neurons from two of the monkeys while they performed the task with either juice or cocaine reward. 2. In this task the monkey was required to release its grip on a bar when a small visual response cue changed colors from red (the wait signal) to green (the go signal). The duration of the wait signal was varied randomly. The cue became blue whenever the monkey successfully responded to the go signal within 1 s of its appearance. A reward was delivered after the monkey successfully completed one, two, or three trials. The schedules were randomly interleaved. A second visual stimulus that progressively brightened or dimmed signaled to the monkeys their progress toward earning a reward. This discriminative cue allowed the monkeys to judge the proportion of work remaining in the current ratio schedule of reinforcement. Data were collected from three monkeys while they performed this task. 3. The average reaction times became faster and error rates declined as the monkeys progressed toward completing the current schedule of reinforcement and thereby earning a reward, whereas the modal reaction time did not change. As the duration of the wait period before the go signal increased, the monkeys reacted more quickly but their error rates scarcely changed. From these results we infer that the effects of motivation and motor readiness in this task are generated by separate mechanisms rather than by a single mechanism subserving generalized arousal. 4. The activity of 138 ventral striatal neurons was sampled in two monkeys while they performed the task to earn juice reward. We saw tonic changes in activity throughout the trials, and we saw phasic activity following the reward. The activity of these neurons was markedly different during juice-rewarded trials than during correctly performed trials when no reward was forthcoming (or expected). The responses also were weakly, but significantly, related to the proximity of the reward in the schedules requiring more than one trial. 5. The monkeys worked to obtain intravenous cocaine while we recorded 62 neurons. For 57 of the neurons, we recorded activity while the monkeys worked in blocks of trials during which they self-administered cocaine after blocks during which they worked for juice. Although fewer neurons responded to cocaine than to juice reward (19 vs. 33{\%}), this difference was not significant. The neuronal response properties to cocaine and juice rewards were independent; that is, the responses when one was the reward one failed to predict the response when the other was the reward. In addition, the neuronal activity lost most of its selectivity for rewarded trials, i.e, the activity did not distinguish nearly as well between cocaine and sham rewards as between juice and sham rewards. 6. Our results show that mechanisms by which cocaine acts do not appear to be the same as the ones activated when the monkeys were presented with an oral juice reward. This finding raises the intriguing possibility that the effects of cocaine could be reduced selectively without blocking the effects of many natural rewards.},
author = {Bowman, E M and Aigner, T G and Richmond, B J},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowman, Aigner, Richmond - 1996 - Neural signals in the monkey ventral striatum related to motivation for juice and cocaine rewards.pdf:pdf},
isbn = {0022-3077 (Print)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Animals,Cocaine,Cocaine: pharmacology,Corpus Striatum,Corpus Striatum: physiology,Female,Macaca mulatta,Male,Models, Psychological,Motivation,Neurons,Neurons: physiology,Reaction Time,Reaction Time: physiology,Reward},
month = {mar},
number = {3},
pages = {1061--73},
pmid = {8867118},
publisher = {American Physiological Society},
title = {{Neural signals in the monkey ventral striatum related to motivation for juice and cocaine rewards.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8867118},
volume = {75},
year = {1996}
}
@article{Maia2009,
abstract = {The field of reinforcement learning has greatly influenced the neuroscientific study of conditioning. This article provides an introduction to reinforcement learning followed by an examination of the successes and challenges using reinforcement learning to understand the neural bases of conditioning. Successes reviewed include (1) the mapping of positive and negative prediction errors to the firing of dopamine neurons and neurons in the lateral habenula, respectively; (2) the mapping of model-based and model-free reinforcement learning to associative and sensorimotor cortico-basal ganglia-thalamo-cortical circuits, respectively; and (3) the mapping of actor and critic to the dorsal and ventral striatum, respectively. Challenges reviewed consist of several behavioral and neural findings that are at odds with standard reinforcement-learning models, including, among others, evidence for hyperbolic discounting and adaptive coding. The article suggests ways of reconciling reinforcement-learning models with many of the challenging findings, and highlights the need for further theoretical developments where necessary. Additional information related to this study may be downloaded from http://cabn.psychonomic-journals.org/content/supplemental.},
author = {Maia, Tiago V.},
doi = {10.3758/CABN.9.4.343},
isbn = {1531-135X (Electronic)$\backslash$n1530-7026 (Linking)},
issn = {15307026},
journal = {Cognitive, Affective and Behavioral Neuroscience},
month = {dec},
number = {4},
pages = {343--364},
pmid = {19897789},
publisher = {Springer-Verlag},
title = {{Reinforcement learning, conditioning, and the brain: Successes and challenges}},
url = {http://www.springerlink.com/index/10.3758/CABN.9.4.343},
volume = {9},
year = {2009}
}
@article{Rescorla1967,
abstract = {Behavior and experience are organized around the enjoyment and pursuit of incentives. During the time that an incentive is behaviorally salient, an organism is especially responsive to incentive-related cues. This sustained sensitivity requires postulating a continuing state (denoted by a construct, current concern) with a definite onset (commitment) and offset (consummation or disengagement). Disengagement follows frustration, accompanies the behavioral process of extinction, and involves an incentive-disengagement cycle of invigoration, aggression, depression, and recovery. Depression is thus a normal part of disengagement that may be either adaptive or maladaptive for the individual but is probably adaptive for the species. The theory offers implications for motivation; etiology, symptomatology, and treatment of depression; drug use; and other social problem areas.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rescorla, Robert A. and Solomon, Richard L.},
doi = {10.1037/h0024475},
eprint = {arXiv:1011.1669v3},
isbn = {1939-1471$\backslash$n0033-295X},
issn = {0033295X},
journal = {Psychological Review},
keywords = {INSTRUMENTAL LEARNING {\&} PAVLOVIAN CONDITIONING},
number = {3},
pages = {151--182},
pmid = {6571423},
title = {{Two-Process Learning Theory: Relationships Between Pavlovian Conditioning and Instrumental Learning}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0024475},
volume = {74},
year = {1967}
}
@article{Day2011,
abstract = {Efficient decision-making requires that animals consider both the benefits and the costs of potential actions, such as the amount of effort or temporal delay involved in reward seeking. The nucleus accumbens (NAc) has been implicated in the ability to choose between options with different costs and overcome high costs when necessary, but it is not clear how NAc processing contributes to this role. Here, neuronal activity in the rat NAc was monitored using multi-neuron electrophysiology during two cost-based decision tasks in which either reward effort or reward delay was manipulated. In each task, distinct visual cues predicted high-value (low effort/immediate) and low-value (high effort/delayed) rewards. After training, animals exhibited a behavioral preference for high-value rewards, yet overcame high costs when necessary to obtain rewards. Electrophysiological analysis indicated that a subgroup of NAc neurons exhibited phasic increases in firing rate during cue presentations. In the effort-based decision task (but not the delay-based task), this population reflected the cost-discounted value of the future response. In contrast, other subgroups of cells were activated during response initiation or reward delivery, but activity did not differ on the basis of reward cost. Finally, another population of cells exhibited sustained changes in firing rate while animals completed high-effort requirements or waited for delayed rewards. These findings are consistent with previous reports that implicate NAc function in reward prediction and behavioral allocation during reward-seeking behavior, and suggest a mechanism by which NAc activity contributes to both cost-based decisions and actual cost expenditure.},
author = {Day, Jeremy J. and Jones, Joshua L. and Carelli, Regina M.},
doi = {10.1111/j.1460-9568.2010.07531.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Day, Jones, Carelli - 2011 - Nucleus accumbens neurons encode predicted and ongoing reward costs in rats.pdf:pdf},
isbn = {0953-816X},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Cost,Decision-making,Dopamine,Motivation,Nucleus accumbens,Reward},
month = {jan},
number = {2},
pages = {308--321},
pmid = {21198983},
publisher = {Blackwell Publishing Ltd},
title = {{Nucleus accumbens neurons encode predicted and ongoing reward costs in rats}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2010.07531.x},
volume = {33},
year = {2011}
}
@article{Ylinen1995,
abstract = {Previously it has been shown that the hippocampus and neocortex can spontaneously reactivate ensemble activity patterns during post-behavioral sleep and rest periods. Here we examined whether such reactivation also occurs in a subcortical structure, the ventral striatum, which receives a direct input from the hippocampal formation and has been implicated in guidance of consummatory and conditioned behaviors. During a reward-searching task on a T-maze, flanked by sleep and rest periods, parallel recordings were made from ventral striatal ensembles while EEG signals were derived from the hippocampus. Statistical measures indicated a significant amount of reactivation in the ventral striatum. In line with hippocampal data, reactivation was especially prominent during post-behavioral slow-wave sleep, but unlike the hippocampus, no decay in pattern recurrence was visible in the ventral striatum across the first 40 min of post-behavioral rest. We next studied the relationship between ensemble firing patterns in ventral striatum and hippocampal ripples-sharp waves, which have been implicated in pattern replay. Firing rates were significantly modulated in close temporal association with hippocampal ripples in 25{\%} of the units, showing a marked transient enhancement in the average response profile. Strikingly, ripple-modulated neurons in ventral striatum showed a clear reactivation, whereas nonmodulated cells did not. These data suggest, first, the occurrence of pattern replay in a subcortical structure implied in the processing and prediction of reward and, second, a functional linkage between ventral striatal reactivation and a specific type of high-frequency population activity associated with hippocampal replay.},
author = {Pennartz, C. M. A.},
doi = {10.1523/JNEUROSCI.0575-04.2004},
isbn = {1529-2401 (Electronic)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jan},
number = {29},
pages = {6446--6456},
pmid = {15269254},
publisher = {Society for Neuroscience},
title = {{The Ventral Striatum in Off-Line Processing: Ensemble Reactivation during Sleep and Modulation by Hippocampal Ripples}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0575-04.2004},
volume = {24},
year = {2004}
}
@article{Brown1968,
abstract = {Reliable acquisition of the pigeon's key-peck response resulted from repeated unconditional (response-independent) presentations of food after the response key was illuminated momentarily. Comparison groups showed that acquisition was dependent upon light-food pairings, in that order.},
author = {Brown, P L and Jenkins, H M},
doi = {10.1901/jeab.1968.11-1},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown, Jenkins - 1968 - Auto-shaping of the pigeon's key-peck1.pdf:pdf},
isbn = {0022-5002 (Print)$\backslash$r0022-5002 (Linking)},
issn = {0022-5002},
journal = {Journal of the experimental analysis of behavior},
month = {jan},
number = {1},
pages = {1--8},
pmid = {5636851},
publisher = {Blackwell Publishing Ltd},
title = {{Auto-shaping of the pigeon's key-peck.}},
url = {http://www.pubmedcentral.gov/articlerender.fcgi?artid=1338436},
volume = {11},
year = {1968}
}
@article{Schonberg,
abstract = {The computational framework of reinforcement learning has been used to forward our understanding of the neural mechanisms underlying reward learning and decision-making behavior. It is known that humans vary widely in their performance in decision-making tasks. Here, we used a simple four-armed bandit task in which subjects are almost evenly split into two groups on the basis of their performance: those who do learn to favor choice of the optimal action and those who do not. Using models of reinforcement learning we sought to determine the neural basis of these intrinsic differences in performance by scanning both groups with functional magnetic resonance imaging. We scanned 29 subjects while they performed the reward-based decision-making task. Our results suggest that these two groups differ markedly in the degree to which reinforcement learning signals in the striatum are engaged during task performance. While the learners showed robust prediction error signals in both the ventral and dorsal striatum during learning, the nonlearner group showed a marked absence of such signals. Moreover, the magnitude of prediction error signals in a region of dorsal striatum correlated significantly with a measure of behavioral performance across all subjects. These findings support a crucial role of prediction error signals, likely originating from dopaminergic midbrain neurons, in enabling learning of action selection preferences on the basis of obtained rewards. Thus, spontaneously observed individual differences in decision making performance demonstrate the suggested dependence of this type of learning on the functional integrity of the dopaminergic striatal system in humans.},
author = {Schonberg, T. and Daw, Nathaniel D and Joel, Daphna and O'Doherty, J. P.},
doi = {10.1523/JNEUROSCI.2496-07.2007},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {associative learning,basal ganglia,computational models,fMRI,instrumental conditioning,prediction errors},
number = {47},
pages = {12860--12867},
pmid = {18032658},
title = {{Reinforcement Learning Signals in the Human Striatum Distinguish Learners from Nonlearners during Reward-Based Decision Making}},
url = {http://www.jneurosci.org/content/jneuro/27/47/12860.full.pdf http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2496-07.2007},
volume = {27},
year = {2007}
}
@article{Hyman2006,
abstract = {Addiction is a state of compulsive drug use; despite treatment and other attempts to control drug taking, addiction tends to persist. Clinical and laboratory observations have converged on the hypothesis that addiction represents the pathological usurpation of neural processes that normally serve reward-related learning. The major substrates of persistent compulsive drug use are hypothesized to be molecular and cellular mechanisms that underlie long-term associative memories in several forebrain circuits (involving the ventral and dorsal striatum and prefrontal cortex) that receive input from midbrain dopamine neurons. Here we review progress in identifying candidate mechanisms of addiction.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hyman, Steven E. and Malenka, Robert C. and Nestler, Eric J.},
doi = {10.1146/annurev.neuro.29.051605.113009},
eprint = {arXiv:1011.1669v3},
isbn = {0147-006X$\backslash$r978-0-8243-2429-2},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {associative memory,dependence,dopamine,drug,plasticity,reward},
month = {jul},
number = {1},
pages = {565--598},
pmid = {16776597},
publisher = {Annual Reviews},
title = {{NEURAL MECHANISMS OF ADDICTION: The Role of Reward-Related Learning and Memory}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.neuro.29.051605.113009},
volume = {29},
year = {2006}
}
@article{West2016,
abstract = {Nucleus accumbens (NAc) neurons encode features of stimulus learning and action selection associated with rewards. The NAc is necessary for using information about expected outcome values to guide behavior after reinforcer devaluation. Evidence suggests that core and shell subregions may play dissociable roles in guiding motivated behavior. Here, we recorded neural activity in the NAc core and shell during training and performance of a reinforcer devaluation task. Long-Evans male rats were trained that presses on a lever under an illuminated cue light delivered a flavored sucrose reward. On subsequent test days, each rat was given free access to one of two distinctly flavored foods to consume to satiation and were then immediately tested on the lever pressing task under extinction conditions. Rats decreased pressing on the test day when the reinforcer earned during training was the sated flavor (devalued) compared with the test day when the reinforcer was not the sated flavor (nondevalued), demonstrating evidence of outcome-selective devaluation. Cue-selective encoding during training by NAc core (but not shell) neurons reliably predicted subsequent behavioral performance; that is, the greater the percentage of neurons that responded to the cue, the better the rats suppressed responding after devaluation. In contrast, NAc shell (but not core) neurons significantly decreased cue-selective encoding in the devalued condition compared with the nondevalued condition. These data reveal that NAc core and shell neurons encode information differentially about outcome-specific cues after reinforcer devaluation that are related to behavioral performance and outcome value, respectively. SIGNIFICANCE STATEMENT Many neuropsychiatric disorders are marked by impairments in behavioral flexibility. Although the nucleus accumbens (NAc) is required for behavioral flexibility, it is not known how NAc neurons encode this information. Here, we recorded NAc neurons during a training session in which rats learned that a cue predicted a specific reward and during a test session when that reward value was changed. Although encoding in the core during training predicted the ability of rats to change behavior after the reward value was altered, the NAc shell encoded information about the change in reward value during the test session. These findings suggest differential roles of the core and shell in behavioral flexibility.},
author = {West, E. A. and Carelli, R. M.},
doi = {10.1523/JNEUROSCI.2976-15.2016},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {accumbens,behavior,devaluation,electrophysiology,motivation,rat},
month = {jan},
number = {4},
pages = {1128--1139},
pmid = {26818502},
publisher = {Society for Neuroscience},
title = {{Nucleus Accumbens Core and Shell Differentially Encode Reward-Associated Cues after Reinforcer Devaluation}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2976-15.2016},
volume = {36},
year = {2016}
}
@article{Mannella2013,
abstract = {Goal-directed behavior is a fundamental means by which animals can flexibly solve the challenges posed by variable external and internal conditions. Recently, the processes and brain mechanisms underlying such behavior have been extensively studied from behavioral, neuroscientific and computational perspectives. This research has highlighted the processes underlying goal-directed behavior and associated brain systems including prefrontal cortex, basal ganglia and, in particular therein, the nucleus accumbens (NAcc). This paper focusses on one particular process at the core of goal-directed behavior: how motivational value is assigned to goals on the basis of internal states and environmental stimuli, and how this supports goal selection processes. Various biological and computational accounts have been given of this problem and of related multiple neural and behavior phenomena, but we still lack an integrated hypothesis on the generation and use of value for goal selection. This paper proposes an hypothesis that aims to solve this problem and is based on this key elements: (a) amygdala and hippocampus establish the motivational value of stimuli and goals; (b) prefrontal cortex encodes various types of action outcomes; (c) NAcc integrates different sources of value, representing them in terms of a common currency with the aid of dopamine, and thereby plays a major role in selecting action outcomes within prefrontal cortex. The "goals" pursued by the organism are the outcomes selected by these processes. The hypothesis is developed in the context of a critical review of relevant biological and computational literature which offer it support. The paper shows how the hypothesis has the potential to integrate existing interpretations of motivational value and goal selection.},
author = {Mannella, Francesco and Gurney, Kevin and Baldassarre, Gianluca},
doi = {10.3389/fnbeh.2013.00135},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mannella, Gurney, Baldassarre - 2013 - The nucleus accumbens as a nexus between values and goals in goal-directed behavior a review and.pdf:pdf},
isbn = {1662-5153 (Electronic)$\backslash$r1662-5153 (Linking)},
issn = {1662-5153},
journal = {Frontiers in Behavioral Neuroscience},
keywords = {amygdala (amg),appetitive and novelty  value,bio-behavioural and computational perspectives,goal selection,hippocampus (Hip),nucleus accumbens (NAcc),prefrontal cortex (PFC)},
pages = {135},
pmid = {24167476},
publisher = {Frontiers},
title = {{The nucleus accumbens as a nexus between values and goals in goal-directed behavior: a review and a new hypothesis}},
url = {http://journal.frontiersin.org/article/10.3389/fnbeh.2013.00135/abstract},
volume = {7},
year = {2013}
}
@article{Nicola2004,
abstract = {The nucleus accumbens (NAc) has long been thought of as a limbic-motor interface. Despite behavioral and anatomical evidence in favor of this idea, little is known about how NAc neurons encode information about motivationally relevant environmental cues and use this information to affect motor action. We therefore investigated the firing of these neurons during the performance of a discriminative stimulus (DS) task using simultaneous multiple single-unit recordings in rats. In this task, two stimuli are randomly presented to the animal: a DS, which signals the availability of a sucrose reward contingent on an operant response, and a similar but nonrewarded stimulus (NS). Subpopulations of NAc neurons increased or decreased their firing in association with several distinct components of the task. In this paper, we investigate cue- and operant-responsive neurons. Neurons excited and inhibited by cues showed larger firing changes in response to the DS than the NS and larger changes when the animal made an operant response to the cue than when the animal failed to respond. Excitations during operant responding were not modulated by the information contained by the cue, whereas inhibitions during operant responding were somewhat larger if the operant response occurred during the DS and somewhat smaller if they occurred in the absence of a cue. These results are consistent with the hypothesis that the firing of subpopulations of NAc neurons encode both the predictive value of environmental stimuli and the specific motor behaviors required to respond to them.},
author = {Nicola, S. M.},
doi = {10.1152/jn.00657.2003},
isbn = {0022-3077 (Print)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
month = {apr},
number = {4},
pages = {1840--1865},
pmid = {14645377},
publisher = {American Physiological Society},
title = {{Cue-Evoked Firing of Nucleus Accumbens Neurons Encodes Motivational Significance During a Discriminative Stimulus Task}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00657.2003},
volume = {91},
year = {2004}
}
@techreport{ODoherty2003,
abstract = {Temporal difference learning has been proposed as a model for Pavlovian conditioning, in which an animal learns to predict delivery of reward following presentation of a conditioned stimulus (CS). A key component of this model is a prediction error signal, which, before learning, responds at the time of presentation of reward but, after learning, shifts its response to the time of onset of the CS. In order to test for regions manifesting this signal profile, subjects were scanned using event-related fMRI while undergoing appetitive conditioning with a pleasant taste reward. Regression analyses revealed that responses in ventral striatum and orbitofrontal cortex were significantly correlated with this error signal, suggesting that, during appetitive conditioning, computations described by temporal difference learning are expressed in the human brain.},
author = {O'Doherty, John P. and Dayan, Peter and Friston, Karl and Critchley, Hugo and Dolan, Raymond J.},
booktitle = {Neuron},
doi = {10.1016/S0896-6273(03)00169-7},
isbn = {0896-6273},
issn = {08966273},
number = {2},
pages = {329--337},
pmid = {12718865},
title = {{Temporal difference models and reward-related learning in the human brain}},
volume = {38},
year = {2003}
}
@article{Corlett2010,
author = {Corlett, P R and Taylor, J R and Wang, X.-J and Fletcher, P C and Krystal, J H},
doi = {10.1016/j.pneurobio.2010.06.007},
isbn = {1873-5118 (Electronic)$\backslash$r0301-0082 (Linking)},
issn = {03010082},
journal = {Progress in Neurobiology},
keywords = {Delusions,Error,Habit,Learning,Memory,Prediction,Reconsolidation},
pages = {345--369},
title = {{Toward a neurobiology of delusions}},
url = {http://www.cns.nyu.edu/wanglab/publications/pdf/corlett.pn2010.pdf},
volume = {92},
year = {2010}
}
@article{Berridge2007,
abstract = {INTRODUCTION: Debate continues over the precise causal contribution made by mesolimbic dopamine systems to reward. There are three competing explanatory categories: 'liking', learning, and 'wanting'. Does dopamine mostly mediate the hedonic impact of reward ('liking')? Does it instead mediate learned predictions of future reward, prediction error teaching signals and stamp in associative links (learning)? Or does dopamine motivate the pursuit of rewards by attributing incentive salience to reward-related stimuli ('wanting')? Each hypothesis is evaluated here, and it is suggested that the incentive salience or 'wanting' hypothesis of dopamine function may be consistent with more evidence than either learning or 'liking'. In brief, recent evidence indicates that dopamine is neither necessary nor sufficient to mediate changes in hedonic 'liking' for sensory pleasures. Other recent evidence indicates that dopamine is not needed for new learning, and not sufficient to directly mediate learning by causing teaching or prediction signals. By contrast, growing evidence indicates that dopamine does contribute causally to incentive salience. Dopamine appears necessary for normal 'wanting', and dopamine activation can be sufficient to enhance cue-triggered incentive salience. Drugs of abuse that promote dopamine signals short circuit and sensitize dynamic mesolimbic mechanisms that evolved to attribute incentive salience to rewards. Such drugs interact with incentive salience integrations of Pavlovian associative information with physiological state signals. That interaction sets the stage to cause compulsive 'wanting' in addiction, but also provides opportunities for experiments to disentangle 'wanting', 'liking', and learning hypotheses. Results from studies that exploited those opportunities are described here. CONCLUSION: In short, dopamine's contribution appears to be chiefly to cause 'wanting' for hedonic rewards, more than 'liking' or learning for those rewards.},
author = {Berridge, Kent C.},
doi = {10.1007/s00213-006-0578-x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berridge - 2007 - The debate over dopamine's role in reward the case for incentive salience.pdf:pdf},
isbn = {0033-3158 (Print)$\backslash$n0033-3158 (Linking)},
issn = {00333158},
journal = {Psychopharmacology},
keywords = {Accumbens,Addiction,Appetite,Associative learning,Aversion,Basal forebrain,Dopamine,Opioid,Reward},
month = {mar},
number = {3},
pages = {391--431},
pmid = {17072591},
publisher = {Springer-Verlag},
title = {{The debate over dopamine's role in reward: The case for incentive salience}},
url = {http://link.springer.com/10.1007/s00213-006-0578-x},
volume = {191},
year = {2007}
}
@article{Carelli1994,
abstract = {The firing patterns of nucleus accumbens (NA) neurons in the rat were recorded during cocaine self-administration and responding for water. Recordings were obtained from permanently implanted multiple-electrode arrays (eight microwires) inserted bilaterally into rostral portions of the NA in subjects (n = 18) exhibiting stable cocaine self-administration (0.33 mg/infusion), and during stable responding for water reinforcement. Electronically isolated and identified NA neurons exhibited four distinct patterns of phasic activity relative to the reinforced response. Three of these firing patterns were observed during both cocaine self-administration and water reinforcement sessions. Response-related activity was categorized by cells that showed an anticipatory increase in firing rate during the preresponse phase (type PR), and by cells that were excited (type RFE) or inhibited (type RFI) following the response in the reinforcement phase. PR and RFE cells showed significantly reduced peak firing during cocaine self-administration, compared to similar cells in water reinforcement sessions. A fourth type of NA firing pattern (type PR+RF) was observed only in cells recorded during cocaine self-administration sessions (Carelli et al., 1993b). PR+RF neurons exhibited two distinct peaks, one preceding the response and terminating at response completion (like PR cells), and a second peak immediately following the response (like RFE cells) with an inhibitory period between the two peaks (like RFI cells). The findings are discussed in terms of the role of the NA in mediating the reinforcing properties of both cocaine and water.},
author = {Carelli, R M and Deadwyler, S A},
isbn = {0270-6474 (Print)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Animal,Animals,Behavior,Cocaine,Cocaine: administration {\&} dosage,Cocaine: pharmacology,Electrophysiology,Male,Neurons,Neurons: drug effects,Neurons: physiology,Nucleus Accumbens,Nucleus Accumbens: cytology,Nucleus Accumbens: physiology,Rats,Reinforcement (Psychology),Self Administration,Sprague-Dawley,Water},
number = {12},
pages = {7735--7746},
pmid = {7996208},
title = {{A Comparison of Nucleus Accumbens Neuronal Firing Patterns during Cocaine Self-Administration and Water Reinforcement in Rats}},
volume = {14},
year = {1994}
}
@article{Rigotti2013,
abstract = {Nature (2013). doi:10.1038/nature12160},
author = {Rigotti, Mattia and Barak, Omri and Warden, Melissa R. and Wang, Xiao Jing and Daw, Nathaniel D. and Miller, Earl K. and Fusi, Stefano},
doi = {10.1038/nature12160},
isbn = {doi:10.1038/nature12160},
issn = {00280836},
journal = {Nature},
month = {may},
number = {7451},
pages = {585--590},
pmid = {23685452},
publisher = {NIH Public Access},
title = {{The importance of mixed selectivity in complex cognitive tasks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23685452 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4412347},
volume = {497},
year = {2013}
}
@article{Carelli1994a,
abstract = {The firing patterns of nucleus accumbens (NA) neurons in the rat were recorded during cocaine self-administration and responding for water. Recordings were obtained from permanently implanted multiple-electrode arrays (eight microwires) inserted bilaterally into rostral portions of the NA in subjects (n = 18) exhibiting stable cocaine self-administration (0.33 mg/infusion), and during stable responding for water reinforcement. Electronically isolated and identified NA neurons exhibited four distinct patterns of phasic activity relative to the reinforced response. Three of these firing patterns were observed during both cocaine self-administration and water reinforcement sessions. Response-related activity was categorized by cells that showed an anticipatory increase in firing rate during the preresponse phase (type PR), and by cells that were excited (type RFE) or inhibited (type RFI) following the response in the reinforcement phase. PR and RFE cells showed significantly reduced peak firing during cocaine self-administration, compared to similar cells in water reinforcement sessions. A fourth type of NA firing pattern (type PR+RF) was observed only in cells recorded during cocaine self-administration sessions (Carelli et al., 1993b). PR+RF neurons exhibited two distinct peaks, one preceding the response and terminating at response completion (like PR cells), and a second peak immediately following the response (like RFE cells) with an inhibitory period between the two peaks (like RFI cells). The findings are discussed in terms of the role of the NA in mediating the reinforcing properties of both cocaine and water.},
author = {Carelli, R M and Deadwyler, S A},
isbn = {0270-6474 (Print)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Animal,Animals,Behavior,Cocaine,Cocaine: administration {\&} dosage,Cocaine: pharmacology,Electrophysiology,Male,Neurons,Neurons: drug effects,Neurons: physiology,Nucleus Accumbens,Nucleus Accumbens: cytology,Nucleus Accumbens: physiology,Rats,Reinforcement (Psychology),Self Administration,Sprague-Dawley,Water},
month = {dec},
number = {12},
pages = {7735--7746},
pmid = {7996208},
title = {{A Comparison of Nucleus Accumbens Neuronal Firing Patterns during Cocaine Self-Administration and Water Reinforcement in Rats}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7996208},
volume = {14},
year = {1994}
}
@article{Sjulson2017,
abstract = {Conditioned place preference (CPP) is a widely used model of addiction-related behavior whose underlying mechanism is not understood. In this study, we used dual site silicon probe recordings in freely moving mice to examine interactions between the hippocampus and nucleus accumbens in cocaine CPP. We found that CPP was associated with recruitment of nucleus accumbens medium spiny neurons (MSNs) to fire in the cocaine-paired location, and this recruitment was driven predominantly by selective strengthening of hippocampal inputs arising from place cells that encode the cocaine-paired location. These findings provide in vivo evidence that the synaptic potentiation in the accumbens caused by repeated cocaine administration preferentially affects inputs that were active at the time of drug exposure. This provides a plausible physiological mechanism by which drug use becomes associated with specific environmental contexts.},
author = {Sjulson, Lucas and Peyrache, Adrien and Cumpelik, Andrea and Cassataro, Daniela and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.1101/105890},
journal = {bioRxiv},
month = {may},
pages = {1--10},
publisher = {Cold Spring Harbor Laboratory},
title = {{Cocaine place conditioning strengthens location-specific hippocampal inputs to the nucleus accumbens}},
url = {http://www.biorxiv.org/content/early/2017/02/03/105890{\%}0Ahttp://www.biorxiv.org/content/biorxiv/early/2017/02/03/105890.full.pdf},
year = {2017}
}
@article{Phillips2003,
abstract = {Evidence is reviewed in support of a role for the mesocorticolimbic dopamine system in motivated behavior as opposed to the hedonic assessment of reward stimuli. Microdialysis studies describe the dynamic changes in dopamine efflux in the medial prefrontal cortex (mPFC) and nucleus accumbens (NAc) during the development of sensory-specific satiety for food or sexual activity by male rats. These data confirm that dopamine efflux is increased in both regions in anticipation of reward and decreases with the development of satiety. Importantly, presentation of a novel reward stimulus is accompanied by a further increase in dopamine efflux. Neural circuits linking the hippocampal formation to the prefrontal cortex and nucleus accumbens subserve memory-based search behaviors for food reward. Furthermore, dopamine D1 receptors in the prefrontal cortex selective modulate working memory processes responsible for the accurate recall of the location of food reward. In contrast, dopamine D1 receptors in the nucleus accumbens modulate memory-based search behavior, without prior knowledge of the location of food. A final series of experiments confirm that dopamine efflux in the medial prefrontal cortex triggered by expectation of food reward is related to the accuracy of recall for the location of food reward. Collectively, these experiments support the hypothesis that dopamine serves as a critical link between motivational and memory processes. {\textcopyright} 2003, Elsevier Science B.V. All rights reserved.},
author = {Phillips, Anthony G.},
doi = {10.1016/S0531-5131(03)00188-2},
isbn = {1604822775},
issn = {05315131},
journal = {International Congress Series},
keywords = {Dopamine,Memory,Microdialysis,Motivation,Reward},
month = {aug},
number = {C},
pages = {509--526},
pmid = {9705481},
title = {{Mesocorticolimbic dopamine: A neurochemical link between motivation and memory}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9705481 http://www.physiology.org/doi/10.1152/jn.1998.80.2.947},
volume = {1250},
year = {2003}
}
@article{Cooch2015,
abstract = {The ventral striatum has long been proposed as an integrator of biologically significant associative information to drive actions. Although inputs from the amygdala and hippocampus have been much studied, the role of prominent inputs from orbitofrontal cortex (OFC) are less well understood. Here, we recorded single-unit activity from ventral striatum core in rats with sham or ipsilateral neurotoxic lesions of lateral OFC, as they performed an odour-guided spatial choice task. Consistent with prior reports, we found that spiking activity recorded in sham rats during cue sampling was related to both reward magnitude and reward identity, with higher firing rates observed for cues that predicted more reward. Lesioned rats also showed differential activity to the cues, but this activity was unbiased towards larger rewards. These data support a role for OFC in shaping activity in the ventral striatum to represent the biological significance of associative information in the environment.},
author = {Cooch, Nisha K. and Stalnaker, Thomas A. and Wied, Heather M. and Bali-Chaudhary, Sheena and McDannald, Michael A. and Liu, Tzu Lan and Schoenbaum, Geoffrey},
doi = {10.1038/ncomms8195},
isbn = {2041-1723 (Electronic)$\backslash$r2041-1723 (Linking)},
issn = {20411723},
journal = {Nature Communications},
month = {jun},
pages = {7195},
pmid = {26006060},
publisher = {Nature Publishing Group},
title = {{Orbitofrontal lesions eliminate signalling of biological significance in cue-responsive ventral striatal neurons}},
url = {http://www.nature.com/doifinder/10.1038/ncomms8195},
volume = {6},
year = {2015}
}
@article{Cheer2007,
abstract = {Intracranial self-stimulation (ICSS) activates the neural pathways that mediate reward, including dopaminergic terminal areas such as the nucleus accumbens (NAc). However, a direct role of dopamine in ICSS-mediated reward has been questioned. Here, simultaneous voltammetric and electrophysiological recordings from the same electrode reveal that, at certain sites, the onset of anticipatory dopamine surges and changes in neuronal firing patterns during ICSS are coincident, whereas sites lacking dopamine changes also lack patterned firing. Intrashell microinfusion of a D1, but not a D2 receptor antagonist, blocks ICSS. An iontophoresis approach was implemented to explore the effect of dopamine antagonists on firing patterns without altering behavior. Similar to the microinfusion experiments, ICSS-related firing is selectively attenuated following D1 receptor blockade. This work establishes a temporal link between anticipatory rises of dopamine and firing patterns in the NAc shell during ICSS and suggests that they may play a similar role with natural rewards and during drug self-administration. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {(1) Cheer, J. F.; Aragona, B. J.; Heien, M. L. A. V; Seipel, A. T.; Carelli, R. M.; Wightman, R. M. Neuron 2007, 54 (2), 237–244.},
author = {Cheer, Joseph F. and Aragona, Brandon J. and Heien, Michael L A V and Seipel, Andrew T. and Carelli, Regina M. and Wightman, R. Mark},
doi = {10.1016/j.neuron.2007.03.021},
eprint = {(1) Cheer, J. F.; Aragona, B. J.; Heien, M. L. A. V; Seipel, A. T.; Carelli, R. M.; Wightman, R. M. Neuron 2007, 54 (2), 237–244.},
isbn = {0896-6273 (Print)},
issn = {08966273},
journal = {Neuron},
keywords = {HUMDISEASE,SYSNEURO},
month = {apr},
number = {2},
pages = {237--244},
pmid = {17442245},
publisher = {Elsevier},
title = {{Coordinated Accumbal Dopamine Release and Neural Activity Drive Goal-Directed Behavior}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17442245},
volume = {54},
year = {2007}
}
@misc{sutton1998,
abstract = {From the Publisher:In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.},
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Sutton, R.S. and Barto, A.G.},
booktitle = {IEEE Transactions on Neural Networks},
doi = {10.1109/TNN.1998.712192},
eprint = {1603.02199},
isbn = {0262193981},
issn = {1045-9227},
keywords = {reinforcement learning theory},
number = {5},
pages = {1054--1054},
pmid = {18255791},
publisher = {MIT Press, Cambridge, MA},
title = {{Reinforcement Learning: An Introduction}},
url = {http://ieeexplore.ieee.org/document/712192/},
volume = {9},
year = {1998}
}
@article{Kalivas2005,
abstract = {OBJECTIVE: A primary behavioral pathology in drug addiction is the overpowering motivational strength and decreased ability to control the desire to obtain drugs. In this review the authors explore how advances in neurobiology are approaching an understanding of the cellular and circuitry underpinnings of addiction, and they describe the novel pharmacotherapeutic targets emerging from this understanding. METHOD: Findings from neuroimaging of addicts are integrated with cellular studies in animal models of drug seeking. RESULTS: While dopamine is critical for acute reward and initiation of addiction, end-stage addiction results primarily from cellular adaptations in anterior cingulate and orbitofrontal glutamatergic projections to the nucleus accumbens. Pathophysiological plasticity in excitatory transmission reduces the capacity of the prefrontal cortex to initiate behaviors in response to biological rewards and to provide executive control over drug seeking. Simultaneously, the prefrontal cortex is hyperresponsive to stimuli predicting drug availability, resulting in supraphysiological glutamatergic drive in the nucleus accumbens, where excitatory synapses have a reduced capacity to regulate neurotransmission. CONCLUSIONS: Cellular adaptations in prefrontal glutamatergic innervation of the accumbens promote the compulsive character of drug seeking in addicts by decreasing the value of natural rewards, diminishing cognitive control (choice), and enhancing glutamatergic drive in response to drug-associated stimuli.},
author = {Kalivas, Peter W. and Volkow, Nora D.},
doi = {10.1176/appi.ajp.162.8.1403},
isbn = {0002-953X (Print)},
issn = {0002953X},
journal = {American Journal of Psychiatry},
month = {aug},
number = {8},
pages = {1403--1413},
pmid = {16055761},
publisher = {American Psychiatric Publishing},
title = {{The neural basis of addiction: A pathology of motivation and choice}},
url = {http://psychiatryonline.org/doi/abs/10.1176/appi.ajp.162.8.1403},
volume = {162},
year = {2005}
}
@article{Reynolds2008,
abstract = {The nucleus accumbens mediates both appetitive motivation for rewards and fearful motivation toward threats, which are generated in part by glutamate-related circuits organized in a keyboard fashion. At rostral sites of the medial shell, localized glutamate disruptions typically generate intense appetitive behaviors in rats, but the disruption incrementally generates fearful behaviors as microinjection sites move more caudally. We found that exposure to stressful environments caused caudal fear-generating zones to expand rostrally, filling approximately 90{\%} of the shell. Conversely, a preferred home environment caused fear-generating zones to shrink and appetitive-generating zones to expand caudally, filling approximately 90{\%} of the shell. Thus, the emotional environments retuned the generation of motivation in corticolimbic circuits.},
author = {Reynolds, Sheila M. and Berridge, Kent C.},
doi = {10.1038/nn2061},
isbn = {1097-6256 (Print)},
issn = {10976256},
journal = {Nature Neuroscience},
month = {apr},
number = {4},
pages = {423--425},
pmid = {18344996},
publisher = {Nature Publishing Group},
title = {{Emotional environments retune the valence of appetitive versus fearful functions in nucleus accumbens}},
url = {http://www.nature.com/doifinder/10.1038/nn2061},
volume = {11},
year = {2008}
}
@article{Noonan2017,
abstract = {The orbitofrontal cortex is critical for goal-directed behavior. Recent work in macaques has suggested the lateral orbitofrontal cortex (lOFC) is relatively more concerned with assignment of credit for rewards to particular choices during value-guided learning, whereas the medial orbitofrontal cortex (often referred to as ventromedial prefrontal cortex in humans; vmPFC/mOFC) is involved in constraining the decision to the relevant options. We examined whether people with damage restricted to subregions of prefrontal cortex showed the patterns of impairment observed in prior investigations of the effects of lesions to homologous regions in macaques. Groups of patients with either lOFC (predominantly right hemisphere), mOFC/vmPFC, or dorsomedial prefrontal (DMF), and a comparison group of healthy age- and education-matched controls performed a probabilistic 3-choice decision-making task. We report anatomically specific patterns of impairment. We found that credit assignment, as indexed by the normal influence of contingent relationships between choice and reward, is reduced in lOFC patients compared with Controls and mOFC/vmPFC patients. Moreover, the effects of reward contingency on choice were similar for patients with lesions in DMF or mOFC/vmPFC, compared with Controls. By contrast, mOFC/vmPFC-lesioned patients made more stochastic choices than Controls when the decision was framed by valuable distracting alternatives, suggesting that value comparisons were no longer independent of irrelevant options. Once again, there was evidence of regional specialization: patients with lOFC lesions were unimpaired relative to Controls. As in macaques, human lOFC and mOFC/vmPFC are necessary for contingent learning and value-guided decision-making, respectively.SIGNIFICANCE STATEMENT The lateral and medial regions of the orbitofrontal cortex are cytoarchitectonically distinct and have different anatomical connections. Previous investigations in macaques have shown these anatomical differences are accompanied by functional specialization for learning and decision-making. Here, for the first time, we test the predictions made by macaque studies in an experiment with humans with frontal lobe lesions, asking whether behavioral impairments can be linked to lateral or medial orbitofrontal cortex. Using equivalent tasks and computational analyses, our findings broadly replicate the pattern reported after selective lesions in monkeys. Patients with lateral orbitofrontal damage had impaired credit assignment, whereas damage to medial orbitofrontal cortex meant that patients were more likely to be distracted by irrelevant options.},
author = {Noonan, MaryAnn P. and Chau, Bolton K.H. and Rushworth, Matthew F.S. and Fellows, Lesley K.},
doi = {10.1523/JNEUROSCI.0692-17.2017},
isbn = {1529-2401 (Electronic)0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {credit assignment,decision-making,orbitofrontal cortex,prefrontal cortex,reward,ventromedial prefrontal cortex},
month = {jul},
number = {29},
pages = {7023--7035},
pmid = {28630257},
publisher = {Society for Neuroscience},
title = {{Contrasting Effects of Medial and Lateral Orbitofrontal Cortex Lesions on Credit Assignment and Decision-Making in Humans}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0692-17.2017},
volume = {37},
year = {2017}
}
@article{ODoherty2012,
abstract = {Neural computational accounts of reward-learning have been dominated by the hypothesis that dopamine neurons behave like a reward-prediction error and thus facilitate reinforcement learning in striatal target neurons. While this framework is consistent with a lot of behavioral and neural evidence, this theory fails to account for a number of behavioral and neurobiological observations. In this special issue of EJN we feature a combination of theoretical and experimental papers highlighting some of the explanatory challenges faced by simple reinforcement-learning models and describing some of the ways in which the framework is being extended in order to address these challenges.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {O'Doherty, John P.},
doi = {10.1111/j.1460-9568.2012.08074.x},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Doherty - 2012 - Beyond simple reinforcement learning the computational neurobiology of reward-learning and valuation.pdf:pdf},
isbn = {1460-9568 (Electronic)$\backslash$n0953-816X (Linking)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Basal ganglia,Computational neuroscience,Conditioning,Decision-making,Prefrontal cortex},
month = {apr},
number = {7},
pages = {987--990},
pmid = {22487029},
publisher = {Blackwell Publishing Ltd},
title = {{Beyond simple reinforcement learning: The computational neurobiology of reward-learning and valuation}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2012.08074.x},
volume = {35},
year = {2012}
}
@article{Akaishi2016,
abstract = {In complex environments, many potential cues can guide a decision or be assigned responsibility for the outcome of the decision. We know little, however, about how humans and animals select relevant information sources that should guide behavior. We show that subjects solve this relevance selection and credit assignment problem by selecting one cue and its association with a particular outcome as the main focus of a hypothesis. To do this, we examined learning while using a task design that allowed us to estimate the focus of each subject's hypotheses on a trial-by-trial basis. When a prediction is confirmed by the outcome, then credit for the outcome is assigned to that cue rather than an alternative. Activity in medial frontal cortex is associated with the assignment of credit to the cue that is the main focus of the hypothesis. However, when the outcome disconfirms a prediction, the focus shifts between cues, and the credit for the outcome is assigned to an alternative cue. This process of reselection for credit assignment to an alternative cue is associated with lateral orbitofrontal cortex.},
author = {Akaishi, R. and Kolling, N. and Brown, J. W. and Rushworth, M.},
doi = {10.1523/JNEUROSCI.3159-15.2016},
isbn = {0270-6474$\backslash$r1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jan},
number = {4},
pages = {1096--1112},
pmid = {26818500},
publisher = {Society for Neuroscience},
title = {{Neural Mechanisms of Credit Assignment in a Multicue Environment}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3159-15.2016},
volume = {36},
year = {2016}
}
@article{Shidara1998,
abstract = {Single neurons in the ventral striatum of primates carry signals that are related to reward and motivation. When monkeys performed a task requiring one to three bar release trials to be completed successfully before a reward was given, they seemed more motivated as the rewarded trials approached; they responded more quickly and accurately. When the monkeys were cued as to the progress of the schedule, 89 out of 150 ventral striatal neurons responded in at least one part of the task: (1) at the onset of the visual cue, (2) near the time of bar release, and/or (3) near the time of reward delivery. When the cue signaled progress through the schedule, the neuronal activity was related to the progress through the schedule. For example, one large group of these neurons responded in the first trial of every schedule, another large group responded in trials other than the first of a schedule, and a third large group responded in the first trial of schedules longer than one. Thus, these neurons coded the state of the cue, i.e., the neurons carried the information about how the monkey was progressing through the task. The differential activity disappeared on the first trial after randomizing the relation of the cue to the schedule. Considering the anatomical loop structure that includes ventral striatum and prefrontal cortex, we suggest that the ventral striatum might be part of a circuit that supports keeping track of progress through learned behavioral sequences that, when successfully completed, lead to reward.},
author = {Shidara, M and Aigner, T G and Richmond, B J},
isbn = {0270-6474},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {apr},
number = {7},
pages = {2613--25},
pmid = {9502820},
publisher = {Society for Neuroscience},
title = {{Neuronal signals in the monkey ventral striatum related to progress through a predictable series of trials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9502820},
volume = {18},
year = {1998}
}
@article{Strait2016,
abstract = {When we evaluate an option, how is our representation of its value bound to the 30 option's identity? We examined neuronal activity in four key reward regions of the brain: 31 orbitofrontal cortex (OFC), ventromedial prefrontal cortex (vmPFC), ventral striatum (VS), 32 and dorsal anterior cingulate cortex (dACC), in several two-option gambling tasks with 33 lateralized and asynchronous presentation of offers. We found that neuronal responses in all 34 areas are sensitive to the spatial positions of both offers and of choices. This selectivity is 35 strongest in reward-sensitive neurons, indicating that it is not a property of a specialized 36 subpopulation. We did not find any anatomical organization to these responses, suggesting 37 that they may be difficult to detect with aggregate measures like neuroimaging and lesion 38 studies. These results suggest that value coding is linked to object identity and suggest a 39},
author = {Strait, Caleb E. and Sleezer, Brianna J. and Blanchard, Tommy C. and Azab, Habiba and Castagno, Meghan D. and Hayden, Benjamin Y.},
doi = {10.1152/jn.00325.2015},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Strait et al. - 2016 - Neuronal selectivity for spatial positions of offers and choices in five reward regions.pdf:pdf},
isbn = {1522-1598(Electronic);0022-3077(Print)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {binding,decision making,prefrontal cortex,spatial tuning,value comparison},
month = {mar},
number = {3},
pages = {1098--1111},
pmid = {26631146},
publisher = { American Physiological Society Bethesda, MD},
title = {{Neuronal selectivity for spatial positions of offers and choices in five reward regions}},
url = {http://jn.physiology.org/lookup/doi/10.1152/jn.00325.2015},
volume = {115},
year = {2016}
}
@article{Lansink2016,
abstract = {The use of information from the hippocampal memory system in motivated behavior depends on its communication with the ventral striatum. When an animal encounters cues that signal subsequent reward, its reward expectancy is raised. It is unknown, however, how this process affects hippocampal dynamics and their influence on target structures, such as ventral striatum. We show that, in rats, reward-predictive cues result in enhanced hippocampal theta and beta band rhythmic activity during subsequent action, compared with uncued goal-directed navigation. The beta band component, also labeled theta's harmonic, involves selective hippocampal CA1 cell groups showing frequency doubling of firing periodicity relative to theta rhythmicity and it partitions the theta cycle into segments showing clear versus poor spike timing organization. We found that theta phase precession occurred over a wider range than previously reported. This was apparent from spikes emitted near the peak of the theta cycle exhibiting large "phase precessing jumps" relative to spikes in foregoing cycles. Neither this phenomenon nor the regular manifestation of theta phase precession was affected by reward expectancy. Ventral striatal neuronal firing phase-locked not only to hippocampal theta, but also to beta band activity. Both hippocampus and ventral striatum showed increased synchronization between neuronal firing and local field potential activity during cued compared with uncued goal approaches. These results suggest that cue-triggered reward expectancy intensifies hippocampal output to target structures, such as the ventral striatum, by which the hippocampus may gain prioritized access to systems modulating motivated behaviors. SIGNIFICANCE STATEMENT Here we show that temporally discrete cues raising reward expectancy enhance both theta and beta band activity in the hippocampus once goal-directed navigation has been initiated. These rhythmic activities are associated with increased synchronization of neuronal firing patterns in the hippocampus and the connected ventral striatum. When transmitted to downstream target structures, this expectancy-related state of intensified processing in the hippocampus may modulate goal-directed action.},
author = {Lansink, C. S. and Meijer, G. T. and Lankelma, J. V. and Vinck, M. A. and Jackson, J. C. and Pennartz, C. M. A.},
doi = {10.1523/JNEUROSCI.0682-16.2016},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {local field potential,motivation,navigation,nucleus accumbens,rhythm,tetrode},
month = {oct},
number = {41},
pages = {10598--10610},
pmid = {27733611},
publisher = {Society for Neuroscience},
title = {{Reward Expectancy Strengthens CA1 Theta and Beta Band Synchronization and Hippocampal-Ventral Striatal Coupling}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0682-16.2016},
volume = {36},
year = {2016}
}
@article{Mulder2004,
abstract = {Hippocampal 'place' neurons discharge when rats occupy specific regions within an environment. This finding is a cornerstone of the theory of the hippocampus as a cognitive map of space. But for navigation, representations of current position must be implemented by signals concerning where to go next, and how to get there. In recordings in hippocampal output structures associated with the motor system (nucleus accumbens and ventromedial caudate nucleus) in rats solving a plus-maze, neurons fired continuously from the moment the rat left one location until it arrived at the next goal site, or at an intermediate place, such as the maze centre. While other studies have shown discharges during reward approach behaviours, this is the first demonstration of activity corresponding to the parsing of complex routes into sequences of movements between landmarks, similar to the lists of instructions we often employ to communicate directions to follow between points on a map. As these cells fired during a series of several paces or re-orientation movements, perhaps this is homologous to 'chunking'. The temporal overlaps in the activity profiles of the individual neurons provide a possible substrate to successively trigger movements required to arrive at the goal. These hippocampally informed, and in some cases, spatially selective responses support the view of the ventral striatum as an interface between limbic and motor systems, permitting contextual representations to have an impact on fundamental action sequences for goal-directed behaviour.},
author = {Mulder, Antonius B. and Tabuchi, Eiichi and Wiener, Sidney I.},
doi = {10.1111/j.1460-9568.2004.03301.x},
isbn = {0953-816X (Print)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Delay activity,Hippocampus,Learning,Place cell,Reward,Spatial memory},
month = {apr},
number = {7},
pages = {1923--1932},
pmid = {15078566},
publisher = {Blackwell Science, Ltd},
title = {{Neurons in hippocampal afferent zones of rat striatum parse routes into multi-pace segments during maze navigation}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2004.03301.x},
volume = {19},
year = {2004}
}
@misc{Humphries2010,
abstract = {The basal ganglia are often conceptualised as three parallel domains that include all the constituent nuclei. The 'ventral domain' appears to be critical for learning flexible behaviours for exploration and foraging, as it is the recipient of converging inputs from amygdala, hippocampal formation and prefrontal cortex, putatively centres for stimulus evaluation, spatial navigation, and planning/contingency, respectively. However, compared to work on the dorsal domains, the rich potential for quantitative theories and models of the ventral domain remains largely untapped, and the purpose of this review is to provide the stimulus for this work. We systematically review the ventral domain's structures and internal organisation, and propose a functional architecture as the basis for computational models. Using a full schematic of the structure of inputs to the ventral striatum (nucleus accumbens core and shell), we argue for the existence of many identifiable processing channels on the basis of unique combinations of afferent inputs. We then identify the potential information represented in these channels by reconciling a broad range of studies from the hippocampal, amygdala and prefrontal cortex literatures with known properties of the ventral striatum from lesion, pharmacological, and electrophysiological studies. Dopamine's key role in learning is reviewed within the three current major computational frameworks; we also show that the shell-based basal ganglia sub-circuits are well placed to generate the phasic burst and dip responses of dopaminergic neurons. We detail dopamine's modulation of ventral basal ganglia's inputs by its actions on pre-synaptic terminals and post-synaptic membranes in the striatum, arguing that the complexity of these effects hint at computational roles for dopamine beyond current ideas. The ventral basal ganglia are revealed as a constellation of multiple functional systems for the learning and selection of flexible behaviours and of behavioural strategies, sharing the common operations of selection-by-disinhibition and of dopaminergic modulation. {\textcopyright} 2009 Elsevier Ltd.},
author = {Humphries, Mark D. and Prescott, Tony J.},
booktitle = {Progress in Neurobiology},
doi = {10.1016/j.pneurobio.2009.11.003},
isbn = {1873-5118 (Electronic)$\backslash$n0301-0082 (Linking)},
issn = {03010082},
keywords = {Action selection,Core,Incentive salience,Nucleus accumbens,Reward prediction error,Shell,Spatial navigation},
number = {4},
pages = {385--417},
pmid = {19941931},
title = {{The ventral basal ganglia, a selection mechanism at the crossroads of space, strategy, and reward}},
volume = {90},
year = {2010}
}
@article{Syed2015,
abstract = {It is widely held that dopamine signaling encodes predictions of future rewards and such predictions are regularly used to drive behavior, but the relationship between these two is poorly defined. We found in rats that nucleus accumbens dopamine following a reward-predicting cue was attenuated unless movement was correctly initiated. Our results indicate that dopamine release in this region is contingent on correct action initiation and not just reward prediction.},
author = {Syed, Emilie C.J. and Grima, Laura L. and Magill, Peter J. and Bogacz, Rafal and Brown, Peter and Walton, Mark E.},
doi = {10.1038/nn.4187},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {15461726},
journal = {Nature Neuroscience},
month = {dec},
number = {1},
pages = {34--36},
pmid = {26642087},
publisher = {Nature Research},
title = {{Action initiation shapes mesolimbic dopamine encoding of future rewards}},
url = {http://www.nature.com/doifinder/10.1038/nn.4187},
volume = {19},
year = {2015}
}
@article{Fitzgerald2014,
abstract = {Multiple features of the environment are often imbued with motivational significance, and the relative importance of these can change across contexts. The ability to flexibly adjust evaluative processes so that currently important features of the environment alone drive behavior is critical to adaptive routines.Weknow relatively little about the neural mechanisms involved, including whether motivation- ally significant features are obligatorily evaluated or whether current relevance gates access to value-sensitive regions. We addressed these questions using functional magnetic resonance imaging data and a task design where human subjects had to choose whether to accept or rejectanoffer indicatedbyvisualandauditory stimuli.Bymanipulating,onatrial-by-trial basis,whichstimulusdeterminedthe value of the offer,weshowchoice activity in the ventral striatum solely reflects the value of the currently relevant stimulus, consistent with a model wherein behavioral relevance modulates the impact of sensory stimuli on value processing. Choice outcome signals in this same region covaried positively with wins on accept trials, and negatively with wins on reject trials, consistent with striatal activity at feedback reflecting correctness of response rather than reward processing per se. We conclude that ventral striatum activity during decision making is dynamically modulated by behavioral context, indexed here by task relevance and action selection.},
author = {FitzGerald, T. H. B. and Schwartenbeck, P. and Dolan, R. J.},
doi = {10.1523/JNEUROSCI.4389-13.2014},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {action value,multisensory,policy selection,reward,ventral striatum},
number = {4},
pages = {1271--1279},
pmid = {24453318},
title = {{Reward-Related Activity in Ventral Striatum Is Action Contingent and Modulated by Behavioral Relevance}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4389-13.2014},
volume = {34},
year = {2014}
}
@article{Bornstein2011b,
abstract = {The basal ganglia, in particular the striatum, are central to theories of behavioral control, and often identified as a seat of action selection. Reinforcement learning (RL) models. - which have driven much recent experimental work on this region. - cast striatum as a dynamic controller, integrating sensory and motivational information to construct efficient and enriching behavioral policies. Befitting this informationally central role, the BG sit at the nexus of multiple anatomical 'loops' of synaptic projections, connecting a wide range of cortical and subcortical structures. Numerous pioneering anatomical studies conducted over the past several decades have meticulously catalogued these loops, and labeled them according to the inferred functions of the connected regions. The specific cotermina of the projections are highly localized to several different subregions of the striatum, leading to the suggestion that these subregions perform complementary but distinct functions. However, until recently, the dominant computational framework outlined only a bipartite, dorsal/ventral, division of striatum. We review recent computational and experimental advances that argue for a more finely fractionated delineation. In particular, experimental data provide extensive insight into unique functions subserved by the dorsomedial striatum (DMS). These functions appear to correspond well with theories of a 'model-based' RL subunit, and may also shed light on the suborganization of ventral striatum. Finally, we discuss the limitations of these ideas and how they point the way toward future refinements of neurocomputational theories of striatal function, bringing them into contact with other areas of computational theory and other regions of the brain. {\textcopyright} 2011 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Bornstein, Aaron M. and Daw, Nathaniel D.},
doi = {10.1016/j.conb.2011.02.009},
eprint = {NIHMS150003},
isbn = {1873-6882 (Electronic)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {jun},
number = {3},
pages = {374--380},
pmid = {21429734},
title = {{Multiplicity of control in the basal ganglia: Computational roles of striatal subregions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438811000365},
volume = {21},
year = {2011}
}
@article{Floresco2006,
abstract = {The ability to behave in a flexible manner is an executive function mediated in part by different regions of the prefrontal cortex. The present study investigated the role of two major efferents of the prefrontal cortex, the nucleus accumbens (NAc) core and shell, in behavioral flexibility using a maze-based strategy set-shifting task. During initial discrimination training, rats learned to use either an egocentric response or a visual-cue discrimination strategy to obtain food reward. During the set shift, animals had to shift from the previously acquired response or visual-cue-based strategy and learn the alternate discrimination. Inactivation of the NAc core, induced by infusion of the GABA agonists baclofen and muscimol, did not impair initial acquisition of either a response or visual-cue discrimination but severely disrupted shifting from one strategy to another. Analysis of the type of errors revealed that impairments in set shifting were not attributable to increased perseveration but to a disruption of the acquisition and maintenance of a new strategy. In contrast, inactivation of the NAc shell did not impair acquisition of either a response or a visual-cue discrimination, or shifting from one strategy to another. However, inactivation of the NAc shell before initial discrimination training improved performance during the set shift relative to control animals. These data indicate that the NAc core and shell make dissociable contributions to behavioral flexibility during set shifting. The NAc core facilitates the acquisition and maintenance of novel behavioral strategies and elimination of inappropriate response options, whereas the shell may mediate learning about irrelevant stimuli.},
author = {Floresco, S. B.},
doi = {10.1523/JNEUROSCI.4431-05.2006},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weiner et al. - 1996 - Differential involvement of the shell and core subterritories of the nucleus accumbens in latent inhibition and a.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Analysis of Variance,Animals,Appetitive Behavior,Appetitive Behavior: physiology,Baclofen,Baclofen: pharmacology,Behavior, Animal,Conditioning, Operant,Conditioning, Operant: drug effects,Conditioning, Operant: physiology,Discrimination Learning,Discrimination Learning: drug effects,Discrimination Learning: physiology,Extinction, Psychological,Extinction, Psychological: drug effects,GABA Agonists,GABA Agonists: pharmacology,Maze Learning,Maze Learning: drug effects,Maze Learning: physiology,Muscimol,Muscimol: pharmacology,Nucleus Accumbens,Nucleus Accumbens: anatomy {\&} histology,Nucleus Accumbens: drug effects,Nucleus Accumbens: physiology,Photic Stimulation,Photic Stimulation: methods,Rats,Rats, Long-Evans,Set (Psychology),Time Factors},
month = {mar},
number = {9},
pages = {2449--2457},
pmid = {16510723},
title = {{Dissociable Roles for the Nucleus Accumbens Core and Shell in Regulating Set Shifting}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4431-05.2006},
volume = {26},
year = {2006}
}
@article{Aitken2016,
abstract = {Environmental reward-predictive stimuli provide a major source of motivation for instrumental reward-seeking activity and this has been linked to dopamine signaling in the nucleus accumbens (NAc) core. This cue-induced incentive motivation can be quite general, not restricted to instrumental actions that earn the same unique reward, and is also typically regulated by one's current need state, such that cues only motivate actions when this is adaptive. But it remains unknown whether cue-evoked dopamine signaling is similarly regulated by need state. Here, we used fast-scan cyclic voltammetry to monitor dopamine concentration changes in the NAc core of rats during a Pavlovian-to-instrumental transfer task in which the motivating influence of two cues, each signaling a distinct food reward (sucrose or food pellets), over an action earning a third unique food reward (polycose) was assessed in a state of hunger and of satiety. Both cues elicited a robust NAc dopamine response when hungry. The magnitude of the sucrose cue-evoked dopamine response correlated with the Pavlovian-to-instrumental transfer effect that was selectively induced by this stimulus. Satiety attenuated these cue-evoked dopamine responses and behavioral responding, even though rats had never experienced the specific food rewards in this state. These data demonstrate that cue-evoked NAc core responses are sensitive to current need state, one critical variable that determines the current adaptive utility of cue-motivated behavior. Food-predictive stimuli motivate food-seeking behavior. Here, we show that food cues evoke a robust nucleus accumbens core dopamine response when hungry that correlates with the cue's ability to invigorate general food seeking. This response is attenuated when sated, demonstrating that food cue-evoked accumbens dopamine responses are sensitive to the need state information that determines the current adaptive utility of cue-motivated action.},
author = {Aitken, Tara J. and Greenfield, Venuz Y. and Wassum, Kate M.},
doi = {10.1111/jnc.13494},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aitken, Greenfield, Wassum - 2016 - Nucleus accumbens core dopamine signaling tracks the need-based motivational value of food-paired cu.pdf:pdf},
issn = {14714159},
journal = {Journal of Neurochemistry},
keywords = {Pavlovian-to-instrumental transfer,hunger,mesolimbic dopamine,reward,satiety,voltammetry},
month = {mar},
number = {5},
pages = {1026--1036},
pmid = {26715366},
title = {{Nucleus accumbens core dopamine signaling tracks the need-based motivational value of food-paired cues}},
url = {http://doi.wiley.com/10.1111/jnc.13494},
volume = {136},
year = {2016}
}
@article{Day2006,
abstract = {Environmental stimuli predictive of appetitive events can elicit Pavlovian approach responses that enhance an organism's ability to track and secure natural rewards, but may also contribute to the compulsive nature of drug addiction. Here, we examined the activity of individual nucleus accumbens (NAc) neurons during an autoshaping paradigm. One conditioned stimulus (CS+, a retractable lever presented for 10 s) was immediately followed by the delivery of a 45-mg sucrose pellet to a food receptacle, while another stimulus (CS-, a separate retractable lever presented for 10 s) was never followed by sucrose. Approach responses directed at the CS+ and CS- were recorded as lever presses and had no experimental consequence. Rats (n = 9) selectively approached the CS+ on more than 80{\%} of trials and were surgically prepared for electrophysiological recording. Of 76 NAc neurons, 57 cells (75{\%}) exhibited increases and/or decreases in firing rate (i.e. termed 'phasically active') during the CS+ presentation and corresponding approach response. Forty-seven percent of phasically active cells (27 out of 57) were characterized by time-locked but transient increases in cell firing, while 53{\%} (30 out of 57) showed a significant reduction in firing for the duration of the CS+. In contrast, the same excitatory subpopulation exhibited smaller increases in activity relative to CS- onset, while the inhibitory subpopulation showed no change in firing during the CS- period. The magnitude and prevalence of cue-related neural responses reported here indicates that the NAc encodes biologically significant, repetitive approach responses that may model the compulsive nature of drug addiction in humans.},
author = {Day, Jeremy J. and Wheeler, Robert A. and Roitman, Mitchell F. and Carelli, Regina M.},
doi = {10.1111/j.1460-9568.2006.04654.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Day et al. - 2006 - Nucleus accumbens neurons encode Pavlovian approach behaviors evidence from an autoshaping paradigm.pdf:pdf},
isbn = {0953-816X (Print)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Addiction,Associative learning,Conditioning,Electrophysiology,Reward},
month = {mar},
number = {5},
pages = {1341--1351},
pmid = {16553795},
publisher = {Blackwell Publishing Ltd},
title = {{Nucleus accumbens neurons encode Pavlovian approach behaviors: Evidence from an autoshaping paradigm}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2006.04654.x},
volume = {23},
year = {2006}
}
@article{Costa2016,
abstract = {Reinforcement learning (RL) theories posit that dopaminergic signals are integrated within the striatum to associate choices with outcomes. Often overlooked is that the amygdala also receives dopaminergic input and is involved in Pavlovian processes that influence choice behavior. To determine the relative contributions of the ventral striatum (VS) and amygdala to appetitive RL, we tested rhesus macaques with VS or amygdala lesions on deterministic and stochastic versions of a two-arm bandit reversal learning task. When learning was characterized with an RL model relative to controls, amygdala lesions caused general decreases in learning from positive feedback and choice consistency. By comparison, VS lesions only affected learning in the stochastic task. Moreover, the VS lesions hastened the monkeys' choice reaction times, which emphasized a speed-accuracy trade-off that accounted for errors in deterministic learning. These results update standard accounts of RL by emphasizing distinct contributions of the amygdala and VS to RL.},
author = {Costa, Vincent D. and {Dal Monte}, Olga and Lucas, Daniel R. and Murray, Elisabeth A. and Averbeck, Bruno B.},
doi = {10.1016/j.neuron.2016.09.025},
issn = {10974199},
journal = {Neuron},
keywords = {Bayesian,Pearce-Hall,Rescorla-Wagner,amygdala,associability,decision making,lesion,reinforcement learning,speed-accuracy trade-off,ventral striatum},
month = {oct},
number = {2},
pages = {505--517},
pmid = {27720488},
title = {{Amygdala and Ventral Striatum Make Distinct Contributions to Reinforcement Learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627316305840},
volume = {92},
year = {2016}
}
@article{Ito2015,
abstract = {Previous theoretical studies of animal and human behavioral learning have focused on the dichotomy of the value-based strategy using action value functions to predict rewards and the model-based strategy using internal models to predict environmental states. However, animals and humans often take simple procedural behaviors, such as the "win-stay, lose-switch" strategy without explicit prediction of rewards or states. Here we consider another strategy, the finite state-based strategy, in which a subject selects an action depending on its discrete internal state and updates the state depending on the action chosen and the reward outcome. By analyzing choice behavior of rats in a free-choice task, we found that the finite state-based strategy fitted their behavioral choices more accurately than value-based and model-based strategies did. When fitted models were run autonomously with the same task, only the finite state-based strategy could reproduce the key feature of choice sequences. Analyses of neural activity recorded from the dorsolateral striatum (DLS), the dorsomedial striatum (DMS), and the ventral striatum (VS) identified significant fractions of neurons in all three subareas for which activities were correlated with individual states of the finite state-based strategy. The signal of internal states at the time of choice was found in DMS, and for clusters of states was found in VS. In addition, action values and state values of the value-based strategy were encoded in DMS and VS, respectively. These results suggest that both the value-based strategy and the finite state-based strategy are implemented in the striatum.},
author = {Ito, Makoto and Doya, Kenji},
doi = {10.1371/journal.pcbi.1004540},
editor = {Sporns, Olaf},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ito et al. - 2015 - Parallel Representation of Value-Based and Finite State-Based Strategies in the Ventral and Dorsal Striatum.pdf:pdf},
isbn = {1553734X},
issn = {15537358},
journal = {PLoS Computational Biology},
month = {nov},
number = {11},
pages = {e1004540},
pmid = {26529522},
publisher = {Public Library of Science},
title = {{Parallel Representation of Value-Based and Finite State-Based Strategies in the Ventral and Dorsal Striatum}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1004540},
volume = {11},
year = {2015}
}
@misc{Karlsson2012,
abstract = {Regions within the prefrontal cortex are thought to process beliefs about the world, but little is known about the circuit dynamics underlying the formation and modification of these beliefs. Using a task that permits dissociation between the activity encoding an animal's internal state and that encoding aspects of behavior, we found that transient increases in the volatility of activity in the rat medial prefrontal cortex accompany periods when an animal's belief is modified after an environmental change. Activity across the majority of sampled neurons underwent marked, abrupt, and coordinated changes when prior belief was abandoned in favor of exploration of alternative strategies. These dynamics reflect network switches to a state of instability, which diminishes over the period of exploration as new stable representations are formed.},
author = {Karlsson, Mattias P. and Tervo, Dougal G R and Karpova, Alla Y.},
booktitle = {Science},
doi = {10.1126/science.1226518},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {10959203},
number = {6103},
pages = {135--139},
pmid = {23042898},
title = {{Network resets in medial prefrontal cortex mark the onset of behavioral uncertainty}},
volume = {338},
year = {2012}
}
@article{Robinson2009,
abstract = {Background: If presentation of a stimulus (conditional stimulus, CS) reliably predicts delivery of a reward, the CS will come to evoke a conditional response (CR) through Pavlovian learning, and the CS may also acquire incentive motivational properties. Thus, CSs can have both predictive and incentive properties. We ask here whether it is possible to dissociate the predictive versus incentive properties of a CS in rats by considering individual differences in the nature of the CR. Methods: We used Pavlovian procedures to study the ability of a localizable CS (an illuminated lever) to acquire two properties of an incentive stimulus-the ability to attract and the ability to act as a conditional reinforcer. Results: For some rats, the CS evoked a "sign-tracking" CR, consisting of approach toward and engagement with the CS itself. For other rats, the CS instead produced a "goal-tracking" CR: approach was directed away from the CS toward the site of food delivery. For sign-trackers (but not goal-trackers) the CS also acted as an effective conditional reinforcer. Conclusions: The predictive and incentive properties of a CS can be dissociated by considering individual differences in the CR. In a given animal, a cue that is predictive of reward, supporting Pavlovian learning, may or may not be attributed with incentive salience. This procedure may provide a powerful means to test hypotheses regarding the role of neural systems in learning versus incentive motivational functions and to study individual variation in the extent to which reward-associated stimuli act as incentive stimuli. {\textcopyright} 2009 Society of Biological Psychiatry.},
author = {Robinson, Terry E. and Flagel, Shelly B.},
doi = {10.1016/j.biopsych.2008.09.006},
isbn = {0006-3223},
issn = {00063223},
journal = {Biological Psychiatry},
keywords = {Autoshaping,Pavlovian conditioning,conditional reinforcement,goal-tracking,incentive motivation,incentive salience,learning,sign-tracking},
month = {may},
number = {10},
pages = {869--873},
pmid = {18930184},
title = {{Dissociating the Predictive and Incentive Motivational Properties of Reward-Related Cues Through the Study of Individual Differences}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18930184 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2737368 http://linkinghub.elsevier.com/retrieve/pii/S0006322308010949},
volume = {65},
year = {2009}
}
@article{Bissonette2013,
abstract = {Neurons in the ventral striatum (VS) fire to cues that predict differently valued rewards. It is unclear whether this activity represents the value associated with the expected reward or the level of motivation induced by reward anticipation. To distinguish between the two, we trained rats on a task in which we varied value independently from motivation by manipulating the size of the reward expected on correct trials and the threat of punishment expected upon errors. We found that separate populations of neurons in VS encode expected value and motivation.},
author = {Bissonette, Gregory B. and Burton, Amanda C. and Gentry, Ronny N. and Goldstein, Brandon L. and Hearn, Taylor N. and Barnett, Brian R. and Kashtelyan, Vadim and Roesch, Matthew R.},
doi = {10.1371/journal.pone.0064673},
editor = {Zhuang, Xiaoxi},
isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
month = {may},
number = {5},
pages = {e64673},
pmid = {23724077},
publisher = {Public Library of Science},
title = {{Separate Populations of Neurons in Ventral Striatum Encode Value and Motivation}},
url = {http://dx.plos.org/10.1371/journal.pone.0064673},
volume = {8},
year = {2013}
}
@article{Yang1984,
abstract = {Extracellular single unit recordings were obtained from neurones in the nucleus accumbens of urethane anaesthetized rats. Single pulse stimulation (300-800 $\mu$A, 0.15 ms, 0.5-1.5 Hz) of the ventral subiculum of the hippocampus strongly excited silent and spontaneously active (3-6 spikes/s) medial accumbens neurones. The majority of neurones excited by hippocampal stimulation were quiescent and identified only by the elicited action potentials. Neurones on the dorso-medial border of the nucleus accumbens and adjacent lateral septum, with a faster spontaneous discharge rate (8-12 spikes/s), were inhibited by hippocampal stimulation. In the ventral border of the accumbens and the olfactory tubercle, hippocampal stimulation also inhibited the fast-firing ({\textgreater} 20 spikes/s) neurones. When trains of 10 conditioning pulses (300-800 $\mu$A, 0.15 ms, 10 Hz) were delivered to the ventral tegmental area (VTA) 100 ms before each single-pulse stimulation of the hippocampus, the excitatory responses of the silent and spontaneously active accumbens neurones were attenuated. The possibility of this relatively prolonged attenuation effect being dopamine-mediated was supported by several lines of evidence. Dopamine, applied iontophoretically, reduced markedly the excitatory response of accumbens neurones to hippocampal stimulation. Iontophoretically applied dopamine mimicked the attenuating effect produced by VTA conditioning stimulation in the same neurone. The attenuating effects of VTA conditioning stimulation on the activation of accumbens neurones by hippocampal stimulation was reduced by: (1) administration of 6-hydroxydopamine to the VTA 2 days and 7-9 days prior to the recording session, (2) the intraperitoneal injection of haloperidol 1 h before the recording session, and (3) the iontophoretic application of trifluoperazine to accumbens neurones. These observations support the hypothesis that the attenuating effects of the mesolimbic dopamine system on limbic inputs to the nucleus accumbens may have a role in limbic-motor integration. {\textcopyright} 1984.},
author = {{R. Yang}, Charles and {J. Mogenson}, Gordon},
doi = {10.1016/0006-8993(84)90623-1},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 1984 - Electrophysiological responses of neurones in the nucleus accumbens to hippocampal stimulation and the attenuation.pdf:pdf},
issn = {00068993},
journal = {Brain Research},
keywords = {hippocampus,mesolimbic dopamine system,nucleus accumbens,ventral tegmental area},
month = {dec},
number = {1},
pages = {69--84},
pmid = {6151418},
publisher = {Society for Neuroscience},
title = {{Electrophysiological responses of neurones in the nucleus accumbens to hippocampal stimulation and the attenuation of the excitatory responses by the mesolimbic dopaminergic system}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6151418},
volume = {324},
year = {1984}
}
@article{Corbit2011,
abstract = {Tests of Pavlovian-instrumental transfer (PIT) demonstrate that reward-predictive stimuli can exert a powerful motivational influence on the performance of instrumental actions. Recent evidence suggests that predictive stimuli produce this effect through either the general arousal (general PIT) or the specific predictions (outcome-specific PIT) produced by their association with reward. In two experiments, we examined the effects of pretraining lesions (Experiment 1) or muscimol-induced inactivation (Experiment 2) of either the core or shell regions of the nucleus accumbens (NAC) on these forms of PIT. Rats received Pavlovian training in which three auditory stimuli each predicted the delivery of a distinct food outcome. Separately, the rats were trained to perform two instrumental actions, each of which earned one of the outcomes used in Pavlovian conditioning. Finally, the effects of the three stimuli on performance of the two actions were assessed in extinction. Here we report evidence of a double dissociation between general and outcome-specific PIT at the level of the accumbens. Shell lesions eliminated outcome-specific PIT but spared general PIT, whereas lesions of the core abolished general PIT but spared outcome-specific PIT. Importantly, the infusion of muscimol into core or shell made immediately before the PIT tests produced a similar pattern of results. These results suggest that whereas the NAC core mediates the general excitatory effects of reward-related cues, the NAC shell mediates the effect of outcome-specific reward predictions on instrumental performance, and thereby serve to clarify reported discrepancies regarding the role of the NAC core and shell in PIT.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Corbit, L. H. and Balleine, B. W.},
doi = {10.1523/JNEUROSCI.2711-11.2011},
eprint = {NIHMS150003},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {aug},
number = {33},
pages = {11786--11794},
pmid = {21849539},
title = {{The General and Outcome-Specific Forms of Pavlovian-Instrumental Transfer Are Differentially Mediated by the Nucleus Accumbens Core and Shell}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2711-11.2011},
volume = {31},
year = {2011}
}
@article{Hauber2000,
abstract = {Expectancy of future reward is an important factor guiding the speed of instrumental behavior. The present study sought to explore whether signals transmitted via the NMDA subtype of glutamate receptors and via dopamine D(2) receptors in the nucleus accumbens (NAc) are critical for the determination of reaction times (RTs) of instrumental responses by the expectancy of future reward. A simple RT task for rats demanding conditioned lever release was used in which the upcoming reward magnitude (5 or 1 pellet) was signaled in advance by discriminative stimuli. In trained rats, RTs of conditioned responses with expectancy of a high reward magnitude were found to be significantly shorter. The shortening of RTs by stimuli predictive of high reward to be obtained was dose-dependently impaired by bilateral intra-NAc infusion of the competitive NMDA antagonist dl-2-amino-5-phosphonovaleric acid (APV) (1, 2, or 10 microg in 0.5 microl/side), but not by infusion of the preferential dopamine D(2) antagonist haloperidol (5 and 12.5 microg in 0.5 microl/side) or by infusion of vehicle (0.5 microl/side). In conclusion, the data reveal that in well trained animals stimulation of intra-NAc NMDA, but not of dopamine D(2), receptors, is critically involved in guiding the speed of instrumental responses according to stimuli predictive of the upcoming reward magnitude.},
author = {Hauber, W and Bohn, I and Giertler, C},
doi = {20/16/6282 [pii]},
isbn = {0270-6474 (Print)$\backslash$r0270-6474 (Linking)},
issn = {02706474},
journal = {J Neurosci},
keywords = {*Reward,Animal/drug effects/*physiology,Animals,Behavior,Dopamine D2/drug effects/*metabolism,Male,Motor Activity/drug effects/physiology,N-Methyl-D-Aspartate/drug effects/*metabolism,Neuropsychological Tests,Nucleus Accumbens/cytology/drug effects/*metabolis,Psychomotor Performance/drug effects/*physiology,Rats,Reaction Time/drug effects/physiology,Receptors,Sprague-Dawley},
month = {aug},
number = {16},
pages = {6282--6288},
pmid = {10934279},
publisher = {Society for Neuroscience},
title = {{NMDA, but not dopamine D(2), receptors in the rat nucleus accumbens areinvolved in guidance of instrumental behavior by stimuli predicting reward magnitude}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10934279},
volume = {20},
year = {2000}
}
@article{Ambroggi2008,
abstract = {Both the nucleus accumbens (NAc) and basolateral amygdala (BLA) contribute to learned behavioral choice. Neurons in both structures that encode reward-predictive cues may underlie the decision to respond to such cues, but the neural circuits by which the BLA influences reward-seeking behavior have not been established. Here, we test the hypothesis that the BLA drives NAc neuronal responses to reward-predictive cues. First, using a disconnection experiment, we show that the BLA and dopamine projections to the NAc interact to promote the reward-seeking behavioral response. Next, we demonstrate that BLA neuronal responses to cues precede those of NAc neurons and that cue-evoked excitation of NAc neurons depends on BLA input. These results indicate that BLA input is required for dopamine to enhance the cue-evoked firing of NAc neurons and that this enhanced firing promotes reward-seeking behavior. {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Ambroggi, Frederic and Ishikawa, Akinori and Fields, Howard L. and Nicola, Saleem M.},
doi = {10.1016/j.neuron.2008.07.004},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
keywords = {SIGNALING,SYSBIO,SYSNEURO},
month = {aug},
number = {4},
pages = {648--661},
pmid = {18760700},
title = {{Basolateral Amygdala Neurons Facilitate Reward-Seeking Behavior by Exciting Nucleus Accumbens Neurons}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18760700 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2603341 http://linkinghub.elsevier.com/retrieve/pii/S0896627308005734},
volume = {59},
year = {2008}
}
@article{Sleezer2016,
abstract = {Activemaintenanceof rules, like other executive functions, is often thought to be the domain of a discrete executive system.Analternative view is that rule maintenance is a broadly distributed function relyingonwidespread corticalandsubcortical circuits. Tentative evidence supporting this view comes from research showing some rule selectivity in the orbitofrontal cortex and dorsal striatum.Werecorded in these regions and in the ventral striatum, which has not been associated previously with rule representation, as macaques performed a Wisconsin Card Sorting Task.Wefound robust encoding of rule category (color vs shape) and rule identity (six possible rules) in all three regions. Rule identity modulated responses to potential choice targets, suggesting that rule information guides behavior by highlighting choice targets. The effects that we observed were not explained by differences in behavioral performance across rules and thus cannot be attributed torewardexpectation.Ourresults suggest that rulemaintenanceandrule-guided selection of options are distributed processes and provide new insight into orbital and striatal contributions to executive control.},
author = {Sleezer, B. J. and Castagno, M. D. and Hayden, B. Y.},
doi = {10.1523/JNEUROSCI.1766-16.2016},
isbn = {1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {decision making,executive control,macaque,orbitofrontal cortex,single unit,striatum},
month = {nov},
number = {44},
pages = {11223--11237},
pmid = {27807165},
publisher = {Society for Neuroscience},
title = {{Rule Encoding in Orbitofrontal Cortex and Striatum Guides Selection}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1766-16.2016},
volume = {36},
year = {2016}
}
@article{Zaehle2013,
abstract = {Theoretical models and empirical work indicate a critical role of the NAcc in salience processing. For instance, the NAcc not only responds to appetitive and aversive information, but it also signals novelty, contextual deviance, and action monitoring. However, because most studies have investigated only one specific type of salience independently, it remains unclear how the NAcc concurrently differentiates between different forms of salience. To investigate this issue, we used intracranial electroencephalography in human epilepsy patients together with a previously established visual oddball paradigm. Here, three different oddball categories (novel, neutral, and target images) were infrequently presented among a standard scene image, and subjects responded to the target via button press. This task allowed us to differentiate "item novelty" (new vs neutral oddballs) from "contextual deviance" (neutral oddballs vs standard images) and "targetness" (target vs neutral oddballs). Time-frequency analysis revealed a dissociation between item novelty and contextual deviance on the basis of decreases in either $\theta$ (4-8 Hz) or $\beta$ power (20-30 Hz). Targetness, on the other hand, was signaled by positive deflections in the stimulus-locked local field potentials, which, importantly, correlated with subjects' reaction times. These findings indicate that, in an ongoing stream of information, the NAcc differentiates between types of salience by distinct neural mechanisms to guide goal-directed behavior.},
author = {Zaehle, T. and Bauch, E. M. and Hinrichs, H. and Schmitt, F. C. and Voges, J. and Heinze, H.-J. and Bunzeck, N.},
doi = {10.1523/JNEUROSCI.5276-12.2013},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaehle et al. - 2013 - Nucleus accumbens activity dissociates different forms of salience evidence from human intracranial recordings.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {may},
number = {20},
pages = {8764--8771},
pmid = {23678119},
publisher = {Society for Neuroscience},
title = {{Nucleus Accumbens Activity Dissociates Different Forms of Salience: Evidence from Human Intracranial Recordings}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5276-12.2013},
volume = {33},
year = {2013}
}
@article{Day2007a,
abstract = {The ability to predict favorable outcomes using environmental cues is an essential part of learned behavior. Dopamine neurons in the midbrain encode such stimulus-reward relationships in a manner consistent with contemporary learning models, but it is unclear how encoding this translates into actual dopamine release in target regions. Here, we sampled dopamine levels in the rat nucleus accumbens on a rapid (100 ms) timescale using electrochemical technology during a classical conditioning procedure. Early in conditioning, transient dopamine-release events signaled a primary reward, but not predictive cues. After repeated cue-reward pairings, dopamine signals shifted in time to predictive cue onset and were no longer observed at reward delivery. In the absence of stimulus-reward conditioning, there was no shift in the dopamine signal. Consistent with proposed roles in reward prediction and incentive salience, these results indicate that rapid dopamine release provides a reward signal that is dynamically modified by associative learning.},
author = {Day, Jeremy J. and Roitman, Mitchell F. and Wightman, R. Mark and Carelli, Regina M.},
doi = {10.1038/nn1923},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Day et al. - Unknown - Associative learning mediates dynamic shifts in dopamine signaling in the nucleus accumbens.pdf:pdf},
isbn = {1097-6256 (Print)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {8},
pages = {1020--1028},
pmid = {17603481},
title = {{Associative learning mediates dynamic shifts in dopamine signaling in the nucleus accumbens}},
url = {http://www.nature.com/neuro/journal/v10/n8/pdf/nn1923.pdf},
volume = {10},
year = {2007}
}
@article{Durstewitz2010,
abstract = {One of the most intriguing aspects of adaptive behavior involves the inference of regularities and rules in ever-changing environments. Rules are often deduced through evidence-based learning which relies on the prefrontal cortex (PFC). This is a highly dynamic process, evolving trial by trial and therefore may not be adequately captured by averaging single-unit responses over numerous repetitions. Here, we employed advanced statistical techniques to visualize the trajectories of ensembles of simultaneously recorded medial PFC neurons on a trial-by-trial basis as rats deduced a novel rule in a set-shifting task. Neural populations formed clearly distinct and lasting representations of familiar and novel rules by entering unique network states. During rule acquisition, the recorded ensembles often exhibited abrupt transitions, rather than evolving continuously, in tight temporal relation to behavioral performance shifts. These results support the idea that rule learning is an evidence-based decision process, perhaps accompanied by moments of sudden insight. {\textcopyright} 2010 Elsevier Inc.},
author = {Durstewitz, Daniel and Vittoz, Nicole M. and Floresco, Stan B. and Seamans, Jeremy K.},
doi = {10.1016/j.neuron.2010.03.029},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
number = {3},
pages = {438--448},
pmid = {20471356},
title = {{Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning}},
volume = {66},
year = {2010}
}
@article{Aggarwal2012a,
abstract = {In the past few decades there has been remarkable convergence of machine learning with neurobiological understanding of reinforcement learning mechanisms, exemplified by temporal difference (TD) learning models. The anatomy of the basal ganglia provides a number of potential substrates for instantiation of the TD mechanism. In contrast to the traditional concept of direct and indirect pathway outputs from the striatum, we emphasize that projection neurons of the striatum are branched and individual striatofugal neurons innervate both globus pallidus externa and globus pallidus interna/substantia nigra (GPi/SNr). This suggests that the GPi/SNr has the necessary inputs to operate as the source of a TD signal. We also discuss the mechanism for the timing processes necessary for learning in the TD framework. The TD framework has been particularly successful in analysing electrophysiogical recordings from dopamine (DA) neurons during learning, in terms of reward prediction error. However, present understanding of the neural control of DA release is limited, and hence the neural mechanisms involved are incompletely understood. Inhibition is very conspicuously present among the inputs to the DA neurons, with inhibitory synapses accounting for the majority of synapses on DA neurons. Furthermore, synchronous firing of the DA neuron population requires disinhibition and excitation to occur together in a coordinated manner. We conclude that the inhibitory circuits impinging directly or indirectly on the DA neurons play a central role in the control of DA neuron activity and further investigation of these circuits may provide important insight into the biological mechanisms of reinforcement learning.},
author = {Aggarwal, Mayank and Hyland, Brian I. and Wickens, Jeffery R.},
doi = {10.1111/j.1460-9568.2012.08055.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal, Hyland, Wickens - Unknown - Neural control of dopamine neurotransmission implications for reinforcement learning.pdf:pdf},
isbn = {1460-9568},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Basal ganglia,GABA,Striatum,Temporal difference},
number = {7},
pages = {1115--1123},
pmid = {22487041},
title = {{Neural control of dopamine neurotransmission: Implications for reinforcement learning}},
url = {https://s3.amazonaws.com/objects.readcube.com/articles/downloaded/wiley/f1b7d51b5e40ce16bb3a504630a2333c8920fdfbbb477143fd37672b602018d2.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256{\&}X-Amz-Credential=AKIAIS5LBPCM5JPOCDGQ{\%}2F20170321{\%}2Fus-east-1{\%}2Fs3{\%}2Faws4{\_}request{\&}},
volume = {35},
year = {2012}
}
@article{Lee2012,
abstract = {Reinforcement learning is an adaptive process in which an animal utilizes its previous experience to improve the outcomes of future choices. Computational theories of reinforcement learning play a central role in the newly emerging areas of neuroeconomics and decision neuroscience. In this framework, actions are chosen according to their value functions, which describe how much future reward is expected from each action. Value functions can be adjusted not only through reward and penalty, but also by the animal's knowledge of its current environment. Studies have revealed that a large proportion of the brain is involved in representing and updating value functions and using them to choose an action. However, how the nature of a behavioral task affects the neural mechanisms of reinforcement learning remains incompletely understood. Future studies should uncover the principles by which different computational elements of reinforcement learning are dynamically coordinated across the entire brain.},
author = {Lee, Daeyeol and Seo, Hyojung and Jung, Min Whan},
doi = {10.1146/annurev-neuro-062111-150512},
isbn = {0147-006X},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {neuroeconomics,prefrontal cortex,reward,striatum,uncertainty},
number = {1},
pages = {287--308},
pmid = {22462543},
title = {{Neural Basis of Reinforcement Learning and Decision Making}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-062111-150512},
volume = {35},
year = {2012}
}
@article{Hollerman1998,
abstract = {Hollerman, Jeffrey R., L{\'{e}}on Tremblay, and Wolfram Schultz. Influence of reward expectation on behavior-related neuronal activity in primate striatum. J. Neurophysiol. 80: 947–963, 1998. Rewards constitute important goals for voluntary behavior. This study aimed to investigate how expected rewards influence behavior-related neuronal activity in the anterior striatum. In a delayed go-nogo task, monkeys executed or withheld a reaching movement and obtained liquid or sound as reinforcement. An initial instruction picture indicated the behavioral reaction to be performed and the reinforcer to be obtained after a subsequent trigger stimulus. Movements varied according to the reinforcers predicted by the instructions, suggesting that animals differentially expected the two outcomes. About 250 of nearly 1,500 neurons in anterior parts of caudate nucleus, putamen, and ventral striatum showed typical task-related activations that reflected the expectation of instructions and trigger, and the preparation, initiation...},
author = {Hollerman, Jeffrey R. and Tremblay, L{\'{e}}on and Schultz, Wolfram},
doi = {10.1152/jn.1998.80.2.947},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
month = {aug},
number = {2},
pages = {947--963},
publisher = { American Physiological SocietyBethesda, MD },
title = {{Influence of Reward Expectation on Behavior-Related Neuronal Activity in Primate Striatum}},
url = {http://www.physiology.org/doi/10.1152/jn.1998.80.2.947},
volume = {80},
year = {1998}
}
@article{Khamassi2012,
abstract = {Behavior in spatial navigation is often organized into map-based (place-driven) vs. map-free (cue-driven) strategies; behavior in operant conditioning research is often organized into goal-directed vs. habitual strategies. Here we attempt to unify the two. We review one powerful theory for distinct forms of learning during instrumental conditioning, namely model-based (maintaining a representation of the world) and model-free (reacting to immediate stimuli) learning algorithms. We extend these lines of argument to propose an alternative taxonomy for spatial navigation, showing how various previously identified strategies can be distinguished as "model-based" or "model-free" depending on the usage of information and not on the type of information (e.g., cue vs. place). We argue that identifying "model-free" learning with dorsolateral striatum and "model-based" learning with dorsomedial striatum could reconcile numerous conflicting results in the spatial navigation literature. From this perspective, we further propose that the ventral striatum plays key roles in the model-building process. We propose that the core of the ventral striatum is positioned to learn the probability of action selection for every transition between states of the world. We further review suggestions that the ventral striatal core and shell are positioned to act as "critics" contributing to the computation of a reward prediction error for model-free and model-based systems, respectively.},
author = {Khamassi, Mehdi and Humphries, Mark D.},
doi = {10.3389/fnbeh.2012.00079},
isbn = {1662-5153 (Electronic)$\backslash$r1662-5153 (Linking)},
issn = {1662-5153},
journal = {Frontiers in Behavioral Neuroscience},
keywords = {action-outcome,habit,nucleus accumbens,reinforcement learning,stimulus-response},
pages = {79},
pmid = {23205006},
publisher = {Frontiers Media SA},
title = {{Integrating cortico-limbic-basal ganglia architectures for learning model-based and model-free navigation strategies}},
url = {http://journal.frontiersin.org/article/10.3389/fnbeh.2012.00079/abstract},
volume = {6},
year = {2012}
}
@article{Ikemoto2007,
abstract = {Anatomical and functional refinements of the meso-limbic dopamine system of the rat are discussed. Present experiments suggest that dopaminergic neurons localized in the posteromedial ventral tegmental area (VTA) and central linear nucleus raphe selectively project to the ventromedial striatum (medial olfactory tubercle and medial nucleus accumbens shell), whereas the anteromedial VTA has few if any projections to the ventral striatum, and the lateral VTA largely projects to the ventrolateral striatum (accumbens core, lateral shell and lateral tubercle). These findings complement the recent behavioral findings that cocaine and amphetamine are more rewarding when administered into the ventromedial striatum than into the ventrolateral striatum. Drugs such as nicotine and opiates are more rewarding when administered into the posterior VTA or the central linear nucleus than into the anterior VTA. A review of the literature suggests that (1) the midbrain has corresponding zones for the accumbens core and medial shell; (2) the striatal portion of the olfactory tubercle is a ventral extension of the nucleus accumbens shell; and (3) a model of two dopamine projection systems from the ventral midbrain to the ventral striatum is useful for understanding reward function. The medial projection system is important in the regulation of arousal characterized by affect and drive and plays a different role in goal-directed learning than the lateral projection system, as described in the variation-selection hypothesis of striatal functional organization.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ikemoto, Satoshi},
doi = {10.1016/j.brainresrev.2007.05.004},
eprint = {NIHMS150003},
isbn = {0165-0173},
issn = {01650173},
journal = {Brain Research Reviews},
keywords = {Arousal,Autoshaping,Caudal linear nucleus,Reinforcement,Ventral striatum,Ventral tegmental area},
month = {nov},
number = {1},
pages = {27--78},
pmid = {17574681},
title = {{Dopamine reward circuitry: Two projection systems from the ventral midbrain to the nucleus accumbens-olfactory tubercle complex}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17574681 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2134972 http://linkinghub.elsevier.com/retrieve/pii/S0165017307000756},
volume = {56},
year = {2007}
}
@article{Steinberg2013,
abstract = {Situations in which rewards are unexpectedly obtained or withheld represent opportunities for new learning. Often, this learning includes identifying cues that predict reward availability. Unexpected rewards strongly activate midbrain dopamine neurons. This phasic signal is proposed to support learning about antecedent cues by signaling discrepancies between actual and expected outcomes, termed a reward prediction error. However, it is unknown whether dopamine neuron prediction error signaling and cue-reward learning are causally linked. To test this hypothesis, we manipulated dopamine neuron activity in rats in two behavioral procedures, associative blocking and extinction, that illustrate the essential function of prediction errors in learning. We observed that optogenetic activation of dopamine neurons concurrent with reward delivery, mimicking a prediction error, was sufficient to cause long-lasting increases in cue-elicited reward-seeking behavior. Our findings establish a causal role for temporally precise dopamine neuron signaling in cue-reward learning, bridging a critical gap between experimental evidence and influential theoretical frameworks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Steinberg, Elizabeth E. and Keiflin, Ronald and Boivin, Josiah R. and Witten, Ilana B. and Deisseroth, Karl and Janak, Patricia H.},
doi = {10.1038/nn.3413},
eprint = {arXiv:1011.1669v3},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {15461726},
journal = {Nature Neuroscience},
number = {7},
pages = {966--973},
pmid = {23708143},
title = {{A causal link between prediction errors, dopamine neurons and learning}},
url = {http://www.nature.com/doifinder/10.1038/nn.3413},
volume = {16},
year = {2013}
}
@article{DiCiano2008,
abstract = {Drug-paired conditioned reinforcers can maintain persistent instrumental responding, thus providing a model of some aspects of long-term drug addiction. The purpose of the present study was to investigate the effects of inactivating the dorsal striatum (DStr), nucleus accumbens (NAcc) core, or NAcc shell on different types of responding, each maintained by drug-paired conditioned reinforcers. Inactivations were achieved by infusing a combination of baclofen and muscimol prior to (1) persistent responding for a drug-paired conditioned reinforcer, (2) reacquisition of this instrumental response after extinction by omission of the contingent conditioned stimulus (CS), or (3) CS (cue)-induced reinstatement of the original (and different) instrumental response that had previously delivered cocaine. Inactivation of the DStr attenuated persistent responding for a cocaine-paired conditioned reinforcer, as well as its reacquisition after extinction of this response, while the only effect of inactivation of the NAcc shell was to increase CS (cue)-induced reinstatement of the extinguished instrumental response that had previously delivered cocaine. Inactivation of the NAcc core affected all measures of responding maintained by drug-paired conditioned reinforcers. These results are discussed with reference to the neural systems involved in different aspects of responding maintained by drug-paired conditioned reinforcers.},
author = {{Di Ciano}, Patricia and Robbins, Trevor W. and Everitt, Barry J.},
doi = {10.1038/sj.npp.1301522},
isbn = {0893-133X (Print)},
issn = {0893133X},
journal = {Neuropsychopharmacology},
keywords = {Addiction,Drug-seeking,Habit,Inactivation,Rat,Reinstatement},
month = {may},
number = {6},
pages = {1413--1425},
pmid = {17712353},
publisher = {Nature Publishing Group},
title = {{Differential effects of nucleus accumbens core, shell, or dorsal striatal inactivations on the persistence, reacquisition, or reinstatement of responding for a drug-paired conditioned reinforcer}},
url = {http://www.nature.com/articles/1301522},
volume = {33},
year = {2008}
}
@article{Flagel2011,
abstract = {Individuals make choices and prioritize goals using complex processes that assign value to rewards and associated stimuli. During Pavlovian learning, previously neutral stimuli that predict rewards can acquire motivational properties, becoming attractive and desirable incentive stimuli. However, whether a cue acts solely as a predictor of reward, or also serves as an incentive stimulus, differs between individuals. Thus, individuals vary in the degree to which cues bias choice and potentially promote maladaptive behaviour. Here we use rats that differ in the incentive motivational properties they attribute to food cues to probe the role of the neurotransmitter dopamine in stimulus-reward learning. We show that intact dopamine transmission is not required for all forms of learning in which reward cues become effective predictors. Rather, dopamine acts selectively in a form of stimulus-reward learning in which incentive salience is assigned to reward cues. In individuals with a propensity for this form of learning, reward cues come to powerfully motivate and control behaviour. This work provides insight into the neurobiology of a form of stimulus-reward learning that confers increased susceptibility to disorders of impulse control.},
author = {Flagel, Shelly B. and Clark, Jeremy J. and Robinson, Terry E. and Mayo, Leah and Czuj, Alayna and Willuhn, Ingo and Akers, Christina A. and Clinton, Sarah M. and Phillips, Paul E M and Akil, Huda},
doi = {10.1038/nature09588},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {00280836},
journal = {Nature},
month = {jan},
number = {7328},
pages = {53--59},
pmid = {21150898},
publisher = {Nature Research},
title = {{A selective role for dopamine in stimulus-reward learning}},
url = {http://www.nature.com/doifinder/10.1038/nature09588},
volume = {469},
year = {2011}
}
@article{Pennartz2004,
abstract = {Previously it has been shown that the hippocampus and neocortex can spontaneously reactivate ensemble activity patterns during post-behavioral sleep and rest periods. Here we examined whether such reactivation also occurs in a subcortical structure, the ventral striatum, which receives a direct input from the hippocampal formation and has been implicated in guidance of consummatory and conditioned behaviors. During a reward-searching task on a T-maze, flanked by sleep and rest periods, parallel recordings were made from ventral striatal ensembles while EEG signals were derived from the hippocampus. Statistical measures indicated a significant amount of reactivation in the ventral striatum. In line with hippocampal data, reactivation was especially prominent during post-behavioral slow-wave sleep, but unlike the hippocampus, no decay in pattern recurrence was visible in the ventral striatum across the first 40 min of post-behavioral rest. We next studied the relationship between ensemble firing patterns in ventral striatum and hippocampal ripples-sharp waves, which have been implicated in pattern replay. Firing rates were significantly modulated in close temporal association with hippocampal ripples in 25{\%} of the units, showing a marked transient enhancement in the average response profile. Strikingly, ripple-modulated neurons in ventral striatum showed a clear reactivation, whereas nonmodulated cells did not. These data suggest, first, the occurrence of pattern replay in a subcortical structure implied in the processing and prediction of reward and, second, a functional linkage between ventral striatal reactivation and a specific type of high-frequency population activity associated with hippocampal replay.},
author = {Pennartz, C. M. A.},
doi = {10.1523/JNEUROSCI.0575-04.2004},
isbn = {1529-2401 (Electronic)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jul},
number = {29},
pages = {6446--6456},
pmid = {15269254},
publisher = {Society for Neuroscience},
title = {{The Ventral Striatum in Off-Line Processing: Ensemble Reactivation during Sleep and Modulation by Hippocampal Ripples}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0575-04.2004},
volume = {24},
year = {2004}
}
@article{Kapur2003,
abstract = {OBJECTIVE: The clinical hallmark of schizophrenia is psychosis. The objective of this overview is to link the neurobiology (brain), the phenomenological experience (mind), and pharmacological aspects of psychosis-in-schizophrenia into a unitary framework. METHOD: Current ideas regarding the neurobiology and phenomenology of psychosis and schizophrenia, the role of dopamine, and the mechanism of action of antipsychotic medication were integrated to develop this framework. RESULTS: A central role of dopamine is to mediate the “salience” of environmental events and internal representations. It is proposed that a dysregulated, hyperdopaminergic state, at a “brain” level of description and analysis, leads to an aberrant assignment of salience to the elements of one's experience, at a “mind” level. Delusions are a cognitive effort by the patient to make sense of these aberrantly salient experiences, whereas hallucinations reflect a direct experience of the aberrant salience of internal representations. Antipsyc...},
author = {Kapur, Shitij},
doi = {10.1176/appi.ajp.160.1.13},
isbn = {0002-953X (Print)$\backslash$r0002-953X (Linking)},
issn = {0002953X},
journal = {American Journal of Psychiatry},
month = {jan},
number = {1},
pages = {13--23},
pmid = {12505794},
title = {{Psychosis as a state of aberrant salience: A framework linking biology, phenomenology, and pharmacology in schizophrenia}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12505794 http://psychiatryonline.org/doi/abs/10.1176/appi.ajp.160.1.13},
volume = {160},
year = {2003}
}
@article{Sugam2014,
abstract = {Background To make appropriate decisions, organisms must evaluate the risks and benefits of action selection. The nucleus accumbens (NAc) has been shown to be critical for this processing and is necessary for appropriate risk-based decision-making behavior. However, it is not clear how NAc neurons encode this information to promote appropriate behavioral responding. Methods Here, rats (n = 17) were trained to perform a risky decision-making task in which discrete visual cues predicted the availability to respond for a smaller certain (safer) or larger uncertain (riskier) reward. Electrophysiological recordings were made in the NAc core and shell to evaluate neural activity during task performance. Results At test, animals exhibited individual differences in risk-taking behavior; some displayed a preference for the risky option, some the safe option, and some did not have a preference. Electrophysiological analysis indicated that NAc neurons differentially encoded information related to risk versus safe outcomes. Further, during free choice trials, neural activity during reward-predictive cues reflected individual behavioral preferences. In addition, neural encoding of reward outcomes was correlated with risk-taking behavior, with safe-preferring and risk-preferring rats showing differential activity in the NAc core and shell during reward omissions. Conclusions Consistent with previously demonstrated alterations in prospective reward value with effort and delay, NAc neurons encode information during reward-predictive cues and outcomes in a risk task that tracked the rats' preferred responses. This processing appears to contribute to subjective encoding of anticipated outcomes and thus may function to bias future risk-based decisions. {\textcopyright} 2014 Society of Biological Psychiatry.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Sugam, Jonathan A. and Saddoris, Michael P. and Carelli, Regina M.},
doi = {10.1016/j.biopsych.2013.09.010},
eprint = {NIHMS150003},
isbn = {1873-2402 (Electronic) 0006-3223 (Linking)},
issn = {18732402},
journal = {Biological Psychiatry},
keywords = {Decision making,electrophysiology,nucleus accumbens,reward,risk taking,value},
month = {may},
number = {10},
pages = {807--816},
pmid = {24143880},
publisher = {Elsevier},
title = {{Nucleus accumbens neurons track behavioral preferences and reward outcomes during risky decision making}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24143880 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3992205},
volume = {75},
year = {2014}
}
@article{Schultz1997a,
abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Schultz, W. and Dayan, P. and Montague, P. R.},
doi = {10.1126/science.275.5306.1593},
eprint = {NIHMS150003},
isbn = {0036-8075},
issn = {00368075},
journal = {Science},
month = {mar},
number = {5306},
pages = {1593--1599},
pmid = {9054347},
title = {{A neural substrate of prediction and reward}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.275.5306.1593},
volume = {275},
year = {1997}
}
@article{Hauber2000a,
abstract = {The ventral striatum (VS) is thought to signal the predicted value of expected outcomes. However, it is still unclear whether VS can encode value independently from variables often yoked to value such as response direction and latency. Expectations of high value reward are often associated with a particular action and faster latencies. To address this issue we trained rats to perform a task in which the size of the predicted reward was signaled before the instrumental response was instructed. Instrumental directional cues were presented briefly at a variable onset to reduce accuracy and increase reaction time. Rats were more accurate and slower when a large versus small reward was at stake. We found that activity in VS was high during odors that predicted large reward even though reaction times were slower under these conditions. In addition to these effects, we found that activity prior to the reward predicting cue reflected past and predicted reward. These results demonstrate that VS can encode value independent of motor contingencies and that VS's role in goal-directed behavior is not just to increase vigor of specific actions when more is at stake.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Goldstein, B. L. and Barnett, B. R. and Vasquez, G. and Tobia, S. C. and Kashtelyan, V. and Burton, A. C. and Bryden, D. W. and Roesch, M. R.},
doi = {10.1523/JNEUROSCI.5349-11.2012},
eprint = {NIHMS150003},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {aug},
number = {6},
pages = {2027--2036},
pmid = {22323717},
publisher = {Society for Neuroscience},
title = {{Ventral Striatum Encodes Past and Predicted Value Independent of Motor Contingencies}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5349-11.2012},
volume = {32},
year = {2012}
}
@article{Lansink2008,
abstract = {Spontaneous "off-line" reactivation of neuronal activity patterns may contribute to the consolidation of memory traces. The ventral striatum exhibits reactivation and has been implicated in the processing of motivational information. It is unknown, however, whether reactivating neuronal ensembles specifically recapitulate information relating to rewards that were encountered during wakefulness. We demonstrate a prolonged reactivation in rat ventral striatum during quiet wakefulness and slow-wave but not rapid eye movement sleep. Reactivation of reward-related information processed in this structure was particularly prominent, and this was primarily attributable to spike trains temporally linked to reward sites. It was accounted for by small, strongly correlated subgroups in recorded cell assemblies and can thus be characterized as a sparse phenomenon. Our results indicate that reactivated memory traces may not only comprise feature- and context-specific information but also contain a value component.},
author = {Lansink, C. S. and Goltstein, P. M. and Lankelma, J. V. and Joosten, R. N. J. M. A. and McNaughton, B. L. and Pennartz, C. M. A.},
doi = {10.1523/JNEUROSCI.1054-08.2008},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jun},
number = {25},
pages = {6372--6382},
pmid = {18562607},
publisher = {Society for Neuroscience},
title = {{Preferential Reactivation of Motivationally Relevant Information in the Ventral Striatum}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1054-08.2008},
volume = {28},
year = {2008}
}
@article{Stuber2011,
abstract = {The basolateral amygdala (BLA) has a crucial role in emotional learning irrespective of valence. The BLA projection to the nucleus accumbens (NAc) is thought to modulate cue-triggered motivated behaviours, but our understanding of the interaction between these two brain regions has been limited by the inability to manipulate neural-circuit elements of this pathway selectively during behaviour. To circumvent this limitation, we used in vivo optogenetic stimulation or inhibition of glutamatergic fibres from the BLA to the NAc, coupled with intracranial pharmacology and ex vivo electrophysiology. Here we show that optical stimulation of the pathway from the BLA to the NAc in mice reinforces behavioural responding to earn additional optical stimulation of these synaptic inputs. Optical stimulation of these glutamatergic fibres required intra-NAc dopamine D1-type receptor signalling, but not D2-type receptor signalling. Brief optical inhibition of fibres from the BLA to the NAc reduced cue-evoked intake of sucrose, demonstrating an important role of this specific pathway in controlling naturally occurring reward-related behaviour. Moreover, although optical stimulation of glutamatergic fibres from the medial prefrontal cortex to the NAc also elicited reliable excitatory synaptic responses, optical self-stimulation behaviour was not observed by activation of this pathway. These data indicate that whereas the BLA is important for processing both positive and negative affect, the glutamatergic pathway from the BLA to the NAc, in conjunction with dopamine signalling in the NAc, promotes motivated behavioural responding. Thus, optogenetic manipulation of anatomically distinct synaptic inputs to the NAc reveals functionally distinct properties of these inputs in controlling reward-seeking behaviours.},
author = {Stuber, Garret D. and Sparta, Dennis R. and Stamatakis, Alice M. and {Van Leeuwen}, Wieke A. and Hardjoprajitno, Juanita E. and Cho, Saemi and Tye, Kay M. and Kempadoo, Kimberly A. and Zhang, Feng and Deisseroth, Karl and Bonci, Antonello},
doi = {10.1038/nature10194},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stuber et al. - 2011 - Excitatory transmission from the amygdala to nucleus accumbens facilitates reward seeking.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {00280836},
journal = {Nature},
number = {7356},
pages = {377--382},
pmid = {21716290},
title = {{Excitatory transmission from the amygdala to nucleus accumbens facilitates reward seeking}},
url = {http://www.nature.com/nature/journal/v475/n7356/pdf/nature10194.pdf},
volume = {475},
year = {2011}
}
@article{Maia2011,
abstract = {Over the last decade and a half, reinforcement learning models have fostered an increasingly sophisticated understanding of the functions of dopamine and cortico-basal ganglia-thalamo-cortical (CBGTC) circuits. More recently, these models, and the insights that they afford, have started to be used to understand important aspects of several psychiatric and neurological disorders that involve disturbances of the dopaminergic system and CBGTC circuits. We review this approach and its existing and potential applications to Parkinson's disease, Tourette's syndrome, attention-deficit/hyperactivity disorder, addiction, schizophrenia and preclinical animal models used to screen new antipsychotic drugs. The approach's proven explanatory and predictive power bodes well for the continued growth of computational psychiatry and computational neurology.},
author = {Maia, Tiago V. and Frank, Michael J.},
doi = {10.1038/nn.2723},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {2},
pages = {154--162},
pmid = {21270784},
title = {{From reinforcement learning models to psychiatric and neurological disorders}},
url = {https://www.nature.com/articles/nn.2723.pdf},
volume = {14},
year = {2011}
}
@article{Kaczkurkin2015,
abstract = {A review of the literature demonstrates a lack of research on fear-generalization processes in many anxiety disorders including obsessive-compulsive disorder (OCD) and posttraumatic stress disorder (PTSD). Chapter 2 represents the first study that attempted to investigate the generalization of conditioned fear in individuals with obsessive-compulsive traits using startle EMG and behavioral measures. The results of this study demonstrated that individuals with high levels of Threat Estimation as measured by the Obsessive Beliefs Questionnaire (OBQ-44) displayed overgeneralization of fear responses to a greater range of stimuli resembling the danger cue than those with low levels of Threat Estimation. In addition, despite etiological theories proposing that fear conditioning and overgeneralization of fear play prominent roles in the development and maintenance of PTSD, little research had been done on the neurobiological mechanisms that contribute to fear conditioning processes in PTSD patients and none have been specifically conducted on generalization. Chapter 3 investigated the neurobiological substrates associated with the overgeneralization of conditioned fear in PTSD patients using behavioral, skin conductance, and functional magnetic resonance imaging (fMRI) measures. This study provides evidence that PTSD patients demonstrate overgeneralization of conditioned fear in the dorsal medial prefrontal cortex, bilateral insula, left and right caudate, left inferior parietal lobule, and right superior frontal gyrus. This body of work provides novel evidence regarding the generalization of conditioned fear in OCD and PTSD. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
author = {Kaczkurkin, Antonia},
isbn = {0419-4217(Print)},
journal = {Dissertation Abstracts International: Section B: The Sciences and Engineering},
number = {3-B(E)},
pages = {No Pagination Specified},
title = {{The contribution of fear conditioning to pathological anxiety: An investigation of conditioned fear generalization in ocd traits and ptsd}},
url = {https://conservancy.umn.edu/bitstream/handle/11299/167172/Kaczkurkin{\_}umn{\_}0130E{\_}14221.pdf?sequence=1{\&}isAllowed=y http://ovidsp.ovid.com/ovidweb.cgi?T=JS{\&}CSC=Y{\&}NEWS=N{\&}PAGE=fulltext{\&}D=psyc12{\&}AN=2015-99180-249{\%}0Ahttp://zp2yn2et6f.search.serialssolutions.com/?},
volume = {76},
year = {2015}
}
@article{Walsh2011,
abstract = {When feedback follows a sequence of decisions, relationships between actions and outcomes can be difficult to learn. We used event-related potentials (ERPs) to understand how people overcome this temporal credit assignment problem. Participants performed a sequential decision task that required two decisions on each trial. The first decision led to an intermediate state that was predictive of the trial outcome, and the second decision was followed by positive or negative trial feedback. The feedback-related negativity (fERN), a component thought to reflect reward prediction error, followed negative feedback and negative intermediate states. This suggests that participants evaluated intermediate states in terms of expected future reward, and that these evaluations supported learning of earlier actions within sequences. We examine the predictions of several temporal-difference models to determine whether the behavioral and ERP results reflected a reinforcement-learning process.},
author = {Walsh, Matthew M. and Anderson, John R.},
doi = {10.3758/s13415-011-0027-0},
isbn = {1531-135X (Electronic)$\backslash$n1530-7026 (Linking)},
issn = {15307026},
journal = {Cognitive, Affective and Behavioral Neuroscience},
keywords = {Actor/critic,Credit assignment,Eligibility traces,Event-related potentials,Q-learning,SARSA,Temporal difference learning},
month = {jun},
number = {2},
pages = {131--143},
pmid = {21416212},
publisher = {Springer-Verlag},
title = {{Learning from delayed feedback: Neural responses in temporal credit assignment}},
url = {http://www.springerlink.com/index/10.3758/s13415-011-0027-0},
volume = {11},
year = {2011}
}
@article{Atallah2014,
abstract = {The ventromedial striatum (VMS) is a node in circuits underpinning both affect and reinforcement learning. The cellular bases of these functions and especially their potential linkages have been unclear. VMS cholinergic interneurons, however, have been singled out as being related both to affect and to reinforcement-based conditioning, raising the possibility that unique aspects of their signaling could account for these functions. Here we show that VMS tonically active neurons (TANs), including putative cholinergic interneurons, generate unique bidirectional outcome responses during reward-based learning, reporting both positive (reward) and negative (reward omission) outcomes when behavioral change is prompted by switches in reinforcement contingencies. VMS output neurons (SPNs), by contrast, are nearly insensitive to switches in reinforcement contingencies, gradually losing outcome signaling while maintaining responses at trial initiation and goal approach. Thus, TANs and SPNs in the VMS provide distinct signals optimized for different aspects of the learning process. •Plasticity in ventromedial striatum during reward learning is cell-type specific•Cholinergic interneurons signal outcome and track reinforcement contingencies•Spiny projection neurons (SPNs) lose outcome responses during learning•SPNs maintain responses at trial initiation and goal approach during learning. Atallah etal. demonstrate that in the ventromedial striatum, a region related to emotion, special sets of neurons signal the success or failure of behaviors as animals learn. After learning, this signal subsides, suggesting that it is a true learning signal. {\textcopyright} 2014 Elsevier Inc.},
author = {Atallah, Hisham E. and McCool, Andrew D. and Howe, Mark W. and Graybiel, Ann M.},
doi = {10.1016/j.neuron.2014.04.021},
isbn = {1097-4199 (Electronic)$\backslash$n0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
month = {jun},
number = {5},
pages = {1145--1156},
pmid = {24908491},
publisher = {Cell Press},
title = {{Neurons in the ventral striatum exhibit cell-type-specific representations of outcome during learning}},
url = {https://www.sciencedirect.com/science/article/pii/S0896627314003353},
volume = {82},
year = {2014}
}
@article{Setlow2003,
abstract = {A growing body of evidence implicates the ventral striatum in using information acquired through associative learning. The present study examined the activity of ventral striatal neurons in awake, behaving rats during go/no-go odor discrimination learning and reversal. Many neurons fired selectively to odor cues predictive of either appetitive (sucrose) or aversive (quinine) outcomes. Few neurons were selective when first exposed to the odors, but many acquired this differential activity as rats learned the significance of the cues. A substantial proportion of these neurons encoded the cues' learned motivational significance, and these neurons tended to reverse their firing selectivity after reversal of odor-outcome contingencies. Other neurons that became selectively activated during learning did not reverse, but instead appeared to encode specific combinations of cues and associated motor responses. The results support a role for ventral striatum in using the learned significance, both appetitive and aversive, of predictive cues to guide behavior.},
author = {Setlow, Barry and Schoenbaum, Geoffrey and Gallagher, Michela},
doi = {10.1016/S0896-6273(03)00264-2},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
month = {may},
number = {4},
pages = {625--636},
pmid = {12765613},
title = {{Neural encoding in ventral striatum during olfactory discrimination learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12765613},
volume = {38},
year = {2003}
}
@article{Crone2005,
abstract = {The ability to retrieve and flexibly switch between task rules is seen as an important component of cognitive control. It is often assumed that lateral prefrontal cortex (latPFC) is important for switching between rules. However, activation associated with rule-switching is less reliably observed in latPFC than in medial PFC (specifically, pre-supplementary motor area). In this study, we tested the hypothesis that medial PFC is important for reconfiguration of task sets, whereas latPFC is important for retrieving, maintaining and implementing relevant rules (i.e. rule representation). Twenty young adults participated in a functional magnetic resonance imaging study in which they determined the correct response to a target stimulus on the basis of an instructional cue. For bivalent targets, the appropriate response depended on the currently relevant rule. In contrast, univalent targets were always associated with the same response. Brain regions of interest were characterized according to their responsiveness to bivalent and univalent targets, on both rule-switch and rule-repetition trials. The data support the hypothesis that rule representation and task-set reconfiguration are separable cognitive processes, associated with dissociable neural activation in latPFC and medial PFC, respectively. Activation profiles of posterior parietal cortex, basal ganglia and rostrolateral PFC are also examined and discussed.},
author = {Crone, Eveline A. and Wendelken, Carter and Donohue, Sarah E. and Bunge, Silvia A.},
doi = {10.1093/cercor/bhi127},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Crone et al. - 2005 - Neural Evidence for Dissociable Components of Task-switching.pdf:pdf},
isbn = {1047-3211 (Print)$\backslash$n1047-3211 (Linking)},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {Context,Goal,Reconfiguration,Rule,Task set,Task switching,VLPFC,pre-SMA},
month = {jun},
number = {4},
pages = {475--486},
pmid = {16000652},
publisher = {Oxford University Press},
title = {{Neural evidence for dissociable components of task-switching}},
url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhi127},
volume = {16},
year = {2006}
}
@article{Birrell2000a,
abstract = {Forming place-reward associations critically depends on the integrity of the hippocampal-ventral striatal system. The ventral striatum (VS) receives a strong hippocampal input conveying spatial-contextual information, but it is unclear how this structure integrates this information to invigorate reward-directed behavior. Neuronal ensembles in rat hippocampus (HC) and VS were simultaneously recorded during a conditioning task in which navigation depended on path integration. In contrast to HC, ventral striatal neurons showed low spatial selectivity, but rather coded behavioral task phases toward reaching goal sites. Outcome-predicting cues induced a remapping of firing patterns in the HC, consistent with its role in episodic memory. VS remapped in conjunction with the HC, indicating that remapping can take place in multiple brain regions engaged in the same task. Subsets of ventral striatal neurons showed a "flip" from high activity when cue lights were illuminated to low activity in intertrial intervals, or vice versa. The cues induced an increase in spatial information transmission and sparsity in both structures. These effects were paralleled by an enhanced temporal specificity of ensemble coding and a more accurate reconstruction of the animal's position from population firing patterns. Altogether, the results reveal strong differences in spatial processing between hippocampal area CA1 and VS, but indicate similarities in how discrete cues impact on this processing.},
author = {Lansink, C. S. and Jackson, J. C. and Lankelma, J. V. and Ito, R. and Robbins, T. W. and Everitt, B. J. and Pennartz, C. M. A.},
doi = {10.1523/JNEUROSCI.0593-12.2012},
isbn = {0270-6474; 1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jun},
number = {36},
pages = {12444--12459},
pmid = {22956836},
publisher = {Society for Neuroscience},
title = {{Reward Cues in Space: Commonalities and Differences in Neural Coding by Hippocampal and Ventral Striatal Ensembles}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0593-12.2012},
volume = {32},
year = {2012}
}
@article{DuHoffmann2014,
abstract = {Approach to reward is a fundamental adaptive behavior, disruption of which is a core symptom of addiction and depression. Nucleus accumbens (NAc) dopamine is required for reward-predictive cues to activate vigorous reward seeking, but the underlying neural mechanism is unknown. Reward-predictive cues elicit both dopamine release in the NAc and excitations and inhibitions in NAc neurons. However, a direct link has not been established between dopamine receptor activation, NAc cue-evoked neuronal activity, and reward-seeking behavior. Here, we use a novel microelectrode array that enables simultaneous recording of neuronal firing and local dopamine receptor antagonist injection. We demonstrate that, in the NAc of rats performing a discriminative stimulus task for sucrose reward, blockade of either D1 or D2 receptors selectively attenuates excitation, but not inhibition, evoked by reward-predictive cues. Furthermore, we establish that this dopamine-dependent signal is necessary for reward-seeking behavior. These results demonstrate a neural mechanism by which NAc dopamine invigorates environmentally cued reward-seeking behavior.},
author = {du Hoffmann, J. and Nicola, S. M.},
doi = {10.1523/JNEUROSCI.3492-14.2014},
isbn = {0270-6474 1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {cue-excited neurons,discriminative stimulus,dopamine,nucleus accumbens,reward seeking},
month = {oct},
number = {43},
pages = {14349--14364},
pmid = {25339748},
title = {{Dopamine Invigorates Reward Seeking by Promoting Cue-Evoked Excitation in the Nucleus Accumbens}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3492-14.2014},
volume = {34},
year = {2014}
}
@article{McGinty2013,
abstract = {A key function of the nucleus accumbens is to promote vigorous reward seeking, but the corresponding neural mechanism has not been identified despite many years of research. Here, we study cued flexible approach behavior, a form of reward seeking that strongly depends on the accumbens, and we describe a robust, single-cell neural correlate of behavioral vigor in the excitatory response of accumbens neurons to reward-predictive cues. Well before locomotion begins, this cue-evoked excitation predicts both the movement initiation latency and the speed of subsequent flexible approach responses, but not those of stereotyped, inflexible responses. Moreover, the excitation simultaneously signals the subject@s proximity to the approach target, a signal that appears to mediate greater response vigor on trials that begin with the subject closer to the target. These results demonstrate a neural mechanism for response invigoration whereby accumbens neuronal encoding of reward availability and target proximity together drive the onset and speed of reward-seeking locomotion},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {McGinty, Vincent B. and Lardeux, Sylvie and Taha, Sharif A. and Kim, James J. and Nicola, Saleem M.},
doi = {10.1016/j.neuron.2013.04.010},
eprint = {NIHMS150003},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
month = {jun},
number = {5},
pages = {910--922},
pmid = {23764290},
publisher = {Cell Press},
title = {{Invigoration of reward seeking by cue and proximity encoding in the nucleus accumbens}},
url = {https://www.sciencedirect.com/science/article/pii/S0896627313003127},
volume = {78},
year = {2013}
}
@article{Parkinson2000,
abstract = {The nucleus accumbens (NAcc) has been implicated in a variety of forms of reward-related learning, reflecting its anatomical connections with limbic cortical structures. After confirming that excitotoxic lesions of the anterior cingulate cortex (Ant Cing) impaired the acquisition of appetitive Pavlovian conditioning in an autoshaping procedure, the effects of excitotoxic lesions to the NAcc core or shell on autoshaping were also assessed. Only selective core lesions impaired Pavlovian approach. A subsequent experiment studied the effects of a disconnection of the Ant Cing and NAcc core, using an asymmetric lesion procedure, to determine whether these structures interact sequentially as part of a limbic corticostriatal system. Such lesioned rats were also significantly impaired relative to controls at autoshaping. These results demonstrate that the NAcc core and Ant Cing are "nodes" of a corticostriatal circuit involved in stimulus-reward learning.},
author = {Parkinson, John A. and Willoughby, Pamela J. and Robbins, Trevor W. and Everitt, Barry J.},
doi = {10.1037//0735-7044.114.1.42},
isbn = {0735-7044 (Print)$\backslash$r0735-7044 (Linking)},
issn = {07357044},
journal = {Behavioral Neuroscience},
number = {1},
pages = {42--63},
pmid = {10718261},
title = {{Disconnection of the anterior cingulate cortex and nucleus accumbens core impairs pavlovian approach behavior: Further evidence for limbic cortical-ventral striatopallidal systems}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0735-7044.114.1.42},
volume = {114},
year = {2000}
}
@article{Hamid2015,
abstract = {Dopamine cell firing can encode errors in reward prediction, providing a learning signal to guide future behavior. Yet dopamine is also a key modulator of motivation, invigorating current behavior. Existing theories propose that fast (phasic) dopamine fluctuations support learning, whereas much slower (tonic) dopamine changes are involved in motivation. We examined dopamine release in the nucleus accumbens across multiple time scales, using complementary microdialysis and voltammetric methods during adaptive decision-making. We found that minute-by-minute dopamine levels covaried with reward rate and motivational vigor. Second-by-second dopamine release encoded an estimate of temporally discounted future reward (a value function). Changing dopamine immediately altered willingness to work and reinforced preceding action choices by encoding temporal-difference reward prediction errors. Our results indicate that dopamine conveys a single, rapidly evolving decision variable, the available reward for investment of effort, which is employed for both learning and motivational functions.},
author = {Hamid, Arif A. and Pettibone, Jeffrey R. and Mabrouk, Omar S. and Hetrick, Vaughn L. and Schmidt, Robert and {Vander Weele}, Caitlin M. and Kennedy, Robert T. and Aragona, Brandon J. and Berke, Joshua D.},
doi = {10.1038/nn.4173},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {15461726},
journal = {Nature Neuroscience},
month = {nov},
number = {1},
pages = {117--126},
pmid = {26595651},
publisher = {Nature Research},
title = {{Mesolimbic dopamine signals the value of work}},
url = {http://www.nature.com/doifinder/10.1038/nn.4173},
volume = {19},
year = {2015}
}
@article{Alvarez2016,
abstract = {The study by Calipari et al. in PNAS provides a glimpse into the in vivo pattern of neuronal activation in the mouse nucleus accumbens during the acquisition and expression of learned reward–context associations (1). The nucleus accumbens sits in the ventral part of the mouse striatum, and is required for reward-motivated learning. The activity of neurons in this region is thought to code information on the reward value of cues and contexts. Two distinct subpopulations of striatal neurons can be identified based on their anatomical projections and the degree of expression of dopamine D1 and D2 receptors. Striatal neurons expressing D1 receptors (D1-expressing neurons) have been shown to enhance reward learning, whereas striatal neurons expressing D2 receptors (D2-expressing neurons) have been shown to reduce reward learning when activated via optogenetic stimulation (2, 3). These manipulations, together with decades of experimentation in the field, have led to consensus around a general model in which the outputs of D1-expressing neurons and D2-expressing neurons exert opposing actions on coding of reward value and where the balance of activity between these outputs determines the final state (Fig. 1A). Based on this conceptual framework, predictions can be made about the activity of D1- and D2-expressing neurons during reward learning. However, recording the activity of the striatal neurons in a cell-specific manner has been very difficult. To this end, Calipari et al. (1) introduce the genetically coded calcium indicator GCaMP6 selectively in D1- or D2-expressing neurons of the nucleus accumbens, and use fiber photometry to monitor the calcium signals generated in this cell-specific fashion during the acquisition of condition place preference for cocaine. It is important to stress that although each detected calcium signal is generated by the firing of one or more},
author = {Alvarez, Veronica A.},
doi = {10.1073/pnas.1601162113},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alvarez - 2016 - Clues on the coding of reward cues by the nucleus accumbens.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {mar},
number = {10},
pages = {2560--2562},
pmid = {26917689},
publisher = {National Academy of Sciences},
title = {{Clues on the coding of reward cues by the nucleus accumbens}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1601162113},
volume = {113},
year = {2016}
}
@article{Roesch2009,
abstract = {The ventral striatum (VS) is thought to serve as a gateway whereby associative information from the amygdala and prefrontal regions can influence motor output to guide behavior. If VS mediates this "limbic-motor" interface, then one might expect neural correlates in VS to reflect this information. Specifically, neural activity should reflect the integration of motivational value with subsequent behavior. To test this prediction, we recorded from single units in VS while rats performed a choice task in which different odor cues indicated that reward was available on the left or on the right. The value of reward associated with a left or rightward movement was manipulated in separate blocks of trials by either varying the delay preceding reward delivery or by changing reward size. Rats' behavior was influenced by the value of the expected reward and the response required to obtain it, and activity in the majority of cue-responsive VS neurons reflected the integration of these two variables. Unlike similar cue-evoked activity reported previously in dopamine neurons, these correlates were only observed if the directional response was subsequently executed. Furthermore, activity was correlated with the speed at which the rats' executed the response. These results are consistent with the notion that VS serves to integrate information about the value of an expected reward with motor output during decision making.},
author = {Roesch, M. R. and Singh, T. and Brown, P. L. and Mullins, S. E. and Schoenbaum, G.},
doi = {10.1523/JNEUROSCI.2572-09.2009},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {42},
pages = {13365--13376},
pmid = {19846724},
title = {{Ventral Striatal Neurons Encode the Value of the Chosen Action in Rats Deciding between Differently Delayed or Sized Rewards}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2572-09.2009},
volume = {29},
year = {2009}
}
@article{Ishikawa2008,
abstract = {Cue-elicited phasic changes in firing of nucleus accumbens (NAc) neurons can facilitate reward-seeking behavior. Here, we test the hypothesis that the medial prefrontal cortex (mPFC), which sends a dense glutamatergic projection to the NAc core, contributes to NAc neuronal firing responses to reward-predictive cues. Rats trained to perform an operant response to a cue for sucrose were implanted with recording electrodes in the core of the NAc and microinjection cannulas in the dorsal mPFC (dmPFC). The cue-evoked firing of NAc neurons was reduced by bilateral injection of GABA(A) and GABA(B) agonists into the dmPFC concomitant with loss of behavioral responding to the cue. In addition, unilateral dmPFC inactivation reduced ipsilateral cue excitations and contralateral cue inhibitions. These findings indicate that cue-evoked excitations and inhibitions of NAc core neurons depend on dmPFC projections to the NAc and that these phasic changes contribute to the behavioral response to reward-predictive cues.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ishikawa, A. and Ambroggi, F. and Nicola, S. M. and Fields, H. L.},
doi = {10.1523/JNEUROSCI.0253-08.2008},
eprint = {NIHMS150003},
isbn = {1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {may},
number = {19},
pages = {5088--5098},
pmid = {18463262},
publisher = {Society for Neuroscience},
title = {{Dorsomedial Prefrontal Cortex Contribution to Behavioral and Nucleus Accumbens Neuronal Responses to Incentive Cues}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0253-08.2008},
volume = {28},
year = {2008}
}
@article{Maia2011a,
abstract = {Over the last decade and a half, reinforcement learning models have fostered an increasingly sophisticated understanding of the functions of dopamine and cortico-basal ganglia-thalamo-cortical (CBGTC) circuits. More recently, these models, and the insights that they afford, have started to be used to understand important aspects of several psychiatric and neurological disorders that involve disturbances of the dopaminergic system and CBGTC circuits. We review this approach and its existing and potential applications to Parkinson's disease, Tourette's syndrome, attention-deficit/hyperactivity disorder, addiction, schizophrenia and preclinical animal models used to screen new antipsychotic drugs. The approach's proven explanatory and predictive power bodes well for the continued growth of computational psychiatry and computational neurology.},
author = {Maia, Tiago V and Frank, Michael J},
doi = {10.1038/nn.2723},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {2},
pages = {154--162},
pmid = {21270784},
title = {{From reinforcement learning models to psychiatric and neurological disorders}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21270784 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4408000 http://www.nature.com/articles/nn.2723},
volume = {14},
year = {2011}
}
@article{Schultz1997,
abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Schultz, W. and Dayan, P. and Montague, P. R.},
doi = {10.1126/science.275.5306.1593},
eprint = {NIHMS150003},
isbn = {0036-8075},
issn = {00368075},
journal = {Science},
month = {mar},
number = {5306},
pages = {1593--1599},
pmid = {9054347},
publisher = {American Association for the Advancement of Science},
title = {{A neural substrate of prediction and reward}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9054347},
volume = {275},
year = {1997}
}
@article{Lissek2014,
abstract = {Background Meta-analytic results of fear-conditioning studies in the anxiety disorders implicate generalization of conditioned fear to stimuli resembling the conditioned danger cue as one of the more robust conditioning markers of anxiety pathology. Due to the absence of conditioning studies assessing generalization in generalized anxiety disorder (GAD), results of this meta-analysis do not reveal whether such generalization abnormalities also apply to GAD. The current study fills this gap by behaviorally and psychophysiologically assessing levels of conditioned fear generalization across adults with and without GAD. Methods Twenty-two patients with a DSM-IV-Text Revision diagnosis of GAD and 26 healthy comparison subjects were recruited and tested. The employed generalization paradigm consisted of quasi-randomly presented rings of gradually increasing size, with extreme sizes serving as conditioned danger cues (CS+) and conditioned safety cues. The rings of intermediary size served as generalization stimuli, creating a continuum of similarity between CS+ and conditioned safety cues across which to assess response slopes, referred to as generalization gradients. Primary outcome variables included slopes for fear-potentiated startle (electromyography) and self-reported risk ratings. Results Behavioral and psychophysiological findings demonstrated overgeneralization of conditioned fear among patients with GAD. Specifically, generalization gradients were abnormally shallow among GAD patients, reflecting less degradation of the conditioned fear response as the presented stimulus differentiated from the CS+. Conclusions Overgeneralization of conditioned fear to safe encounters resembling feared situations may contribute importantly to the psychopathology of GAD by proliferating anxiety cues in the individual's environment that are then capable of evoking and maintaining anxiety and worry associated with GAD. {\textcopyright} 2014 Society of Biological Psychiatry.Published by Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Lissek, Shmuel and Kaczkurkin, Antonia N and Rabin, Stephanie and Geraci, Marilla and Pine, Daniel S and Grillon, Christian},
doi = {10.1016/j.biopsych.2013.07.025},
eprint = {NIHMS150003},
isbn = {6126269918},
issn = {18732402},
journal = {Biological Psychiatry},
keywords = {Fear conditioning,fear-potentiated startle,generalized anxiety disorder,interpretation bias,pathophysiology,stimulus generalization},
month = {jun},
number = {11},
pages = {909--915},
pmid = {24001473},
publisher = {Elsevier},
title = {{Generalized anxiety disorder is associated with overgeneralization of classically conditioned fear}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24001473 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3938992},
volume = {75},
year = {2014}
}
@article{Nicola2010a,
abstract = {Dopamine released in the nucleus accumbens is thought to contribute to the decision to exert effort to seek reward. This hypothesis is supported by findings that performance of tasks requiring higher levels of effort is more susceptible to disruption by manipulations that reduce accumbensdopaminefunction than tasks that require less effort. However, performance ofsomelow-effort cue-responding tasks is highly dependent on accumbens dopamine. To reconcile these disparate results, we made detailed behavioral observations of rats performing various operant tasks and determined how injection of dopamine receptor antagonists into the accumbens influenced specific aspects of the animals' behavior. Strikingly, once animals began a chain of operant responses, the antagonists did not affect the ability to continue the chain until reward delivery. Instead,whenrats left the operandum, the antagonists severely impaired the ability to return.Weshow that this impairment is specific to situations in which the animal must determine a new set of approach actions on each approach occasion; this behavior is called “flexible approach.” Both high-effort operant tasks and some low-effort cue-responding tasks require dopamine receptor activation in the accumbens because animals pause their responding and explore the chamber, and accum- bensdopamineis required to terminate these pauses with flexibleapproachto theoperandum.Theflexibleapproachhypothesis provides a unified framework for understanding the contribution of the accumbens and its dopamine projection to reward-seeking behavior. Introduction.},
author = {Nicola, S. M.},
doi = {10.1523/JNEUROSCI.3958-10.2010},
file = {:C$\backslash$:/Users/mvdmlab/Google Drive/Project/Literature/dopamine/2010 Nicola J Neuro - flexible approach nAc and DA.pdf:pdf},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {49},
pages = {16585--16600},
pmid = {21147998},
title = {{The Flexible Approach Hypothesis: Unification of Effort and Cue-Responding Hypotheses for the Role of Nucleus Accumbens Dopamine in the Activation of Reward-Seeking Behavior}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3958-10.2010},
volume = {30},
year = {2010}
}
@article{Averbeck2017,
abstract = {Reinforcement learning (RL) is the behavioral process of learning the values of actions and objects. Most models of RL assume that the dopaminergic prediction error signal drives plasticity in frontal–striatal circuits. The striatum then encodes value representations that drive decision processes. However, the amygdala has also been shown to play an important role in forming Pavlovian stimulus–outcome associations. These Pavlovian associations can drive motivated behavior via the amygdala projections to the ventral striatum or the ventral tegmental area. The amygdala may, therefore, play a central role in RL. Here we compare the contributions of the amygdala and the striatum to RL and show that both the amygdala and striatum learn and represent expected values in RL tasks. Furthermore, value representations in the striatum may be inherited, to some extent, from the amygdala. The striatum may, therefore, play less of a primary role in learning stimulus– outcome associations in RL than previously suggested.},
author = {Averbeck, Bruno B. and Costa, Vincent D.},
doi = {10.1038/nn.4506},
isbn = {1097-6256},
issn = {15461726},
journal = {Nature Neuroscience},
keywords = {Motivation,Reward},
month = {apr},
number = {4},
pages = {505--512},
pmid = {28352111},
publisher = {Nature Publishing Group},
title = {{Motivational neural circuits underlying reinforcement learning}},
url = {http://www.nature.com/articles/nn.4506},
volume = {20},
year = {2017}
}
@article{Grant1948,
abstract = {The University of Wisconsin Card-Sorting Test was used. The individual cards can be sorted on the basis either of the color, the number, or the form of the figures appearing on them. Color was arbitrarily selected as the initally "correct" sorting category. As each S sorted the cards he was told whether he was "right" or "wrong." As soon as S made a certain number of consecutive correct responses, E without explanation changed the "correct" basis of classification. Seven groups of about 20 Ss each were given 3, 4, 5, 6, 7, 8 and 10 reinforcing trials, respectively, before each shift. "Increasing the amount of reinforcement of original modes of response reduced the amount of perseveration of these responses when they suddenly became incorrect." Increased reinforcement also reduced the number of errors S made in reaching the new correct solution after deserting the old formerly correct one.},
author = {Grant, David A. and Berg, Esta},
doi = {10.1037/h0059831},
isbn = {Print 0022-1015 Journal of Experimental Psychology General American Psychological Association Psychological Review Company; US Print},
issn = {00221015},
journal = {Journal of Experimental Psychology},
keywords = {{\&} REINFORCEMENT,{\&} RESPONSE SHIFT,CARD SORTING,CARD-SORTING,LEARNING,LEARNING {\&} MEMORY,REINFORCEMENT,RESPONSE,RESPONSE SHIFT,SHIFT},
number = {4},
pages = {404--411},
pmid = {18874598},
title = {{A behavioral analysis of degree of reinforcement and ease of shifting to new responses in a Weigl-type card-sorting problem}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0059831},
volume = {38},
year = {1948}
}
@article{VanderMeer2009,
abstract = {Local field potential (LFP) oscillations in the brain reflect organization thought to be important for perception, attention, movement, and memory. In the basal ganglia, including dorsal striatum, dysfunctional LFP states are associated with Parkinson's disease, while in healthy subjects, dorsal striatal LFPs have been linked to decision-making processes. However, LFPs in ventral striatum have been less studied. We report that in rats running a spatial decision task, prominent gamma-50 (45-55 Hz) and gamma-80 (70-85 Hz) oscillations in ventral striatum had distinct relationships to behavior, task events, and spiking activity. Gamma-50 power increased sharply following reward delivery and before movement initiation, while in contrast, gamma-80 power ramped up gradually to reward locations. Gamma-50 power was low and contained little structure during early learning, but rapidly developed a stable pattern, while gamma-80 power was initially high before returning to a stable level within a similar timeframe. Putative fast-spiking interneurons (FSIs) showed phase, firing rate, and coherence relationships with gamma-50 and gamma-80, indicating that the observed LFP patterns are locally relevant. Furthermore, in a number of FSIs such relationships were specific to gamma-50 or gamma-80, suggesting that partially distinct FSI populations mediate the effects of gamma-50 and gamma-80.},
author = {van der Meer, Matthijs A.A.},
doi = {10.3389/neuro.07.009.2009},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van der Meer, Redish - 2009 - Low and High Gamma Oscillations in Rat Ventral Striatum have Distinct Relationships to Behavior, Reward, a.pdf:pdf},
isbn = {1662-5145},
issn = {16625145},
journal = {Frontiers in Integrative Neuroscience},
pages = {9},
pmid = {19562092},
title = {{Low and high gamma oscillations in rat ventral striatum have distinct relationships to behavior, reward, and spiking activity on a learned spatial decision task}},
url = {http://journal.frontiersin.org/article/10.3389/neuro.07.009.2009/abstract},
volume = {3},
year = {2009}
}
@incollection{Carelli2009,
abstract = {Drug addiction in humans is a chronic disease characterized by compulsive drug intake followed by periods of abstinence and relapse. Electrophysiological recordings in behaving rodents have provided critical information regarding cellular mechanisms underlying this behavior. This approach, combined with the drug self-administration procedure, allows for an analysis of cell firing during key features of drug-seeking behaviors. Here, animal studies that examined the activity of neurons within the brain reward system (particularly the nucleus accumbens, NAc) during drug self-administration are reviewed. These findings reveal important insight into neural mechanisms underlying goal-directed behaviors and how drugs of abuse alter this system and lead to addiction. {\textcopyright} 2009 Elsevier Ltd All rights reserved.},
author = {Carelli, R. M.},
booktitle = {Encyclopedia of Neuroscience},
doi = {10.1016/B978-008045046-9.01546-1},
isbn = {9780080450469},
keywords = {Abstinence,Abuse,Accumbens,Addiction,Alcohol,Behavior,Cocaine,Cortex,Electrophysiology,Heroin,Reinforcement,Reward},
pages = {677--682},
publisher = {Elsevier},
title = {{Drug Addiction: Behavioral Neurophysiology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780080450469015461},
year = {2010}
}
@article{Saunders2012,
abstract = {The role of dopamine in reward is a topic of debate. For example, some have argued that phasic dopamine signaling provides a prediction-error signal necessary for stimulus-reward learning, whereas others have hypothesized that dopamine is not necessary for learning per se, but for attributing incentive motivational value ('incentive salience') to reward cues. These psychological processes are difficult to tease apart, because they tend to change together. To disentangle them we took advantage of natural individual variation in the extent to which reward cues are attributed with incentive salience, and asked whether dopamine (specifically in the core of the nucleus accumbens) is necessary for the expression of two forms of pavlovian-conditioned approach behavior--one in which the cue acquires powerful motivational properties (sign-tracking) and another closely related one in which it does not (goal-tracking). After acquisition of these conditioned responses (CRs), intra-accumbens injection of the dopamine receptor antagonist flupenthixol markedly impaired the expression of a sign-tracking CR, but not a goal-tracking CR. Furthermore, dopamine antagonism did not produce a gradual extinction-like decline in behavior, but maximally impaired expression of a sign-tracking CR on the very first trial, indicating the effect was not due to new learning (i.e. it occurred in the absence of new prediction-error computations). The data support the view that dopamine in the accumbens core is not necessary for learning stimulus-reward associations, but for attributing incentive salience to reward cues, transforming predictive conditional stimuli into incentive stimuli with powerful motivational properties.},
author = {Saunders, Benjamin T. and Robinson, Terry E.},
doi = {10.1111/j.1460-9568.2012.08217.x},
isbn = {1460-9568 (Electronic) 0953-816X (Linking)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Goal-tracking,Learning,Motivation,Rat,Sign-tracking},
month = {aug},
number = {4},
pages = {2521--2532},
pmid = {22780554},
publisher = {NIH Public Access},
title = {{The role of dopamine in the accumbens core in the expression of pavlovian-conditioned responses}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22780554 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3424374},
volume = {36},
year = {2012}
}
@article{Harris2001,
abstract = {Spontaneous "off-line" reactivation of neuronal activity patterns may contribute to the consolidation of memory traces. The ventral striatum exhibits reactivation and has been implicated in the processing of motivational information. It is unknown, however, whether reactivating neuronal ensembles specifically recapitulate information relating to rewards that were encountered during wakefulness. We demonstrate a prolonged reactivation in rat ventral striatum during quiet wakefulness and slow-wave but not rapid eye movement sleep. Reactivation of reward-related information processed in this structure was particularly prominent, and this was primarily attributable to spike trains temporally linked to reward sites. It was accounted for by small, strongly correlated subgroups in recorded cell assemblies and can thus be characterized as a sparse phenomenon. Our results indicate that reactivated memory traces may not only comprise feature- and context-specific information but also contain a value component.},
author = {Lansink, C. S. and Goltstein, P. M. and Lankelma, J. V. and Joosten, R. N. J. M. A. and McNaughton, B. L. and Pennartz, C. M. A.},
doi = {10.1523/JNEUROSCI.1054-08.2008},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {feb},
number = {25},
pages = {6372--6382},
pmid = {18562607},
publisher = {Society for Neuroscience},
title = {{Preferential Reactivation of Motivationally Relevant Information in the Ventral Striatum}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1054-08.2008},
volume = {28},
year = {2008}
}
@article{DiCiano2001,
abstract = {Stimuli paired with primary rewards can acquire emotional valence and the ability to elicit automatic, Pavlovian approach responses that have been shown to be mediated by the nucleus accumbens. The present experiment investigated the effects of infusions of glutamatergic or dopaminergic receptor antagonists into the core of the nucleus accumbens on the acquisition and performance of Pavlovian discriminated approach to an appetitive conditioned stimulus. Rats were trained on an autoshaping task in which a conditioned stimulus (CS+; a lever) was inserted into the operant chamber for 10 sec, after which a food pellet was delivered. Presentation of another lever (CS-) was never followed by food. Subjects developed a conditioned response of approaching and contacting the CS+ selectively, although food delivery was not in any way contingent on the animals' response. A triple dissociation in the effects of AP-5, LY293558 [(3SR, 4aRS, 6RS, 8aRS)-6-[2-(iH-tetrazol-5-yl)ethyl]-1,2,3,4,4a,5,6,7,8,8a-decahydroiso-qui noline-3-carboxylic acid], and alpha-flupenthixol infused into the nucleus accumbens core on the acquisition and performance of this conditioned response was observed. The AMPA/kainate receptor antagonist LY293558 disrupted discriminated approach performance but not acquisition, as evidenced by increased approaches to the CS-. In contrast, the NMDA receptor antagonist AP-5 impaired only the acquisition, but not performance, of autoshaping whereas the dopamine D1/D2 receptor antagonist alpha-flupenthixol decreased approaches to the CS+ during both acquisition and performance. The data are discussed with reference to dissociable interactions of these receptor types with limbic cortical and dopaminergic afferents to the nucleus accumbens core during the acquisition and expression of Pavlovian conditioned approach.},
author = {Ciano, Patricia Di and Cardinal, Rudolf N and Cowell, Rosie A and Little, Simon J and Everitt, Barry J and {Di Ciano}, P and Cardinal, Rudolf N and Cowell, Rosie A and Little, Simon J and Everitt, Barry J},
doi = {21/23/9471 [pii]},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {2-Amino-5-phosphonovalerate/administration {\&} dosag,2001,AMPA/antagonists {\&} inhibitors/*metaboli,Animal,Animal/drug effects,Appetitive Behavior/drug effects/physiology,Behavior,Catheterization,Classical/drug effects/*physiology,Conditioning,Dopamine Antagonists/administration {\&} dosage,Dopamine/*metabolism,Dose-Response Relationship,Drug,Excitatory Amino Acid Antagonists/administration {\&},Flupenthixol/administration {\&} dosage,Inbred Strains,Isoquinolines/administration {\&} dosage,Learning/drug effects,Male,Microinjections,N-Methyl-D-Aspartate/antagonists {\&} inhi,Non-U.S. Gov't,Nucleus Accumbens/drug effects/*metabolism,Operant/drug effects/physiology,Rats,Receptors,Support,Tetrazoles/administration {\&} dosage,abolished the acquisition of,ampa,au-,autoshaping,conditioned stimulus,dopamine,dopaminergic depletions of the,glutamate,lesions of the,moreover,nacc,nmda,nucleus accumbens core,parkinson et al,toshaping},
month = {dec},
number = {23},
pages = {9471--9477},
pmid = {11717381},
title = {{Differential involvement of NMDA, AMPA/kainate, and dopamine receptors in the nucleus accumbens core in the acquisition and performance of pavlovian approach behavior}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve{\&}db=PubMed{\&}dopt=Citation{\&}list{\_}uids=11717381},
volume = {21},
year = {2001}
}
@article{Schultz2015,
abstract = {Rewards are crucial objects that induce learning, approach behavior, choices, and emotions. Whereas emotions are difficult to investigate in animals, the learning function is mediated by neuronal reward prediction error signals which implement basic constructs of reinforcement learning theory. These signals are found in dopamine neurons, which emit a global reward signal to striatum and frontal cortex, and in specific neurons in striatum, amygdala, and frontal cortex projecting to select neuronal populations. The approach and choice functions involve subjective value, which is objectively assessed by behavioral choices eliciting internal, subjective reward preferences. Utility is the formal mathematical characterization of subjective value and a prime decision variable in economic choice theory. It is coded as utility prediction error by phasic dopamine responses. Utility can incorporate various influences, including risk, delay, effort, and social interaction. Appropriate for formal decision mechanisms, rewards are coded as object value, action value, difference value, and chosen value by specific neurons. Although all reward, reinforcement, and decision variables are theoretical constructs, their neuronal signals constitute measurable physical implementations and as such confirm the validity of these concepts. The neuronal reward signals provide guidance for behavior while constraining the free will to act.},
author = {Schultz, Wolfram},
doi = {10.1152/physrev.00023.2014},
isbn = {0031-9333},
issn = {0031-9333},
journal = {Physiological Reviews},
month = {jul},
number = {3},
pages = {853--951},
pmid = {26109341},
title = {{Neuronal Reward and Decision Signals: From Theories to Data}},
url = {http://physrev.physiology.org/lookup/doi/10.1152/physrev.00023.2014},
volume = {95},
year = {2015}
}
@article{Schultz2016,
abstract = {Reward prediction errors consist of the differences between received and predicted rewards. They are crucial for basic forms of learning about rewards and make us strive for more rewards-an evolutionary beneficial trait. Most dopamine neurons in the midbrain of humans, monkeys, and rodents signal a reward prediction error; they are activated by more reward than predicted (positive prediction error), remain at baseline activity for fully predicted rewards, and show depressed activity with less reward than predicted (negative prediction error). The dopamine signal increases nonlinearly with reward value and codes formal economic utility. Drugs of addiction generate, hijack, and amplify the dopamine reward signal and induce exaggerated, uncontrolled dopamine effects on neuronal plasticity. The striatum, amygdala, and frontal cortex also show reward prediction error coding, but only in subpopulations of neurons. Thus, the important concept of reward prediction errors is implemented in neuronal hardware.$\backslash$n$\backslash$nAbstract available from the publisher.$\backslash$n$\backslash$nAbstract available from the publisher.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Schultz, Wolfram},
doi = {10.1038/nrn.2015.26},
eprint = {9809069v1},
isbn = {3-540-27590-8},
issn = {12948322},
journal = {Dialogues in Clinical Neuroscience},
keywords = {Dopamine,Neuron,Neurophysiology,Prediction,Reward,Striatum,Substantia nigra,Ventral tegmental area},
month = {feb},
number = {1},
pages = {23--32},
pmid = {27069377},
primaryClass = {arXiv:gr-qc},
publisher = {Nature Publishing Group},
title = {{Dopamine reward prediction error coding}},
url = {http://www.nature.com/doifinder/10.1038/nrn.2015.26},
volume = {18},
year = {2016}
}
@article{Kaczkurkin2017,
abstract = {Objective:Heightened generalization of fear from an aversively reinforced conditioned stimulus (CS+, a conditioned danger cue) to resembling stimuli is widely accepted as a pathogenic marker of posttraumatic stress disorder (PTSD). Indeed, a distress response to benign stimuli that “resemble” aspects of the trauma is a central feature of the disorder. To date, the link between overgeneralization of conditioned fear and PTSD derives largely from clinical observations, with limited empirical work on the subject. This represents the first effort to examine behavioral and brain indices of generalized conditioned fear in PTSD using systematic methods developed in animals known as generalization gradients: the gradual decline in conditioned responding as the presented stimulus gradually differentiates from CS+.Method:Gradients of conditioned fear generalization were assessed using functional MRI and behavioral measures in U.S. combat veterans who served in Iraq or Afghanistan and had PTSD (N=26), subthreshold P...},
author = {Kaczkurkin, Antonia N. and Burton, Philip C. and Chazin, Shai M. and Manbeck, Adrienne B. and Espensen-Sturges, Tori and Cooper, Samuel E. and Sponheim, Scott R. and Lissek, Shmuel},
doi = {10.1176/appi.ajp.2016.15121549},
isbn = {0006-3223},
issn = {15357228},
journal = {American Journal of Psychiatry},
keywords = {Biological Markers,Cognitive Neuroscience,Emotion,Posttraumatic Stress Disorder},
month = {feb},
number = {2},
pages = {125--134},
pmid = {27794690},
publisher = {American Psychiatric AssociationArlington, VA},
title = {{Neural substrates of overgeneralized conditioned fear in PTSD}},
url = {http://ajp.psychiatryonline.org/doi/10.1176/appi.ajp.2016.15121549},
volume = {174},
year = {2017}
}
@article{Salamone2012,
abstract = {Nucleus accumbens dopamine is known to play a role in motivational processes, and dysfunctions of mesolimbic dopamine may contribute to motivational symptoms of depression and other disorders, as well as features of substance abuse. Although it has become traditional to label dopamine neurons as "reward" neurons, this is an overgeneralization, and it is important to distinguish between aspects of motivation that are differentially affected by dopaminergic manipulations. For example, accumbens dopamine does not mediate primary food motivation or appetite, but is involved in appetitive and aversive motivational processes including behavioral activation, exertion of effort, approach behavior, sustained task engagement, Pavlovian processes, and instrumental learning. In this review, we discuss the complex roles of dopamine in behavioral functions related to motivation.},
author = {Salamone, John D. and Correa, Merc{\`{e}}},
doi = {10.1016/j.neuron.2012.10.021},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
month = {nov},
number = {3},
pages = {470--485},
pmid = {23141060},
publisher = {Cell Press},
title = {{The Mysterious Motivational Functions of Mesolimbic Dopamine}},
url = {http://www.sciencedirect.com/science/article/pii/S0896627312009415},
volume = {76},
year = {2012}
}
@article{Wassum2009,
abstract = {It generally is assumed that a common neural substrate mediates both the palatability and the reward value of nutritive events. However, recent evidence suggests this assumption may not be true. Whereas opioid circuitry in both the nucleus accumbens and ventral pallidum has been reported to mediate taste-reactivity responses to palatable events, the assignment of reward or inventive value to goal-directed actions has been found to involve the basolateral amygdala. Here we found that, in rats, the neural processes mediating palatability and incentive value are indeed dissociable. Naloxone infused into either the ventral pallidum or nucleus accumbens shell blocked the increase in sucrose palatability induced by an increase in food deprivation without affecting the performance of sucrose-related actions. Conversely, naloxone infused into the basolateral amygdala blocked food deprivation-induced changes in sucrose-related actions without affecting sucrose palatability. This double dissociation of opioid-mediated changes in palatability and incentive value suggests that the role of endogenous opioids in reward processing does not depend on a single neural circuit. Rather, changes in palatability and in the incentive value assigned to rewarding events seem to be mediated by distinct neural processes.},
author = {Wassum, K M and Ostlund, S B and Maidment, N T and Balleine, B W},
doi = {10.1073/pnas.0905874106},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wassum et al. - 2009 - Distinct opioid circuits determine the palatability and the desirability of rewarding events.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$n0027-8424 (Linking)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {jul},
number = {30},
pages = {12512--7},
pmid = {19597155},
publisher = {National Academy of Sciences},
title = {{Distinct opioid circuits determine the palatability and the desirability of rewarding events.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19597155{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2718390},
volume = {106},
year = {2009}
}
@article{Holland1992,
abstract = {This chapter describes Pavlovian conditioning as the transfer of control of reflexes (unconditioned responses or URs) from stimuli that elicit them unconditionally (USs) to other stimuli that normally are incapable of eliciting them. Although auditory cues seldom elicit substantial salivation spontaneously, a tone provokes that response if it consistently predicts food delivery. This new-found control of salivation by the tone is typically attributed to the acquisition of some association or potentiated connection between the CS and US pathways: by virtue of that association, the CS becomes a substitute elicitor of activity along some portion of the US-UR pathway. This is often described as the CS's “activating a representation of the US”. Another behavioral control function occasionally ascribed to Pavlovian CSsis modulation. Rather than acquiring its own ability to elicit behavior usually controlled by another reflex system, a Pavlovian CS influences the efficacy of the normal elicitor of a response. The chapter is concerned with a particular modulatory function of CSs in rats solutions of elementary conditional discriminations, in which one CS modifies the efficacy of Pavlovian associations between other cues and the US. This function is called as occasion setting, which is readily distinguished from elicitation both conceptually and empirically, and perhaps anatomically as well. Furthermore, this occasion-setting function involves a hierarchical, multilayered organization of representations of events and relations and thus may aid the expansion of the domain of Pavlovian accounts of behavior. {\textcopyright} 1992, Academic Press Inc.},
author = {Holland, Peter C.},
doi = {10.1016/S0079-7421(08)60488-0},
isbn = {0079-7421},
issn = {00797421},
journal = {Psychology of Learning and Motivation - Advances in Research and Theory},
month = {jan},
number = {C},
pages = {69--125},
publisher = {Academic Press},
title = {{Occasion setting in pavlovian conditioning}},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108604880},
volume = {28},
year = {1992}
}
@article{Hall2001,
abstract = {Pavlovian conditioned cues exert a powerful influence on instrumental actions directed towards a common reward, this is known as Pavlovian-to-instrumental transfer (PIT). The nucleus accumbens (NAcc) has been hypothesized to function as an interface between limbic cortical structures required for associative conditioning, like the amygdala, and response mechanisms through which instrumental behaviour can be selected and performed. Here we have used selective excitotoxic lesions to investigate the involvement of subnuclei of the amygdala as well as the core and shell regions of the nucleus accumbens on PIT in rats. Within the amygdala, selective lesions of the central nucleus (CeN), but not of the basolateral nucleus (BLA), abolished the PIT effect. In addition, selective lesions of the NAcc core, but not the NAcc shell, also abolished PIT. None of the lesions impaired the acquisition of Pavlovian food cup approaches or instrumental responding itself. These data demonstrate that the CeN and NAcc core are central components of the neural system mediating the impact of Pavlovian cues on instrumental responding. We suggest that this effect may depend upon the regulation of the dopaminergic innervation of the NAcc core by projections from the CeN to the ventral tegmental area.},
author = {Hall, J. and Parkinson, J. A. and Connor, T. M. and Dickinson, A. and Everitt, B. J.},
doi = {10.1046/j.0953-816X.2001.01577.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall et al. - 2001 - Involvement of the central nucleus of the amygdala and nucleus accumbens core in mediating Pavlovian influences on.pdf:pdf},
isbn = {0953-816X (Print)$\backslash$r0953-816X (Linking)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Motivation,Pavlovian conditioning,Pavlovian-to-instrumental transfer,Rat},
month = {may},
number = {10},
pages = {1984--1992},
pmid = {11403692},
publisher = {Blackwell Science Ltd},
title = {{Involvement of the central nucleus of the amygdala and nucleus accumbens core in mediating pavlovian influences on instrumental behaviour}},
url = {http://doi.wiley.com/10.1046/j.0953-816x.2001.01577.x},
volume = {13},
year = {2001}
}
@article{Takahashi2016,
abstract = {Dopamine neurons signal reward prediction errors. This requires accurate reward predictions. It has been suggested that the ventral striatum provides these predictions. Here we tested this hypothesis by recording from putative dopamine neurons in the VTA of rats performing a task in which prediction errors were induced by shifting reward timing or number. In controls, the neurons exhibited error signals in response to both manipulations. However, dopamine neurons in rats with ipsilateral ventral striatal lesions exhibited errors only to changes in number and failed to respond to changes in timing of reward. These results, supported by computational modeling, indicate that predictions about the temporal specificity and the number of expected reward are dissociable and that dopaminergic prediction-error signals rely on the ventral striatum for the former but not the latter.},
author = {Takahashi, Yuji K. and Langdon, Angela J. and Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1016/j.neuron.2016.05.015},
isbn = {1097-4199 (Electronic)0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
month = {jul},
number = {1},
pages = {182--193},
pmid = {27292535},
title = {{Temporal Specificity of Reward Prediction Errors Signaled by Putative Dopamine Neurons in Rat VTA Depends on Ventral Striatum}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27292535 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4938771 http://linkinghub.elsevier.com/retrieve/pii/S0896627316301751},
volume = {91},
year = {2016}
}
@article{Honey2014,
abstract = {The central concern of associative learning theory is to provide an account of behavioral adaptation that is parsimonious in addressing three key questions: (1) under what conditions does learning occur, (2) what are the associative structures involved, and (3) how do these affect behavior? The principle focus here is on the second question, concerning associative structures, but we will have cause to touch on the others in passing. This question is one that has exercised theorists since Pavlov's descriptions of the conditioning process, where he identifies the shared significance of the study of conditioned reflexes for psychologists and neuroscientists alike. {\textcopyright} 2013 Elsevier Inc.},
author = {Honey, Robert C. and Iordanova, Mihaela D. and Good, Mark},
doi = {10.1016/j.nlm.2013.06.002},
issn = {10747427},
journal = {Neurobiology of Learning and Memory},
keywords = {Configural,Elemental,Hippocampus},
month = {feb},
pages = {96--103},
pmid = {23769767},
title = {{Associative structures in animal learning: Dissociating elemental and configural processes}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23769767 http://linkinghub.elsevier.com/retrieve/pii/S1074742713000944},
volume = {108},
year = {2014}
}
@article{Floresco1997,
abstract = {The integrative role of the nucleus accumbens and subpallidal area in relaying hippocampal signals to the mesencephalic locomotor region in the brainstem was investigated electrophysiologically in urethan-anaesthetized rats. A behavioural study of the functional connections was also performed in freely moving rats. In the electrophysiological experiments, subpallidal output neurons to the pedunculoppntine nucleus and the adjacent ventral gray were first identified by their antidromic responses to electrical stimulation of the pedunculopontine nucleus. Hippocampal stimulation was then shown to inhibit orthodromically some of these subpallidal neurons. The inhibitory response was attenuated following microinjection of a dopamine D2 agonist (LY 171555), but not a D1 agonist (SKF 38393), into the accumbens. This suggests that signal transmission from the hippocampus to the subpallidal output neurons to the pedunculopontine nucleus is modulated by a D2 receptor-mediated mechanism in the nucleus accumbens. Injections of N-methyl-d-aspartate into the ventral subiculum of the hippocampus resulted in a threefold increase in locomotor responses. Injection of a D2 agonist into the accumbens reduced the hyperkinetic response dose-dependently and suggests that D2 receptors regulate locomotor responses initiated by the hippocampal-accumbens pathway. Injection of nipecotic acid, a GABA uptake inhibitor, into the subpallidal area or of procaine, a neural transmission blocker, into the region of the pedunculopontine nucleus, also reduced significantly the hippocampal-induced hyperkinetic response. These results provide evidence of limbic (e.g. hippocampus) influences on locomotor activity by way of nucleus accumbens-subpallidal-pedunculopontine nucleus connections which may contribute to adaptive behaviour. Signal transmission from the hippocampus may be regulated by a dopamine D1 receptor mechanism in the accumbens, presumably mediated by the converging mesolimbic dopaminergic input from the ventral tegmental area. ?? 1987.},
author = {Yang, C. R. and Mogenson, G. J.},
doi = {10.1016/0306-4522(87)90179-5},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Floresco, Seamans, Phillips - 1997 - Selective roles for hippocampal, prefrontal cortical, and ventral striatal circuits in radial-arm m.pdf:pdf},
isbn = {0306-4522 (Print)},
issn = {03064522},
journal = {Neuroscience},
keywords = {accumbens,and retrieve food efficiently,induced reversible lesions,is an essential,lidocaine-,neural networks,nucleus,prelimbic cortex,rats,spatial memory,subiculum,the ability to locate,ventral ca1},
month = {mar},
number = {3},
pages = {1041--1055},
pmid = {2963972},
title = {{Hippocampal signal transmission to the pedunculopontine nucleus and its regulation by dopamine D2 receptors in the nucleus accumbens: An electrophysiological and behavioural study}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9030646},
volume = {23},
year = {1987}
}
@article{Samejima2005,
abstract = {The estimation of the reward an action will yield is critical in decision-making. To elucidate the role of the basal ganglia in this process, we recorded striatal neurons of monkeys who chose between left and right handle turns, based on the estimated reward probabilities of the actions. During a delay period before the choices, the activity of more than one-third of striatal projection neurons was selective to the values of one of the two actions. Fewer neurons were tuned to relative values or action choice. These results suggest representation of action values in the striatum, which can guide action selection in the basal ganglia circuit.},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.5367},
author = {Samejima, Kazuyuki and Ueda, Yasumasa and Doya, Kenji and Kimura, Minoru},
doi = {10.1126/science.1115270},
eprint = {arXiv:1308.5367},
isbn = {0036-8075},
issn = {00368075},
journal = {Science},
month = {nov},
number = {5752},
pages = {1337--1340},
pmid = {16311337},
publisher = {American Association for the Advancement of Science},
title = {{Neuroscience: Representation of action-specific reward values in the striatum}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16311337},
volume = {310},
year = {2005}
}
@article{Floresco2008,
abstract = {Reinstatement of previously extinguished instrumental responding for drug-related cues has been used as an animal model for relapse of drug abuse, and is differentially affected by inactivation of the core and shell subregions of the nucleus accumbens (NAc). To compare the roles of these subregions in reinstatement induced by cues associated with natural and drug rewards, the present study assessed the effects of inactivation of the NAc core and shell on cue-induced reinstatement of food-seeking behavior. Rats acquired a lever pressing response for food reward paired with a light/tone conditioned stimulus (CS). They were then subjected to extinction, where both food and the CS were withheld. Reinstatement of responding was measured during response-contingent presentations of the CS. Following saline infusions into the NAc core or shell, rats displayed a significant increase in lever pressing during reinstatement sessions. Inactivation of the core, induced by infusion of GABA agonists muscimol and baclofen, attenuated responding for the CS, but did not affect pavlovian approach toward the food receptacle. In contrast, inactivation of the shell had the opposite effect, potentiating responding relative to vehicle treatments. These data suggest that the NAc core and shell play opposing, yet complementary roles in mediating the influence that food-associated conditioned stimuli exert over behavior. The core enables reward-related stimuli to bias the direction and vigor of instrumental responding. In contrast, the shell facilitates alterations in behavior in response to changes in the incentive value of conditioned stimuli. The fact that the NAc core appears to play a similar role in cue-induced reinstatement induced by both natural and drug rewards suggests that this region of the ventral striatum may be a final common pathway through which both drug- and food-associated stimuli may influence the direction and magnitude of ongoing behavior. {\textcopyright} 2008 IBRO.},
author = {Floresco, S. B. and McLaughlin, R. J. and Haluk, D. M.},
doi = {10.1016/j.neuroscience.2008.04.004},
isbn = {0306-4522 (Print)$\backslash$r0306-4522 (Linking)},
issn = {03064522},
journal = {Neuroscience},
keywords = {drug addiction,instrumental learning,pavlovian conditioning,rat,relapse},
month = {jun},
number = {3},
pages = {877--884},
pmid = {18479836},
publisher = {Pergamon},
title = {{Opposing roles for the nucleus accumbens core and shell in cue-induced reinstatement of food-seeking behavior}},
url = {https://www.sciencedirect.com/science/article/pii/S0306452208005435},
volume = {154},
year = {2008}
}
@misc{VanderMeer2011a,
abstract = {Extensive evidence implicates the ventral striatum in multiple distinct facets of action selection. Early work established a role in modulating ongoing behavior, as engaged by the energizing and directing influences of motivationally relevant cues and the willingness to expend effort in order to obtain reward. More recently, reinforcement learning models have suggested the notion of ventral striatum primarily as an evaluation step during learning, which serves as a critic to update a separate actor. Recent computational and experimental work may provide a resolution to the differences between these two theories through a careful parsing of behavior and the instrinsic heterogeneity that characterizes this complex structure. {\textcopyright} 2011 Elsevier Ltd.},
author = {{Van der Meer}, Matthijs A A and Redish, A. David},
booktitle = {Current Opinion in Neurobiology},
doi = {10.1016/j.conb.2011.02.011},
isbn = {0959-4388},
issn = {09594388},
number = {3},
pages = {387--392},
pmid = {21420853},
title = {{Ventral striatum: A critical look at models of learning and evaluation}},
volume = {21},
year = {2011}
}
@article{Hauber2000b,
abstract = {The ventral striatum (VS) is thought to serve as a gateway whereby associative information from the amygdala and prefrontal regions can influence motor output to guide behavior. If VS mediates this "limbic-motor" interface, then one might expect neural correlates in VS to reflect this information. Specifically, neural activity should reflect the integration of motivational value with subsequent behavior. To test this prediction, we recorded from single units in VS while rats performed a choice task in which different odor cues indicated that reward was available on the left or on the right. The value of reward associated with a left or rightward movement was manipulated in separate blocks of trials by either varying the delay preceding reward delivery or by changing reward size. Rats' behavior was influenced by the value of the expected reward and the response required to obtain it, and activity in the majority of cue-responsive VS neurons reflected the integration of these two variables. Unlike similar cue-evoked activity reported previously in dopamine neurons, these correlates were only observed if the directional response was subsequently executed. Furthermore, activity was correlated with the speed at which the rats' executed the response. These results are consistent with the notion that VS serves to integrate information about the value of an expected reward with motor output during decision making.},
author = {Roesch, M. R. and Singh, T. and Brown, P. L. and Mullins, S. E. and Schoenbaum, G.},
doi = {10.1523/JNEUROSCI.2572-09.2009},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {aug},
number = {42},
pages = {13365--13376},
pmid = {19846724},
publisher = {Society for Neuroscience},
title = {{Ventral Striatal Neurons Encode the Value of the Chosen Action in Rats Deciding between Differently Delayed or Sized Rewards}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2572-09.2009},
volume = {29},
year = {2009}
}
