Automatically generated by Mendeley Desktop 1.17.10
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Stuber2011,
abstract = {The basolateral amygdala (BLA) has a crucial role in emotional learning irrespective of valence. The BLA projection to the nucleus accumbens (NAc) is thought to modulate cue-triggered motivated behaviours, but our understanding of the interaction between these two brain regions has been limited by the inability to manipulate neural-circuit elements of this pathway selectively during behaviour. To circumvent this limitation, we used in vivo optogenetic stimulation or inhibition of glutamatergic fibres from the BLA to the NAc, coupled with intracranial pharmacology and ex vivo electrophysiology. Here we show that optical stimulation of the pathway from the BLA to the NAc in mice reinforces behavioural responding to earn additional optical stimulation of these synaptic inputs. Optical stimulation of these glutamatergic fibres required intra-NAc dopamine D1-type receptor signalling, but not D2-type receptor signalling. Brief optical inhibition of fibres from the BLA to the NAc reduced cue-evoked intake of sucrose, demonstrating an important role of this specific pathway in controlling naturally occurring reward-related behaviour. Moreover, although optical stimulation of glutamatergic fibres from the medial prefrontal cortex to the NAc also elicited reliable excitatory synaptic responses, optical self-stimulation behaviour was not observed by activation of this pathway. These data indicate that whereas the BLA is important for processing both positive and negative affect, the glutamatergic pathway from the BLA to the NAc, in conjunction with dopamine signalling in the NAc, promotes motivated behavioural responding. Thus, optogenetic manipulation of anatomically distinct synaptic inputs to the NAc reveals functionally distinct properties of these inputs in controlling reward-seeking behaviours.},
author = {Stuber, Garret D and Sparta, Dennis R and Stamatakis, Alice M and {Van Leeuwen}, Wieke A and Hardjoprajitno, Juanita E and Cho, Saemi and Tye, Kay M and Kempadoo, Kimberly A and Zhang, Feng and Deisseroth, Karl and Bonci, Antonello},
doi = {10.1038/nature10194},
isbn = {1476-4687 (Electronic){\$}\backslash{\$}n0028-0836 (Linking)},
issn = {00280836},
journal = {Nature},
number = {7356},
pages = {377--382},
pmid = {21716290},
title = {{Excitatory transmission from the amygdala to nucleus accumbens facilitates reward seeking}},
url = {http://www.nature.com/nature/journal/v475/n7356/pdf/nature10194.pdf},
volume = {475},
year = {2011}
}
@article{VanderMeer2010c,
abstract = {Decision-making studies across different domains suggest that decisions can arise from multiple, parallel systems in the brain: a flexible system utilizing action-outcome expectancies and a more rigid system based on situation-action associations. The hippocampus, ventral striatum, and dorsal striatum make unique contributions to each system, but how information processing in each of these structures supports these systems is unknown. Recent work has shown covert representations of future paths in hippocampus and of future rewards in ventral striatum. We developed analyses in order to use a comparative methodology and apply the same analyses to all three structures. Covert representations of future paths and reward were both absent from the dorsal striatum. In contrast, dorsal striatum slowly developed situation representations that selectively represented action-rich parts of the task. This triple dissociation suggests that the different roles these structures play are due to differences in information-processing mechanisms.},
annote = {NULL},
author = {van der Meer, Matthijs A A and Johnson, Adam and Schmitzer-Torbert, Neil C and Redish, A David},
doi = {10.1016/j.neuron.2010.06.023},
issn = {1097-4199},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Analysis of Variance,Animals,Association Learning,Automatic Data Processing,Choice Behavior,Choice Behavior: physiology,Conditioning,Corpus Striatum,Corpus Striatum: cytology,Hippocampus,Hippocampus: cytology,Inbred F344,Learning,Learning: physiology,Male,Models,Neurological,Neurons,Neurons: physiology,Operant,Operant: physiology,Rats,Reaction Time,Reward,Space Perception,Space Perception: physiology},
month = {jul},
number = {1},
pages = {25--32},
pmid = {20624589},
title = {{Triple Dissociation of Information Processing in Dorsal Striatum, Ventral Striatum, and Hippocampus on a Learned Spatial Decision Task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20624589},
volume = {67},
year = {2010}
}
@article{Tabuchi2000,
abstract = {To understand how hippocampal signals are processed by downstream neurons, we analyzed the relative timing between neuronal discharges in simultaneous recordings in the hippocampus and nucleus accumbens of rats performing in a plus maze. In all, 154 pairs of cells (composed of 65 hippocampal and 56 accumbens neurons) were examined during the 1 s period prior to reward delivery. Cross-correlation analyses over a +/- 300-ms window with 10-ms bins revealed that 108 pairs had at least one significant histogram bin (P {\textless} 0.01). The most frequently occurring peaks of hippocampal firing prior to accumbens discharges appeared at latencies from -30-0 ms, corresponding to published values of the latency of the hippocampal pathway to the nucleus accumbens. Other peaks appeared most often at latencies multiples of about 110 ms prior to and after this, corresponding to theta rhythmicity. Since firing synchronization can result from several types of connectivity patterns (such as common inputs), a group of 18 hippocampus-accumbens pairs was selected as those most likely to have monosynaptic connections. The criterion was the presence of at least one highly significant peak (P {\textless} 0.001) at latencies corresponding to field potentials evoked in the accumbens by hippocampal stimulation. A significant peak occurred on all four maze arms for only one of these cell pairs, indicating positional modulation for the others. In addition, behavior dependence of the synchrony between these nucleus accumbens and hippocampus neurons was examined by studying data in relation to three different synchronization points: reward box arrival, box departure, and arrival at the center of the maze. This indicates that the functional connectivity between hippocampal and accumbens neurons was stronger when the rat was near reward areas. Ten of the hippocampal neurons in these 18 cell pairs showed 9-Hz (theta) rhythmic activity in autocorrelation analyses. Of these 10 cells, cross-correlograms from eight hippocampal-accumbens pairs also showed theta rhythmicity. Overall, these results indicate that the synchrony between hippocampus and nucleus accumbens neurons is modulated by spatial position and behavior, and theta rhythm may play an important role for this synchronization.},
author = {Tabuchi, E T and Mulder, A B and Wiener, S I},
doi = {10.1002/1098-1063(2000)10:6<717::AID-HIPO1009>3.0.CO;2-3},
issn = {1050-9631},
journal = {Hippocampus},
keywords = {Animal,Animal: physiology,Animals,Behavior,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Long-Evans,Male,Maze Learning,Maze Learning: physiology,Membrane Potentials,Membrane Potentials: physiology,Motor Activity,Neural Pathways,Neurons,Neurons: physiology,Nucleus Accumbens,Nucleus Accumbens: cytology,Nucleus Accumbens: physiology,Rats,Theta Rhythm},
month = {jan},
number = {6},
pages = {717----728},
pmid = {11153717},
title = {{Position and behavioral modulation of synchronization of hippocampal and accumbens neuronal discharges in freely moving rats}},
url = {http://www.cingulate.ibms.sinica.edu.tw/ftpshare/Lab{\_}Seminar/Charm/spike sorting/Tabuchi 2000.pdf http://www.ncbi.nlm.nih.gov/pubmed/11153717},
volume = {10},
year = {2000}
}
@article{lavoie94,
author = {Lavoie, A M and Mizumori, S J Y},
journal = {Brain Research},
pages = {157--168},
title = {{Spatial-, movement- and reward-sensitive discharge by medial ventral striatum neurons in rats}},
volume = {638},
year = {1994}
}
@article{Sutton1998,
author = {Sutton, R S and Barto, A G},
journal = {MIT Press},
title = {{Reinforcement learning: An introduction}},
year = {1998}
}
@article{Khamassi2012,
abstract = {Behavior in spatial navigation is often organized into map-based (place-driven) vs. map-free (cue-driven) strategies; behavior in operant conditioning research is often organized into goal-directed vs. habitual strategies. Here we attempt to unify the two. We review one powerful theory for distinct forms of learning during instrumental conditioning, namely model-based (maintaining a representation of the world) and model-free (reacting to immediate stimuli) learning algorithms. We extend these lines of argument to propose an alternative taxonomy for spatial navigation, showing how various previously identified strategies can be distinguished as "model-based" or "model-free" depending on the usage of information and not on the type of information (e.g., cue vs. place). We argue that identifying "model-free" learning with dorsolateral striatum and "model-based" learning with dorsomedial striatum could reconcile numerous conflicting results in the spatial navigation literature. From this perspective, we further propose that the ventral striatum plays key roles in the model-building process. We propose that the core of the ventral striatum is positioned to learn the probability of action selection for every transition between states of the world. We further review suggestions that the ventral striatal core and shell are positioned to act as "critics" contributing to the computation of a reward prediction error for model-free and model-based systems, respectively.},
author = {Khamassi, Mehdi and Humphries, Mark D},
doi = {10.3389/fnbeh.2012.00079},
isbn = {1662-5153 (Electronic){\$}\backslash{\$}r1662-5153 (Linking)},
issn = {1662-5153},
journal = {Frontiers in Behavioral Neuroscience},
keywords = {action-outcome,habit,nucleus accumbens,reinforcement learning,stimulus-response},
pages = {79},
pmid = {23205006},
publisher = {Frontiers Media SA},
title = {{Integrating cortico-limbic-basal ganglia architectures for learning model-based and model-free navigation strategies}},
url = {http://journal.frontiersin.org/article/10.3389/fnbeh.2012.00079/abstract},
volume = {6},
year = {2012}
}
@article{Niv2007,
abstract = {RATIONALE: Dopamine neurotransmission has long been known to exert a powerful influence over the vigor, strength, or rate of responding. However, there exists no clear understanding of the computational foundation for this effect; predominant accounts of dopamine's computational function focus on a role for phasic dopamine in controlling the discrete selection between different actions and have nothing to say about response vigor or indeed the free-operant tasks in which it is typically measured. OBJECTIVES: We seek to accommodate free-operant behavioral tasks within the realm of models of optimal control and thereby capture how dopaminergic and motivational manipulations affect response vigor. METHODS: We construct an average reward reinforcement learning model in which subjects choose both which action to perform and also the latency with which to perform it. Optimal control balances the costs of acting quickly against the benefits of getting reward earlier and thereby chooses a best response latency. RESULTS: In this framework, the long-run average rate of reward plays a key role as an opportunity cost and mediates motivational influences on rates and vigor of responding. We review evidence suggesting that the average reward rate is reported by tonic levels of dopamine putatively in the nucleus accumbens. CONCLUSIONS: Our extension of reinforcement learning models to free-operant tasks unites psychologically and computationally inspired ideas about the role of tonic dopamine in striatum, explaining from a normative point of view why higher levels of dopamine might be associated with more vigorous responding.},
author = {Niv, Yael and Daw, Nathaniel D and Joel, Daphna and Dayan, Peter},
doi = {10.1007/s00213-006-0502-4},
isbn = {0033-3158},
issn = {00333158},
journal = {Psychopharmacology},
keywords = {Dopamine,Energizing,Free operant,Motivation,Reinforcement learning,Response rate},
month = {mar},
number = {3},
pages = {507--520},
pmid = {17031711},
title = {{Tonic dopamine: Opportunity costs and the control of response vigor}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17031711 http://link.springer.com/10.1007/s00213-006-0502-4},
volume = {191},
year = {2007}
}
@article{Nicola2010,
abstract = {Dopamine released in the nucleus accumbens is thought to contribute to the decision to exert effort to seek reward. This hypothesis is supported by findings that performance of tasks requiring higher levels of effort is more susceptible to disruption by manipulations that reduce accumbens dopamine function than tasks that require less effort. However, performance of some low-effort cue-responding tasks is highly dependent on accumbens dopamine. To reconcile these disparate results, we made detailed behavioral observations of rats performing various operant tasks and determined how injection of dopamine receptor antagonists into the accumbens influenced specific aspects of the animals' behavior. Strikingly, once animals began a chain of operant responses, the antagonists did not affect the ability to continue the chain until reward delivery. Instead, when rats left the operandum, the antagonists severely impaired the ability to return. We show that this impairment is specific to situations in which the animal must determine a new set of approach actions on each approach occasion; this behavior is called "flexible approach." Both high-effort operant tasks and some low-effort cue-responding tasks require dopamine receptor activation in the accumbens because animals pause their responding and explore the chamber, and accumbens dopamine is required to terminate these pauses with flexible approach to the operandum. The flexible approach hypothesis provides a unified framework for understanding the contribution of the accumbens and its dopamine projection to reward-seeking behavior.},
author = {Nicola, S. M.},
doi = {10.1523/JNEUROSCI.3958-10.2010},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {dec},
number = {49},
pages = {16585--16600},
pmid = {21147998},
title = {{The Flexible Approach Hypothesis: Unification of Effort and Cue-Responding Hypotheses for the Role of Nucleus Accumbens Dopamine in the Activation of Reward-Seeking Behavior}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21147998},
volume = {30},
year = {2010}
}
@article{Humphries2010,
author = {Humphries, M.D. and Prescott, T.J.},
journal = {Progress in Neurobiology},
number = {4},
pages = {385--417},
publisher = {Elsevier},
title = {{The ventral basal ganglia, a selection mechanism at the crossroads of space, strategy, and reward.}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S030100820900183X},
volume = {90},
year = {2010}
}
@article{Saddoris2011,
abstract = {During Pavlovian-to-instrumental transfer (PIT), learned Pavlovian cues significantly modulate ongoing instrumental actions. This phenomenon is suggested as a mechanism under which conditioned stimuli may lead to relapse in addicted populations. Following discriminative Pavlovian learning and instrumental conditioning with sucrose, one group of rats (naive) underwent electrophysiological recordings in the nucleus accumbens core and shell during a single PIT session. Other groups, following Pavlovian and instrumental conditioning, were subsequently trained to self-administer cocaine with nosepoke responses, or received yoked saline infusions and nosepoked for water rewards, and then performed PIT while electrophysiological recordings were taken in the nucleus accumbens. Behaviorally, although both naive and saline-treated groups showed increases in lever pressing during the conditioned stimulus cue, this effect was significantly enhanced in the cocaine-treated group. Neurons in the core and shell tracked these behavioral changes. In control animals, core neurons were significantly more likely to encode general information about cues, rewards and responses than those in the shell, and positively correlated with behavioral PIT performance, whereas PIT-specific encoding in the shell, but not core, tracked PIT performance. In contrast, following cocaine exposure, there was a significant increase in neural encoding of all task-relevant events that was selective to the shell. Given that cocaine exposure enhanced both behavior and shell-specific task encoding, these findings suggest that, whereas the core is important for acquiring the information about cues and response contingencies, the shell is important for using this information to guide and modulate behavior and is specifically affected following a history of cocaine self-administration.},
author = {Saddoris, Michael P and Stamatakis, Alice and Carelli, Regina M},
doi = {10.1111/j.1460-9568.2011.07683.x},
issn = {1460-9568},
journal = {The European journal of neuroscience},
month = {jun},
number = {12},
pages = {2274--87},
pmid = {21507084},
title = {{Neural correlates of Pavlovian-to-instrumental transfer in the nucleus accumbens shell are selectively potentiated following cocaine self-administration.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21507084},
volume = {33},
year = {2011}
}
@article{Birrell2000a,
abstract = {Forming place-reward associations critically depends on the integrity of the hippocampal-ventral striatal system. The ventral striatum (VS) receives a strong hippocampal input conveying spatial-contextual information, but it is unclear how this structure integrates this information to invigorate reward-directed behavior. Neuronal ensembles in rat hippocampus (HC) and VS were simultaneously recorded during a conditioning task in which navigation depended on path integration. In contrast to HC, ventral striatal neurons showed low spatial selectivity, but rather coded behavioral task phases toward reaching goal sites. Outcome-predicting cues induced a remapping of firing patterns in the HC, consistent with its role in episodic memory. VS remapped in conjunction with the HC, indicating that remapping can take place in multiple brain regions engaged in the same task. Subsets of ventral striatal neurons showed a "flip" from high activity when cue lights were illuminated to low activity in intertrial intervals, or vice versa. The cues induced an increase in spatial information transmission and sparsity in both structures. These effects were paralleled by an enhanced temporal specificity of ensemble coding and a more accurate reconstruction of the animal's position from population firing patterns. Altogether, the results reveal strong differences in spatial processing between hippocampal area CA1 and VS, but indicate similarities in how discrete cues impact on this processing.},
author = {Lansink, C S and Jackson, J C and Lankelma, J V and Ito, R and Robbins, T W and Everitt, B J and Pennartz, C M A},
doi = {10.1523/JNEUROSCI.0593-12.2012},
isbn = {0270-6474; 1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jun},
number = {36},
pages = {12444--12459},
pmid = {22956836},
publisher = {Society for Neuroscience},
title = {{Reward Cues in Space: Commonalities and Differences in Neural Coding by Hippocampal and Ventral Striatal Ensembles}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0593-12.2012},
volume = {32},
year = {2012}
}
@article{Grant1948,
abstract = {The University of Wisconsin Card-Sorting Test was used. The individual cards can be sorted on the basis either of the color, the number, or the form of the figures appearing on them. Color was arbitrarily selected as the initally "correct" sorting category. As each S sorted the cards he was told whether he was "right" or "wrong." As soon as S made a certain number of consecutive correct responses, E without explanation changed the "correct" basis of classification. Seven groups of about 20 Ss each were given 3, 4, 5, 6, 7, 8 and 10 reinforcing trials, respectively, before each shift. "Increasing the amount of reinforcement of original modes of response reduced the amount of perseveration of these responses when they suddenly became incorrect." Increased reinforcement also reduced the number of errors S made in reaching the new correct solution after deserting the old formerly correct one.},
author = {Grant, David A and Berg, Esta},
doi = {10.1037/h0059831},
isbn = {Print 0022-1015 Journal of Experimental Psychology General American Psychological Association Psychological Review Company; US Print},
issn = {00221015},
journal = {Journal of Experimental Psychology},
keywords = {CARD SORTING,CARD-SORTING,LEARNING,LEARNING {\{}{\&}{\}} MEMORY,REINFORCEMENT,RESPONSE,RESPONSE SHIFT,SHIFT,{\{}{\&}{\}} REINFORCEMENT,{\{}{\&}{\}} RESPONSE SHIFT},
number = {4},
pages = {404--411},
pmid = {18874598},
title = {{A behavioral analysis of degree of reinforcement and ease of shifting to new responses in a Weigl-type card-sorting problem}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0059831},
volume = {38},
year = {1948}
}
@article{Kaczkurkin2013,
abstract = {Generalization of conditioned fear refers to the transfer of the conditioned fear response to stimuli that resemble the original conditioned stimulus. Overgeneralization of conditioned fear has been associated with panic disorder and generalized anxiety disorder and may be relevant to obsessive-compulsive (OC) symptoms as well. This study represents the first attempt to determine the degree to which individuals with high versus low OC traits over generalize conditioned fear. We hypothesized that the high OC individuals, particularly those characterized by overestimation of threat, would show overgeneralization of conditioned fear compared to controls as measured by behavioral and psychophysiological (fear-potentiated startle) measures. The results of this study show an interaction between the high and low Threat Estimation groups as measured by the Obsessive Beliefs Questionnaire, which suggests that those who have a tendency to overestimate threat show overgeneralization of conditioned fear. This finding suggests that the relation between OC symptoms and overgeneralization of conditioned fear may be specific to the high threat estimation component of OC symptoms.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {{Shmuel Lissek}, Antonia N Kaczkurkin},
doi = {10.4172/2161-0487.S7-003},
eprint = {NIHMS150003},
isbn = {2122633255},
issn = {21610487},
journal = {Journal of Psychology {\{}{\&}{\}} Psychotherapy},
keywords = {Fear conditioning,Fear-potentiated startle,Generalization,Obsessive-compulsive disorder},
pages = {3},
pmid = {1000000221},
publisher = {NIH Public Access},
title = {{Generalization of Conditioned Fear and Obsessive-Compulsive Traits}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24567864 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3932061 https://www.omicsonline.org/generalization-of-conditioned-fear-and-obsessive-compulsive-traits-2161-0487.S7-003.php?aid=17795},
volume = {7},
year = {2013}
}
@article{Kaczkurkin2017,
abstract = {Objective:Heightened generalization of fear from an aversively reinforced conditioned stimulus (CS+, a conditioned danger cue) to resembling stimuli is widely accepted as a pathogenic marker of posttraumatic stress disorder (PTSD). Indeed, a distress response to benign stimuli that “resemble” aspects of the trauma is a central feature of the disorder. To date, the link between overgeneralization of conditioned fear and PTSD derives largely from clinical observations, with limited empirical work on the subject. This represents the first effort to examine behavioral and brain indices of generalized conditioned fear in PTSD using systematic methods developed in animals known as generalization gradients: the gradual decline in conditioned responding as the presented stimulus gradually differentiates from CS+.Method:Gradients of conditioned fear generalization were assessed using functional MRI and behavioral measures in U.S. combat veterans who served in Iraq or Afghanistan and had PTSD (N=26), subthreshold P...},
author = {Kaczkurkin, Antonia N and Burton, Philip C and Chazin, Shai M and Manbeck, Adrienne B and Espensen-Sturges, Tori and Cooper, Samuel E and Sponheim, Scott R and Lissek, Shmuel},
doi = {10.1176/appi.ajp.2016.15121549},
isbn = {0006-3223},
issn = {15357228},
journal = {American Journal of Psychiatry},
keywords = {Biological Markers,Cognitive Neuroscience,Emotion,Posttraumatic Stress Disorder},
month = {feb},
number = {2},
pages = {125--134},
pmid = {27794690},
publisher = {American Psychiatric AssociationArlington, VA},
title = {{Neural substrates of overgeneralized conditioned fear in PTSD}},
url = {http://ajp.psychiatryonline.org/doi/10.1176/appi.ajp.2016.15121549},
volume = {174},
year = {2017}
}
@article{ChiYiuYim1982,
abstract = {Extracellular single unit recordings were obtained from the nucleus accumbens of urethane anesthetized rats. It was found that electrical stimulation of the basal lateral and basal medial nuclei of the amygdala produced strong excitatory responses in neurons of the nucleus accumbens, in particular the medial region. Latencies of activation were relatively short with a mean of 10.7 ms. Dopamine applied iontophoretically had a marked attenuating effect on the excitatory response of nucleus accumbens neurons to amygdala stimulation. The spontaneous activity of all neurons recorded from the nucleus accumbens was also suppressed by dopamine, but the excitatory response was more sensitive to dopamine inhibition than the spontaneous activity. Neurons in the nucleus accumbens showed a variety of responses to single-pulse electrical stimulation of the ventral tegmental area (VTA). Some units in the nucleus accumbens received convergent inputs from both the amygdala and the VTA. Stimulation of the VTA also attenuated the response of nucleus accumbens neurons to excitatory inputs from the amygdala. A train of 10 pulses (0.15 ms, 200-600 ??A) at 10 Hz delivered to the VTA at 100 ms before stimulation of the amygdala caused attenuation of the original excitatory response. The attenuating effect could be observed irrespective of whether individual single-pulse stimulation of the VTA elicited a response in that particular accumbens neuron or not. 6-Hydroxydopamine injected into the VTA 2 days prior to the recording experiment, or haloperidol injected intraperitoneally 1 h before the recording session, abolished this attenuating effect. However, responses to single-pulse stimulations of the VTA were not abolished. The results suggest that the attenuation of the excitatory response to amygdala stimulation was due to the release of dopamine from mesolimbic dopaminergic neurons. Responses to single-pulse stimulations of the VTA were probably due to activation of non-dopaminergic neurons projecting from the same area. It is suggested as a working hypothesis that this inhibitory effect of dopamine may be an important function of the mesolimbic dopamine pathway in modulating the extent to which limbic structures can exert an influence on the motor system through the accumbens. ?? 1982.},
author = {{Chi Yiu Yim} and Mogenson, Gordon J},
doi = {10.1016/0006-8993(82)90518-2},
isbn = {0006-8993 (Print){\$}\backslash{\$}r0006-8993 (Linking)},
issn = {00068993},
journal = {Brain Research},
keywords = {amygdala,dopamine,neuromodulation,nucleus accumbens,ventral tegmental area},
month = {may},
number = {2},
pages = {401--415},
pmid = {6284305},
title = {{Response of nucleus accumbens neurons to amygdala stimulation and its modification by dopamine}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0006899382905182},
volume = {239},
year = {1982}
}
@article{Meer2009a,
abstract = {Local field potential (LFP) oscillations in the brain reflect organization thought to be important for perception, attention, movement, and memory. In the basal ganglia, including dorsal striatum, dysfunctional LFP states are associated with Parkinson's disease, while in healthy subjects, dorsal striatal LFPs have been linked to decision-making processes. However, LFPs in ventral striatum have been less studied. We report that in rats running a spatial decision task, prominent gamma-50 (45-55 Hz) and gamma-80 (70-85 Hz) oscillations in ventral striatum had distinct relationships to behavior, task events, and spiking activity. Gamma-50 power increased sharply following reward delivery and before movement initiation, while in contrast, gamma-80 power ramped up gradually to reward locations. Gamma-50 power was low and contained little structure during early learning, but rapidly developed a stable pattern, while gamma-80 power was initially high before returning to a stable level within a similar timeframe. Putative fast-spiking interneurons (FSIs) showed phase, firing rate, and coherence relationships with gamma-50 and gamma-80, indicating that the observed LFP patterns are locally relevant. Furthermore, in a number of FSIs such relationships were specific to gamma-50 or gamma-80, suggesting that partially distinct FSI populations mediate the effects of gamma-50 and gamma-80.},
author = {van der Meer, Matthijs A A and Redish, A David},
doi = {10.3389/neuro.07.009.2009},
journal = {Frontiers in Integrative Neuroscience},
pages = {9},
pmid = {19562092},
title = {{Low and High Gamma Oscillations in Rat Ventral Striatum have Distinct Relationships to Behavior, Reward, and Spiking Activity on a Learned Spatial Decision Task.}},
url = {http://dx.doi.org/10.3389/neuro.07.009.2009},
volume = {3},
year = {2009}
}
@article{VanderMeer2011,
abstract = {Extensive evidence implicates the ventral striatum in multiple distinct facets of action selection. Early work established a role in modulating ongoing behavior, as engaged by the energizing and directing influences of motivationally relevant cues and the willingness to expend effort in order to obtain reward. More recently, reinforcement learning models have suggested the notion of ventral striatum primarily as an evaluation step during learning, which serves as a critic to update a separate actor. Recent computational and experimental work may provide a resolution to the differences between these two theories through a careful parsing of behavior and the instrinsic heterogeneity that characterizes this complex structure.},
annote = {NULL},
author = {van der Meer, Matthijs A A and Redish, A David},
doi = {10.1016/j.conb.2011.02.011},
issn = {1873-6882},
journal = {Current Opinion in Neurobiology},
month = {mar},
number = {3},
pages = {387--92},
pmid = {21420853},
title = {{Ventral striatum: a critical look at models of learning and evaluation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3134536{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {21},
year = {2011}
}
@article{Noonan2017,
abstract = {The orbitofrontal cortex is critical for goal-directed behavior. Recent work in macaques has suggested the lateral orbitofrontal cortex (lOFC) is relatively more concerned with assignment of credit for rewards to particular choices during value-guided learning, whereas the medial orbitofrontal cortex (often referred to as ventromedial prefrontal cortex in humans; vmPFC/mOFC) is involved in constraining the decision to the relevant options. We examined whether people with damage restricted to subregions of prefrontal cortex showed the patterns of impairment observed in prior investigations of the effects of lesions to homologous regions in macaques. Groups of patients with either lOFC (predominantly right hemisphere), mOFC/vmPFC, or dorsomedial prefrontal (DMF), and a comparison group of healthy age- and education-matched controls performed a probabilistic 3-choice decision-making task. We report anatomically specific patterns of impairment. We found that credit assignment, as indexed by the normal influence of contingent relationships between choice and reward, is reduced in lOFC patients compared with Controls and mOFC/vmPFC patients. Moreover, the effects of reward contingency on choice were similar for patients with lesions in DMF or mOFC/vmPFC, compared with Controls. By contrast, mOFC/vmPFC-lesioned patients made more stochastic choices than Controls when the decision was framed by valuable distracting alternatives, suggesting that value comparisons were no longer independent of irrelevant options. Once again, there was evidence of regional specialization: patients with lOFC lesions were unimpaired relative to Controls. As in macaques, human lOFC and mOFC/vmPFC are necessary for contingent learning and value-guided decision-making, respectively.SIGNIFICANCE STATEMENT The lateral and medial regions of the orbitofrontal cortex are cytoarchitectonically distinct and have different anatomical connections. Previous investigations in macaques have shown these anatomical differences are accompanied by functional specialization for learning and decision-making. Here, for the first time, we test the predictions made by macaque studies in an experiment with humans with frontal lobe lesions, asking whether behavioral impairments can be linked to lateral or medial orbitofrontal cortex. Using equivalent tasks and computational analyses, our findings broadly replicate the pattern reported after selective lesions in monkeys. Patients with lateral orbitofrontal damage had impaired credit assignment, whereas damage to medial orbitofrontal cortex meant that patients were more likely to be distracted by irrelevant options.},
author = {Noonan, MaryAnn P and Chau, Bolton K H and Rushworth, Matthew F S and Fellows, Lesley K},
doi = {10.1523/JNEUROSCI.0692-17.2017},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {credit assignment,decision-making,orbitofrontal cortex,prefrontal cortex,reward,ventromedial prefrontal cortex},
month = {jul},
number = {29},
pages = {7023--7035},
pmid = {28630257},
publisher = {Society for Neuroscience},
title = {{Contrasting Effects of Medial and Lateral Orbitofrontal Cortex Lesions on Credit Assignment and Decision-Making in Humans}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0692-17.2017},
volume = {37},
year = {2017}
}
@article{Day2011,
abstract = {Efficient decision-making requires that animals consider both the benefits and the costs of potential actions, such as the amount of effort or temporal delay involved in reward seeking. The nucleus accumbens (NAc) has been implicated in the ability to choose between options with different costs and overcome high costs when necessary, but it is not clear how NAc processing contributes to this role. Here, neuronal activity in the rat NAc was monitored using multi-neuron electrophysiology during two cost-based decision tasks in which either reward effort or reward delay was manipulated. In each task, distinct visual cues predicted high-value (low effort/immediate) and low-value (high effort/delayed) rewards. After training, animals exhibited a behavioral preference for high-value rewards, yet overcame high costs when necessary to obtain rewards. Electrophysiological analysis indicated that a subgroup of NAc neurons exhibited phasic increases in firing rate during cue presentations. In the effort-based decision task (but not the delay-based task), this population reflected the cost-discounted value of the future response. In contrast, other subgroups of cells were activated during response initiation or reward delivery, but activity did not differ on the basis of reward cost. Finally, another population of cells exhibited sustained changes in firing rate while animals completed high-effort requirements or waited for delayed rewards. These findings are consistent with previous reports that implicate NAc function in reward prediction and behavioral allocation during reward-seeking behavior, and suggest a mechanism by which NAc activity contributes to both cost-based decisions and actual cost expenditure.},
author = {Day, Jeremy J and Jones, Joshua L and Carelli, Regina M},
doi = {10.1111/j.1460-9568.2010.07531.x},
file = {::},
issn = {1460-9568},
journal = {European journal of neuroscience},
keywords = {Animal,Animal: physiology,Animals,Behavior,Cues,Decision Making,Decision Making: physiology,Electrophysiology,Male,Neurons,Neurons: metabolism,Nucleus Accumbens,Nucleus Accumbens: cytology,Nucleus Accumbens: physiology,Random Allocation,Rats,Reward,Sprague-Dawley,Time Factors},
month = {jan},
number = {2},
pages = {308--21},
pmid = {21198983},
title = {{Nucleus accumbens neurons encode predicted and ongoing reward costs in rats.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3350310{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {33},
year = {2011}
}
@article{Shidara1998,
abstract = {Single neurons in the ventral striatum of primates carry signals that are related to reward and motivation. When monkeys performed a task requiring one to three bar release trials to be completed successfully before a reward was given, they seemed more motivated as the rewarded trials approached; they responded more quickly and accurately. When the monkeys were cued as to the progress of the schedule, 89 out of 150 ventral striatal neurons responded in at least one part of the task: (1) at the onset of the visual cue, (2) near the time of bar release, and/or (3) near the time of reward delivery. When the cue signaled progress through the schedule, the neuronal activity was related to the progress through the schedule. For example, one large group of these neurons responded in the first trial of every schedule, another large group responded in trials other than the first of a schedule, and a third large group responded in the first trial of schedules longer than one. Thus, these neurons coded the state of the cue, i.e., the neurons carried the information about how the monkey was progressing through the task. The differential activity disappeared on the first trial after randomizing the relation of the cue to the schedule. Considering the anatomical loop structure that includes ventral striatum and prefrontal cortex, we suggest that the ventral striatum might be part of a circuit that supports keeping track of progress through learned behavioral sequences that, when successfully completed, lead to reward.},
author = {Shidara, M and Aigner, T G and Richmond, B J},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animal,Animal: physiology,Animals,Association Learning,Association Learning: physiology,Behavior,Corpus Striatum,Corpus Striatum: cytology,Corpus Striatum: physiology,Electrophysiology,Macaca mulatta,Macaca mulatta: physiology,Motivation,Neurons,Neurons: physiology,Photic Stimulation,Reaction Time,Reaction Time: physiology,Reward},
month = {apr},
number = {7},
pages = {2613--25},
pmid = {9502820},
title = {{Neuronal signals in the monkey ventral striatum related to progress through a predictable series of trials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9502820},
volume = {18},
year = {1998}
}
@article{Ito2015,
abstract = {Previous theoretical studies of animal and human behavioral learning have focused on the dichotomy of the value-based strategy using action value functions to predict rewards and the model-based strategy using internal models to predict environmental states. However, animals and humans often take simple procedural behaviors, such as the "win-stay, lose-switch" strategy without explicit prediction of rewards or states. Here we consider another strategy, the finite state-based strategy, in which a subject selects an action depending on its discrete internal state and updates the state depending on the action chosen and the reward outcome. By analyzing choice behavior of rats in a free-choice task, we found that the finite state-based strategy fitted their behavioral choices more accurately than value-based and model-based strategies did. When fitted models were run autonomously with the same task, only the finite state-based strategy could reproduce the key feature of choice sequences. Analyses of neural activity recorded from the dorsolateral striatum (DLS), the dorsomedial striatum (DMS), and the ventral striatum (VS) identified significant fractions of neurons in all three subareas for which activities were correlated with individual states of the finite state-based strategy. The signal of internal states at the time of choice was found in DMS, and for clusters of states was found in VS. In addition, action values and state values of the value-based strategy were encoded in DMS and VS, respectively. These results suggest that both the value-based strategy and the finite state-based strategy are implemented in the striatum.},
author = {Ito, Makoto and Doya, Kenji},
doi = {10.1371/journal.pcbi.1004540},
editor = {Sporns, Olaf},
isbn = {1553734X},
issn = {15537358},
journal = {PLoS Computational Biology},
month = {nov},
number = {11},
pages = {e1004540},
pmid = {26529522},
publisher = {Public Library of Science},
title = {{Parallel Representation of Value-Based and Finite State-Based Strategies in the Ventral and Dorsal Striatum}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1004540},
volume = {11},
year = {2015}
}
@article{Cheer2007,
abstract = {Intracranial self-stimulation (ICSS) activates the neural pathways that mediate reward, including dopaminergic terminal areas such as the nucleus accumbens (NAc). However, a direct role of dopamine in ICSS-mediated reward has been questioned. Here, simultaneous voltammetric and electrophysiological recordings from the same electrode reveal that, at certain sites, the onset of anticipatory dopamine surges and changes in neuronal firing patterns during ICSS are coincident, whereas sites lacking dopamine changes also lack patterned firing. Intrashell microinfusion of a D1, but not a D2 receptor antagonist, blocks ICSS. An iontophoresis approach was implemented to explore the effect of dopamine antagonists on firing patterns without altering behavior. Similar to the microinfusion experiments, ICSS-related firing is selectively attenuated following D1 receptor blockade. This work establishes a temporal link between anticipatory rises of dopamine and firing patterns in the NAc shell during ICSS and suggests that they may play a similar role with natural rewards and during drug self-administration.},
author = {Cheer, Joseph F and Aragona, Brandon J and Heien, Michael L A V and Seipel, Andrew T and Carelli, Regina M and Wightman, R Mark},
doi = {10.1016/j.neuron.2007.03.021},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animals,Behavior, Animal,Behavior, Animal: physiology,Benzazepines,Benzazepines: administration {\&} dosage,Benzazepines: pharmacology,Brain,Brain: physiology,Cues,Dopamine,Dopamine Antagonists,Dopamine Antagonists: administration {\&} dosage,Dopamine Antagonists: pharmacology,Dopamine: metabolism,Goals,Iontophoresis,Male,Microinjections,Neurons,Neurons: physiology,Nucleus Accumbens,Nucleus Accumbens: metabolism,Rats,Rats, Sprague-Dawley,Receptors, Dopamine D1,Receptors, Dopamine D1: antagonists {\&} inhibitors,Reward,Self Stimulation,vStr-CurrOp},
mendeley-tags = {vStr-CurrOp},
month = {apr},
number = {2},
pages = {237--44},
pmid = {17442245},
title = {{Coordinated accumbal dopamine release and neural activity drive goal-directed behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17442245},
volume = {54},
year = {2007}
}
@article{Hearst,
author = {Hearst, E and Jenkins, H M},
title = {{Full Text}}
}
@misc{Wheeler2009,
abstract = {An important goal of cocaine addiction research is to understand the neurobiological mechanisms underlying this disease state. Here, we review studies from our laboratory that examined nucleus accumbens (NAc) cell firing and rapid dopamine signaling using electrophysiological and electrochemical recordings in behaving rodents. A major advantage of these techniques is that they allow for the characterization of NAc activity and rapid dopamine release during specific phases of motivated behavior. Moreover, each approach enables an examination of the dynamic nature of NAc signaling as a function of factors such as hedonics and associative learning. We show that NAc neurons differentially respond to rewarding and aversive stimuli and their predictors in a bivalent manner. This differential responding is modifiable and can be altered by the presentation of other natural rewards or cocaine. Likewise, the dynamic nature of NAc cell firing is also reflected in the differential activation of distinct populations of NAc neurons during goal-directed behaviors for natural versus drug rewards, and the heightened activation of some NAc neurons following cocaine abstinence. Our electrochemical data also show that rapid dopamine signaling in the NAc reflects primary rewards and their predictors and appears to modulate specific NAc neuronal responses. In some cases, these influences are observed in a regionally specific manner that matches previous pharmacological manipulations. Collectively, these findings provide critical insight into the functional organization of the NAc that can be used to guide additional studies aimed at dissecting the neural code underlying compulsive drug-seeking behavior. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Wheeler, Robert A. and Carelli, Regina M.},
booktitle = {Neuropharmacology},
doi = {10.1016/j.neuropharm.2008.06.028},
isbn = {9199628775},
issn = {00283908},
keywords = {Aversion,Cocaine,Drug abuse,Nucleus accumbens,Reward,Taste},
number = {SUPPL. 1},
pages = {149--159},
pmid = {18625253},
title = {{Dissecting motivational circuitry to understand substance abuse}},
volume = {56},
year = {2009}
}
@article{Honey2014,
abstract = {The central concern of associative learning theory is to provide an account of behavioral adaptation that is parsimonious in addressing three key questions: (1) under what conditions does learning occur, (2) what are the associative structures involved, and (3) how do these affect behavior? The principle focus here is on the second question, concerning associative structures, but we will have cause to touch on the others in passing. This question is one that has exercised theorists since Pavlov's descriptions of the conditioning process, where he identifies the shared significance of the study of conditioned reflexes for psychologists and neuroscientists alike. {\{}{\textcopyright}{\}} 2013 Elsevier Inc.},
author = {Honey, Robert C and Iordanova, Mihaela D and Good, Mark},
doi = {10.1016/j.nlm.2013.06.002},
issn = {10747427},
journal = {Neurobiology of Learning and Memory},
keywords = {Configural,Elemental,Hippocampus},
month = {feb},
pages = {96--103},
pmid = {23769767},
title = {{Associative structures in animal learning: Dissociating elemental and configural processes}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23769767 http://linkinghub.elsevier.com/retrieve/pii/S1074742713000944},
volume = {108},
year = {2014}
}
@article{stefani06,
author = {Stefani, Mark R and Moghaddam, Bita},
doi = {10.1523/JNEUROSCI.1656-06.2006},
journal = {J. Neurosci.},
number = {34},
pages = {8810--8818},
title = {{Rule Learning and Reward Contingency Are Associated with Dissociable Patterns of Dopamine Activation in the Rat Prefrontal Cortex, Nucleus Accumbens, and Dorsal Striatum}},
volume = {26},
year = {2006}
}
@article{Salamone2012,
author = {Salamone, John D. and Correa, Merc{\`{e}}},
doi = {10.1016/j.neuron.2012.10.021},
issn = {08966273},
journal = {Neuron},
month = {nov},
number = {3},
pages = {470--485},
title = {{The Mysterious Motivational Functions of Mesolimbic Dopamine}},
url = {http://www.cell.com/neuron/fulltext/S0896-6273(12)00941-5},
volume = {76},
year = {2012}
}
@article{Lansink2008,
abstract = {Spontaneous "off-line" reactivation of neuronal activity patterns may contribute to the consolidation of memory traces. The ventral striatum exhibits reactivation and has been implicated in the processing of motivational information. It is unknown, however, whether reactivating neuronal ensembles specifically recapitulate information relating to rewards that were encountered during wakefulness. We demonstrate a prolonged reactivation in rat ventral striatum during quiet wakefulness and slow-wave but not rapid eye movement sleep. Reactivation of reward-related information processed in this structure was particularly prominent, and this was primarily attributable to spike trains temporally linked to reward sites. It was accounted for by small, strongly correlated subgroups in recorded cell assemblies and can thus be characterized as a sparse phenomenon. Our results indicate that reactivated memory traces may not only comprise feature- and context-specific information but also contain a value component.},
author = {Lansink, Carien S and Goltstein, Pieter M and Lankelma, Jan V and Joosten, Ruud N J M A and McNaughton, Bruce L and Pennartz, Cyriel M A},
doi = {10.1523/JNEUROSCI.1054-08.2008},
journal = {Journal of Neuroscience},
keywords = {Action Potentials,Animals,Basal Ganglia,Choice,Reward,Wistar},
month = {jun},
number = {25},
pages = {6372--6382},
pmid = {18562607},
title = {{Preferential reactivation of motivationally relevant information in the ventral striatum.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.1054-08.2008},
volume = {28},
year = {2008}
}
@article{Lissek2014,
abstract = {Background Meta-analytic results of fear-conditioning studies in the anxiety disorders implicate generalization of conditioned fear to stimuli resembling the conditioned danger cue as one of the more robust conditioning markers of anxiety pathology. Due to the absence of conditioning studies assessing generalization in generalized anxiety disorder (GAD), results of this meta-analysis do not reveal whether such generalization abnormalities also apply to GAD. The current study fills this gap by behaviorally and psychophysiologically assessing levels of conditioned fear generalization across adults with and without GAD. Methods Twenty-two patients with a DSM-IV-Text Revision diagnosis of GAD and 26 healthy comparison subjects were recruited and tested. The employed generalization paradigm consisted of quasi-randomly presented rings of gradually increasing size, with extreme sizes serving as conditioned danger cues (CS+) and conditioned safety cues. The rings of intermediary size served as generalization stimuli, creating a continuum of similarity between CS+ and conditioned safety cues across which to assess response slopes, referred to as generalization gradients. Primary outcome variables included slopes for fear-potentiated startle (electromyography) and self-reported risk ratings. Results Behavioral and psychophysiological findings demonstrated overgeneralization of conditioned fear among patients with GAD. Specifically, generalization gradients were abnormally shallow among GAD patients, reflecting less degradation of the conditioned fear response as the presented stimulus differentiated from the CS+. Conclusions Overgeneralization of conditioned fear to safe encounters resembling feared situations may contribute importantly to the psychopathology of GAD by proliferating anxiety cues in the individual's environment that are then capable of evoking and maintaining anxiety and worry associated with GAD. {\{}{\textcopyright}{\}} 2014 Society of Biological Psychiatry.Published by Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Lissek, Shmuel and Kaczkurkin, Antonia N and Rabin, Stephanie and Geraci, Marilla and Pine, Daniel S and Grillon, Christian},
doi = {10.1016/j.biopsych.2013.07.025},
eprint = {NIHMS150003},
isbn = {6126269918},
issn = {18732402},
journal = {Biological Psychiatry},
keywords = {Fear conditioning,fear-potentiated startle,generalized anxiety disorder,interpretation bias,pathophysiology,stimulus generalization},
month = {jun},
number = {11},
pages = {909--915},
pmid = {24001473},
publisher = {Elsevier},
title = {{Generalized anxiety disorder is associated with overgeneralization of classically conditioned fear}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24001473 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3938992},
volume = {75},
year = {2014}
}
@article{Floresco2014,
abstract = {Nearly 40 years of research on the function of the nucleus accumbens (NAc) has provided a wealth of information on its contributions to behavior but has also yielded controversies and misconceptions regarding these functions. A primary tenet of this review is that, rather than serving as a “reward” center, the NAc plays a key role in action selection, integrating cognitive and affective information processed by frontal and temporal lobe regions to augment the efficiency and vigor of appetitively or aversively motivated behaviors. Its involvement in these functions is most prominent when the appropriate course of action is ambiguous, uncertain, laden with distractors, or in a state of flux. To this end, different subregions of the NAc play dissociable roles in refining action selection, promoting approach toward motivationally relevant stimuli, suppressing inappropriate actions so that goals may be obtained more efficiently, and encoding action outcomes that guide the direction of subsequent ones.},
author = {Floresco, S B},
doi = {10.1146/annurev-psych-010213-115159},
isbn = {0066-4308},
issn = {0066-4308},
journal = {Annual Review of Psychology},
keywords = {action selection,animal models,dopamine,fmri,ventral striatum},
language = {en},
month = {sep},
number = {1},
pages = {25--52},
pmid = {25251489},
publisher = {Annual Reviews},
title = {{The Nucleus Accumbens: An Interface Between Cognition, Emotion, and Action}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev-psych-010213-115159},
volume = {66},
year = {2015}
}
@article{Takahashi2016a,
abstract = {Dopamine neurons signal reward prediction errors. This requires accurate reward predictions. It has been suggested that the ventral striatum provides these predictions. Here we tested this hypothesis by recording from putative dopamine neurons in the VTA of rats performing a task in which prediction errors were induced by shifting reward timing or number. In controls, the neurons exhibited error signals in response to both manipulations. However, dopamine neurons in rats with ipsilateral ventral striatal lesions exhibited errors only to changes in number and failed to respond to changes in timing of reward. These results, supported by computational modeling, indicate that predictions about the temporal specificity and the number of expected reward are dissociable and that dopaminergic prediction-error signals rely on the ventral striatum for the former but not the latter.},
author = {Takahashi, Yuji K and Langdon, Angela J and Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1016/j.neuron.2016.05.015},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
month = {jul},
number = {1},
pages = {182--193},
pmid = {27292535},
title = {{Temporal Specificity of Reward Prediction Errors Signaled by Putative Dopamine Neurons in Rat VTA Depends on Ventral Striatum}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27292535 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4938771 http://linkinghub.elsevier.com/retrieve/pii/S0896627316301751},
volume = {91},
year = {2016}
}
@article{vanderMeer2010,
annote = {NULL},
author = {van der Meer, M A A and Redish, A D},
journal = {Frontiers in Neuroscience},
pages = {6},
title = {{Expectancies in decision making, reinforcement learning, and ventral striatum}},
volume = {4},
year = {2010}
}
@article{VanderMeerRedish2011,
abstract = {A functional interaction between the hippocampal formation and the ventral striatum is thought to contribute to the learning and expression of associations between places and rewards. However, the mechanism of how such associations may be learned and used is currently unknown. We recorded neural ensembles and local field potentials from the ventral striatum and CA1 simultaneously as rats ran a modified T-maze. Theta-modulated cells in ventral striatum almost invariably showed firing phase precession relative to the hippocampal theta rhythm. Across the population of ventral striatal cells, phase precession was preferentially associated with an anticipatory ramping of activity up to the reward sites. In contrast, CA1 population activity and phase precession were distributed more uniformly. Ventral striatal phase precession was stronger to hippocampal than ventral striatal theta and was accompanied by increased theta coherence with hippocampus, suggesting that this effect is hippocampally derived. These results suggest that the firing phase of ventral striatal neurons contains motivationally relevant information and that phase precession serves to bind hippocampal place representations to ventral striatal representations of reward.},
annote = {NULL},
author = {van der Meer, Matthijs A. A. and Redish, A. D.},
doi = {10.1523/JNEUROSCI.4869-10.2011},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {feb},
number = {8},
pages = {2843--2854},
pmid = {21414906},
title = {{Theta phase precession in rat ventral striatum links place and reward information}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21414906},
volume = {31},
year = {2011}
}
@article{Sugam2014,
abstract = {BACKGROUND
To make appropriate decisions, organisms must evaluate the risks and benefits of action selection. The nucleus accumbens (NAc) has been shown to be critical for this processing and is necessary for appropriate risk-based decision-making behavior. However, it is not clear how NAc neurons encode this information to promote appropriate behavioral responding. 

METHODS
Here, rats (n = 17) were trained to perform a risky decision-making task in which discrete visual cues predicted the availability to respond for a smaller certain (safer) or larger uncertain (riskier) reward. Electrophysiological recordings were made in the NAc core and shell to evaluate neural activity during task performance. 

RESULTS
At test, animals exhibited individual differences in risk-taking behavior; some displayed a preference for the risky option, some the safe option, and some did not have a preference. Electrophysiological analysis indicated that NAc neurons differentially encoded information related to risk versus safe outcomes. Further, during free choice trials, neural activity during reward-predictive cues reflected individual behavioral preferences. In addition, neural encoding of reward outcomes was correlated with risk-taking behavior, with safe-preferring and risk-preferring rats showing differential activity in the NAc core and shell during reward omissions. 

CONCLUSIONS
Consistent with previously demonstrated alterations in prospective reward value with effort and delay, NAc neurons encode information during reward-predictive cues and outcomes in a risk task that tracked the rats' preferred responses. This processing appears to contribute to subjective encoding of anticipated outcomes and thus may function to bias future risk-based decisions.},
author = {Sugam, Jonathan A. and Saddoris, Michael P. and Carelli, Regina M.},
doi = {10.1016/j.biopsych.2013.09.010},
issn = {00063223},
journal = {Biological Psychiatry},
number = {10},
pages = {807--816},
title = {{Nucleus Accumbens Neurons Track Behavioral Preferences and Reward Outcomes During Risky Decision Making}},
volume = {75},
year = {2014}
}
@article{Wiener2003,
author = {Wiener, Sidney I and Shibata, Ryoko and Tabuchi, Eiichi and Trullier, Olivier and Albertin, Sergey V and Mulder, Antonius B},
doi = {10.1016/S0531-5131(03)00978-6},
issn = {05315131},
journal = {International Congress Series},
keywords = {33-1-44271382,33-1-44271621,college-de-france,corresponding author,e-mail address,fax,fr,i,limbic system,navigation,place cells,s,sidney,spatial orientation,striatum,tel,wiener},
month = {oct},
pages = {275--292},
title = {{Spatial and behavioral correlates in nucleus accumbens neurons in zones receiving hippocampal or prefrontal cortical inputs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0531513103009786},
volume = {1250},
year = {2003}
}
@article{holland1992occasion,
author = {Holland, Peter C},
journal = {Psychology of Learning and Motivation},
pages = {69--125},
publisher = {Elsevier},
title = {{Occasion setting in Pavlovian conditioning}},
volume = {28},
year = {1992}
}
@article{Sleezer2016,
abstract = {Activemaintenanceof rules, like other executive functions, is often thought to be the domain of a discrete executive system.Analternative view is that rule maintenance is a broadly distributed function relyingonwidespread corticalandsubcortical circuits. Tentative evidence supporting this view comes from research showing some rule selectivity in the orbitofrontal cortex and dorsal striatum.Werecorded in these regions and in the ventral striatum, which has not been associated previously with rule representation, as macaques performed a Wisconsin Card Sorting Task.Wefound robust encoding of rule category (color vs shape) and rule identity (six possible rules) in all three regions. Rule identity modulated responses to potential choice targets, suggesting that rule information guides behavior by highlighting choice targets. The effects that we observed were not explained by differences in behavioral performance across rules and thus cannot be attributed torewardexpectation.Ourresults suggest that rulemaintenanceandrule-guided selection of options are distributed processes and provide new insight into orbital and striatal contributions to executive control.},
author = {Sleezer, B J and Castagno, M D and Hayden, B Y},
doi = {10.1523/JNEUROSCI.1766-16.2016},
isbn = {1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {decision making,executive control,macaque,orbitofrontal cortex,single unit,striatum},
month = {nov},
number = {44},
pages = {11223--11237},
pmid = {27807165},
publisher = {Society for Neuroscience},
title = {{Rule Encoding in Orbitofrontal Cortex and Striatum Guides Selection}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1766-16.2016},
volume = {36},
year = {2016}
}
@article{Berridge2007,
author = {Berridge, K.C.},
doi = {10.1007/s00213-006-0578-x},
journal = {Psychopharmacology},
keywords = {accumbens,appetite,associative learning,aversion,basal forebrain,dopamine,opioid,reward},
number = {3},
pages = {391--431},
publisher = {Springer},
title = {{The debate over dopamine$\backslash$'s role in reward: the case for incentive salience}},
url = {http://www.springerlink.com/index/N2L74J4847227N83.pdf},
volume = {191},
year = {2007}
}
@misc{Corlett2010,
abstract = {Delusions are the false and often incorrigible beliefs that can cause severe suffering in mental illness. We cannot yet explain them in terms of underlying neurobiological abnormalities. However, by drawing on recent advances in the biological, computational and psychological processes of reinforcement learning, memory, and perception it may be feasible to account for delusions in terms of cognition and brain function. The account focuses on a particular parameter, prediction error - the mismatch between expectation and experience - that provides a computational mechanism common to cortical hierarchies, fronto-striatal circuits and the amygdala as well as parietal cortices. We suggest that delusions result from aberrations in how brain circuits specify hierarchical predictions, and how they compute and respond to prediction errors. Defects in these fundamental brain mechanisms can vitiate perception, memory, bodily agency and social learning such that individuals with delusions experience an internal and external world that healthy individuals would find difficult to comprehend. The present model attempts to provide a framework through which we can build a mechanistic and translational understanding of these puzzling symptoms. {\textcopyright} 2010 Elsevier Ltd.},
author = {Corlett, P. R. and Taylor, J. R. and Wang, X. J. and Fletcher, P. C. and Krystal, J. H.},
booktitle = {Progress in Neurobiology},
doi = {10.1016/j.pneurobio.2010.06.007},
isbn = {1873-5118 (Electronic)$\backslash$r0301-0082 (Linking)},
issn = {03010082},
keywords = {Delusions,Error,Habit,Learning,Memory,Prediction,Reconsolidation},
month = {nov},
number = {3},
pages = {345--369},
pmid = {20558235},
publisher = {Pergamon},
title = {{Toward a neurobiology of delusions}},
url = {https://www.sciencedirect.com/science/article/pii/S030100821000119X},
volume = {92},
year = {2010}
}
@article{mulder04,
author = {Mulder, A B and Tabuchi, E and Wiener, S I},
journal = {European Journal of Neuroscience},
pages = {1923--1932},
title = {{Neurons in hippocampal afferent zones of rat striatum parse routes into multi-pace segments during maze navigation}},
volume = {19},
year = {2004}
}
@article{Hollerman1998,
author = {Hollerman, Jeffrey R. and Tremblay, Leon and Schultz, Wolfram},
file = {::},
journal = {J Neurophysiol},
number = {2},
pages = {947--963},
title = {{Influence of Reward Expectation on Behavior-Related Neuronal Activity in Primate Striatum}},
url = {http://jn.physiology.org/cgi/content/abstract/80/2/947},
volume = {80},
year = {1998}
}
@article{Day2007,
abstract = {The ability to predict favorable outcomes using environmental cues is an essential part of learned behavior. Dopamine neurons in the midbrain encode such stimulus-reward relationships in a manner consistent with contemporary learning models, but it is unclear how encoding this translates into actual dopamine release in target regions. Here, we sampled dopamine levels in the rat nucleus accumbens on a rapid (100 ms) timescale using electrochemical technology during a classical conditioning procedure. Early in conditioning, transient dopamine-release events signaled a primary reward, but not predictive cues. After repeated cue-reward pairings, dopamine signals shifted in time to predictive cue onset and were no longer observed at reward delivery. In the absence of stimulus-reward conditioning, there was no shift in the dopamine signal. Consistent with proposed roles in reward prediction and incentive salience, these results indicate that rapid dopamine release provides a reward signal that is dynamically modified by associative learning.},
author = {Day, Jeremy J and Roitman, Mitchell F and Wightman, R Mark and Carelli, Regina M},
doi = {10.1038/nn1923},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Association Learning,Association Learning: physiology,Behavior, Animal,Conditioning, Classical,Conditioning, Classical: physiology,Dopamine,Dopamine: metabolism,Electrochemistry,Electrochemistry: methods,Male,Nucleus Accumbens,Nucleus Accumbens: metabolism,Probability,Rats,Rats, Sprague-Dawley,Reward},
month = {aug},
number = {8},
pages = {1020--8},
pmid = {17603481},
title = {{Associative learning mediates dynamic shifts in dopamine signaling in the nucleus accumbens.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17603481},
volume = {10},
year = {2007}
}
@article{Strait2015,
abstract = {The ventral striatum (VS), like its cortical afferents, is closely associated with processing of rewards, but the relative contributions of striatal and cortical reward systems remains unclear. Most theories posit distinct roles for these structures, despite their similarities. We compared responses of VS neurons to those of ventromedial prefrontal cortex (vmPFC) Area 14 neurons, recorded in a risky choice task. Five major response patterns observed in vmPFC were also observed in VS: (1) offer value encoding, (2) value difference encoding, (3) preferential encoding of chosen relative to unchosen value, (4) a correlation between residual variance in responses and choices, and (5) prominent encoding of outcomes. We did observe some differences as well; in particular, preferential encoding of the chosen option was stronger and started earlier in VS than in vmPFC. Nonetheless, the close match between vmPFC and VS suggests that cortex and its striatal targets make overlapping contributions to economic choice.},
author = {Strait, Caleb E and Sleezer, Brianna J and Hayden, Benjamin Y},
doi = {10.1371/journal.pbio.1002173},
issn = {1545-7885},
journal = {PLoS biology},
month = {jun},
number = {6},
pages = {e1002173},
pmid = {26086735},
publisher = {Public Library of Science},
title = {{Signatures of Value Comparison in Ventral Striatum Neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26086735 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4472856},
volume = {13},
year = {2015}
}
@article{Berke2009,
abstract = {The striatum and hippocampus are widely held to be components of distinct
memory systems that can guide competing behavioral strategies. However,
some electrophysiological studies have suggested that neurons in
both structures encode spatial information and may therefore make
similar contributions to behavior. In rats well trained to perform
a win-stay radial maze task, we recorded simultaneously from dorsal
hippocampus and from multiple striatal subregions, including both
lateral areas implicated in motor responses to cues and medial areas
that work cooperatively with hippocampus in cognitive operations.
In each brain region, movement through the maze was accompanied by
the continuous sequential activation of sets of projection neurons.
Hippocampal neurons overwhelmingly were active at a single spatial
location (place cells). Striatal projection neurons were active at
discrete points within the progression of every trial-especially
during choices or following reward delivery-regardless of spatial
position. Place-cell-type firing was not observed even for medial
striatal cells entrained to the hippocampal theta rhythm. We also
examined neural coding in earlier training sessions, when rats made
use of spatial working memory to guide choices, and again found that
striatal cells did not show place-cell-type firing. Prospective or
retrospective encoding of trajectory was not observed in either hippocampus
or striatum, at either training stage. Our results indicate that,
at least in this task, dorsal hippocampus uses a spatial foundation
for information processing that is not substantially modulated by
spatial working memory demands. By contrast, striatal cells do not
use such a spatial foundation, even in medial subregions that cooperate
with hippocampus in the selection of spatial strategies. The progressive
dominance of a striatum-dependent strategy does not appear to be
accompanied by large changes in striatal or hippocampal single-cell
representations, suggesting that the conflict between strategies
may be resolved elsewhere.},
author = {Berke, Joshua D and Breck, Jason T and Eichenbaum, Howard},
doi = {10.1152/jn.91106.2008},
journal = {J Neurophysiol},
keywords = {Action Potentials; Animals; Corpus Striatum; Cues;,Long-Evans; Reward; Space Perception,Short-Term; Motor Activity; Neurons; Rats; Rats},
month = {mar},
number = {3},
pages = {1575--1587},
pmid = {19144741},
title = {{Striatal versus hippocampal representations during win-stay maze performance.}},
url = {http://dx.doi.org/10.1152/jn.91106.2008},
volume = {101},
year = {2009}
}
@article{Phillips2003,
abstract = {Evidence is reviewed in support of a role for the mesocorticolimbic dopamine system in motivated behavior as opposed to the hedonic assessment of reward stimuli. Microdialysis studies describe the dynamic changes in dopamine efflux in the medial prefrontal cortex (mPFC) and nucleus accumbens (NAc) during the development of sensory-specific satiety for food or sexual activity by male rats. These data confirm that dopamine efflux is increased in both regions in anticipation of reward and decreases with the development of satiety. Importantly, presentation of a novel reward stimulus is accompanied by a further increase in dopamine efflux. Neural circuits linking the hippocampal formation to the prefrontal cortex and nucleus accumbens subserve memory-based search behaviors for food reward. Furthermore, dopamine D1 receptors in the prefrontal cortex selective modulate working memory processes responsible for the accurate recall of the location of food reward. In contrast, dopamine D1 receptors in the nucleus accumbens modulate memory-based search behavior, without prior knowledge of the location of food. A final series of experiments confirm that dopamine efflux in the medial prefrontal cortex triggered by expectation of food reward is related to the accuracy of recall for the location of food reward. Collectively, these experiments support the hypothesis that dopamine serves as a critical link between motivational and memory processes. {\{}{\textcopyright}{\}} 2003, Elsevier Science B.V. All rights reserved.},
author = {Phillips, Anthony G},
doi = {10.1016/S0531-5131(03)00188-2},
isbn = {1604822775},
issn = {05315131},
journal = {International Congress Series},
keywords = {Dopamine,Memory,Microdialysis,Motivation,Reward},
month = {aug},
number = {C},
pages = {509--526},
pmid = {9705481},
title = {{Mesocorticolimbic dopamine: A neurochemical link between motivation and memory}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9705481 http://www.physiology.org/doi/10.1152/jn.1998.80.2.947},
volume = {1250},
year = {2003}
}
@article{West2016,
abstract = {Nucleus accumbens (NAc) neurons encode features of stimulus learning and action selection associated with rewards. The NAc is necessary for using information about expected outcome values to guide behavior after reinforcer devaluation. Evidence suggests that core and shell subregions may play dissociable roles in guiding motivated behavior. Here, we recorded neural activity in the NAc core and shell during training and performance of a reinforcer devaluation task. Long-Evans male rats were trained that presses on a lever under an illuminated cue light delivered a flavored sucrose reward. On subsequent test days, each rat was given free access to one of two distinctly flavored foods to consume to satiation and were then immediately tested on the lever pressing task under extinction conditions. Rats decreased pressing on the test day when the reinforcer earned during training was the sated flavor (devalued) compared with the test day when the reinforcer was not the sated flavor (nondevalued), demonstrating evidence of outcome-selective devaluation. Cue-selective encoding during training by NAc core (but not shell) neurons reliably predicted subsequent behavioral performance; that is, the greater the percentage of neurons that responded to the cue, the better the rats suppressed responding after devaluation. In contrast, NAc shell (but not core) neurons significantly decreased cue-selective encoding in the devalued condition compared with the nondevalued condition. These data reveal that NAc core and shell neurons encode information differentially about outcome-specific cues after reinforcer devaluation that are related to behavioral performance and outcome value, respectively. SIGNIFICANCE STATEMENT Many neuropsychiatric disorders are marked by impairments in behavioral flexibility. Although the nucleus accumbens (NAc) is required for behavioral flexibility, it is not known how NAc neurons encode this information. Here, we recorded NAc neurons during a training session in which rats learned that a cue predicted a specific reward and during a test session when that reward value was changed. Although encoding in the core during training predicted the ability of rats to change behavior after the reward value was altered, the NAc shell encoded information about the change in reward value during the test session. These findings suggest differential roles of the core and shell in behavioral flexibility.},
author = {West, E A and Carelli, R M},
doi = {10.1523/JNEUROSCI.2976-15.2016},
isbn = {1529-2401 (Electronic){\$}\backslash{\$}r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {accumbens,behavior,devaluation,electrophysiology,motivation,rat},
month = {jan},
number = {4},
pages = {1128--1139},
pmid = {26818502},
publisher = {Society for Neuroscience},
title = {{Nucleus Accumbens Core and Shell Differentially Encode Reward-Associated Cues after Reinforcer Devaluation}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2976-15.2016},
volume = {36},
year = {2016}
}
@article{Goldstein2012,
abstract = {The ventral striatum (VS) is thought to signal the predicted value of expected outcomes. However, it is still unclear whether VS can encode value independently from variables often yoked to value such as response direction and latency. Expectations of high value reward are often associated with a particular action and faster latencies. To address this issue we trained rats to perform a task in which the size of the predicted reward was signaled before the instrumental response was instructed. Instrumental directional cues were presented briefly at a variable onset to reduce accuracy and increase reaction time. Rats were more accurate and slower when a large versus small reward was at stake. We found that activity in VS was high during odors that predicted large reward even though reaction times were slower under these conditions. In addition to these effects, we found that activity before the reward predicting cue reflected past and predicted reward. These results demonstrate that VS can encode value independent of motor contingencies and that the role of VS in goal-directed behavior is not just to increase vigor of specific actions when more is at stake.},
author = {Goldstein, B. L. and Barnett, B. R. and Vasquez, G. and Tobia, S. C. and Kashtelyan, V. and Burton, A. C. and Bryden, D. W. and Roesch, M. R.},
doi = {10.1523/JNEUROSCI.5349-11.2012},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {feb},
number = {6},
pages = {2027--2036},
pmid = {22323717},
title = {{Ventral Striatum Encodes Past and Predicted Value Independent of Motor Contingencies}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22323717},
volume = {32},
year = {2012}
}
@article{Corbit2011,
abstract = {Tests of Pavlovian-instrumental transfer (PIT) demonstrate that reward-predictive stimuli can exert a powerful motivational influence on the performance of instrumental actions. Recent evidence suggests that predictive stimuli produce this effect through either the general arousal (general PIT) or the specific predictions (outcome-specific PIT) produced by their association with reward. In two experiments, we examined the effects of pretraining lesions (Experiment 1) or muscimol-induced inactivation (Experiment 2) of either the core or shell regions of the nucleus accumbens (NAC) on these forms of PIT. Rats received Pavlovian training in which three auditory stimuli each predicted the delivery of a distinct food outcome. Separately, the rats were trained to perform two instrumental actions, each of which earned one of the outcomes used in Pavlovian conditioning. Finally, the effects of the three stimuli on performance of the two actions were assessed in extinction. Here we report evidence of a double dissociation between general and outcome-specific PIT at the level of the accumbens. Shell lesions eliminated outcome-specific PIT but spared general PIT, whereas lesions of the core abolished general PIT but spared outcome-specific PIT. Importantly, the infusion of muscimol into core or shell made immediately before the PIT tests produced a similar pattern of results. These results suggest that whereas the NAC core mediates the general excitatory effects of reward-related cues, the NAC shell mediates the effect of outcome-specific reward predictions on instrumental performance, and thereby serve to clarify reported discrepancies regarding the role of the NAC core and shell in PIT.},
author = {Corbit, Laura H and Balleine, Bernard W},
doi = {10.1523/JNEUROSCI.2711-11.2011},
file = {::},
issn = {1529-2401},
journal = {Journal of Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Animals,Classical,Classical: physiology,Conditioning,Extinction,Feeding Behavior,Feeding Behavior: physiology,Long-Evans,Male,Motivation,Motivation: physiology,Nucleus Accumbens,Nucleus Accumbens: anatomy {\&} histology,Nucleus Accumbens: physiology,Psychological,Psychological: physiology,Rats},
month = {aug},
number = {33},
pages = {11786--94},
pmid = {21849539},
title = {{The general and outcome-specific forms of Pavlovian-instrumental transfer are differentially mediated by the nucleus accumbens core and shell.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3208020{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {31},
year = {2011}
}
@article{McGinty2013,
abstract = {A key function of the nucleus accumbens is to promote vigorous reward seeking, but the corresponding neural mechanism has not been identified despite many years of research. Here, we study cued flexible approach behavior, a form of reward seeking that strongly depends on the accumbens, and we describe a robust, single-cell neural correlate of behavioral vigor in the excitatory response of accumbens neurons to reward-predictive cues. Well before locomotion begins, this cue-evoked excitation predicts both the movement initiation latency and the speed of subsequent flexible approach responses, but not those of stereotyped, inflexible responses. Moreover, the excitation simultaneously signals the subject's proximity to the approach target, a signal that appears to mediate greater response vigor on trials that begin with the subject closer to the target. These results demonstrate a neural mechanism for response invigoration whereby accumbens neuronal encoding of reward availability and target proximity together drive the onset and speed of reward-seeking locomotion.},
author = {McGinty, Vincent B and Lardeux, Sylvie and Taha, Sharif A and Kim, James J and Nicola, Saleem M},
doi = {10.1016/j.neuron.2013.04.010},
issn = {1097-4199},
journal = {Neuron},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Brain Mapping,Conditioning, Operant,Conditioning, Operant: physiology,Cues,Discrimination (Psychology),Electrodes, Implanted,Functional Laterality,Locomotion,Locomotion: physiology,Models, Biological,Neurons,Neurons: physiology,Nucleus Accumbens,Nucleus Accumbens: cytology,Nucleus Accumbens: physiology,Orientation,Principal Component Analysis,Rats,Reaction Time,Reaction Time: physiology,Reward,Videotape Recording},
month = {jun},
number = {5},
pages = {910--22},
pmid = {23764290},
title = {{Invigoration of reward seeking by cue and proximity encoding in the nucleus accumbens.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23764290},
volume = {78},
year = {2013}
}
@article{FitzGerald2014,
abstract = {Multiple features of the environment are often imbued with motivational significance, and the relative importance of these can change across contexts. The ability to flexibly adjust evaluative processes so that currently important features of the environment alone drive behavior is critical to adaptive routines. We know relatively little about the neural mechanisms involved, including whether motivationally significant features are obligatorily evaluated or whether current relevance gates access to value-sensitive regions. We addressed these questions using functional magnetic resonance imaging data and a task design where human subjects had to choose whether to accept or reject an offer indicated by visual and auditory stimuli. By manipulating, on a trial-by-trial basis, which stimulus determined the value of the offer, we show choice activity in the ventral striatum solely reflects the value of the currently relevant stimulus, consistent with a model wherein behavioral relevance modulates the impact of sensory stimuli on value processing. Choice outcome signals in this same region covaried positively with wins on accept trials, and negatively with wins on reject trials, consistent with striatal activity at feedback reflecting correctness of response rather than reward processing per se. We conclude that ventral striatum activity during decision making is dynamically modulated by behavioral context, indexed here by task relevance and action selection.},
author = {FitzGerald, T. H. B. and Schwartenbeck, P. and Dolan, R. J.},
doi = {10.1523/JNEUROSCI.4389-13.2014},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jan},
number = {4},
pages = {1271--1279},
title = {{Reward-Related Activity in Ventral Striatum Is Action Contingent and Modulated by Behavioral Relevance}},
url = {http://www.jneurosci.org/content/34/4/1271.short?rss=1},
volume = {34},
year = {2014}
}
@article{Chang2013,
abstract = {Certain Pavlovian conditioned stimuli (CSs) paired with food unconditioned stimuli (USs) come to elicit approach and even consumption-like behaviors in rats (sign-tracking). We investigated the effects of lesions of the nucleus accumbens core (ACbC) or shell (ACbS) on the acquisition of sign-tracking in a discriminative autoshaping procedure in which presentation of one lever CS was followed by delivery of sucrose, and another was not. Although we previously found that bilateral lesions of the whole ACb disrupted the initial acquisition of sign-tracking, neither ACbC or ACbS lesions affected the rate or percentage of trials in which rats pressed the CS+. In addition, detailed video analysis showed no effect of either lesion on the topography of the sign-tracking conditioned response (CR). These and other results from lesion studies of autoshaping contrast with those from previous sign-tracking experiments that used purely visual cues (Parkinson et al., 2000a,b), suggesting that the neural circuitry involved in assigning incentive value depends upon the nature of the CS.},
author = {Chang, Stephen E. and Holland, Peter C.},
doi = {10.1016/j.bbr.2013.07.046},
issn = {01664328},
journal = {Behavioural Brain Research},
pages = {36--42},
title = {{Effects of nucleus accumbens core and shell lesions on autoshaped lever-pressing}},
volume = {256},
year = {2013}
}
@article{cohen1992context,
author = {Cohen, Jonathan D and Servan-Schreiber, David},
journal = {Psychological review},
number = {1},
pages = {45},
publisher = {American Psychological Association},
title = {{Context, cortex, and dopamine: a connectionist approach to behavior and biology in schizophrenia.}},
volume = {99},
year = {1992}
}
@article{Flint1991,
abstract = {A number of psychiatric phenomena complicate dementia. The author suggests that if we are to understand and manage these noncognitive, neuropsychiatric manifestations, they need to be studied individually rather than in a global fashion. As one example of these phenomena, delusions complicating dementia are reviewed. Nosology, phenomenology, epidemiology, clinical characteristics, treatment, and course are discussed. Ideas for future research are suggested.;},
author = {Flint, A J},
doi = {10.1176/jnp.3.2.121},
issn = {0895-0172},
journal = {The Journal Of Neuropsychiatry And Clinical Neurosciences},
keywords = {Alzheimer Disease/*psychology,Alzheimer Disease/diagnosis,Alzheimer Disease/drug therapy,Antipsychotic Agents/therapeutic use,Delusions/*psychology,Delusions/diagnosis,Delusions/drug therapy,Dementia/*psychology,Dementia/diagnosis,Dementia/drug therapy,Humans,Neuropsychological Tests,Psychiatric Status Rating Scales},
month = {may},
number = {2},
pages = {121--130},
pmid = {1687962},
title = {{Delusions in dementia: a review.}},
url = {http://psychiatryonline.org/doi/abs/10.1176/jnp.3.2.121 http://search.ebscohost.com/login.aspx?direct=true{\%}7B{\&}{\%}7Ddb=cmedm{\%}7B{\&}{\%}7DAN=1687962{\%}7B{\&}{\%}7Dsite=ehost-live},
volume = {3},
year = {1991}
}
@article{Rescorla1967a,
author = {Rescorla, R A and Solomon, R L},
journal = {Psychological Review},
pages = {151--182},
title = {{Two-process learning theory: Relationships between Pavlovian conditioning and instrumental learning}},
volume = {74},
year = {1967}
}
@article{Weiner1996,
abstract = {Latent inhibition (LI) consists of retardation in conditioning to a stimulus as a consequence of its prior non-reinforced preexposure. In view of findings that LI is disrupted in acute schizophrenic patients and evidence from animal experiments pointing to the involvement of the mesolimbic dopamine (DA) system in this phenomenon, the present study investigated the effects of electrolytic lesions to the shell and core subterritories of the nucleus accumbens on LI in rats (Expt. 1). LI was indexed by the amount of suppression of drinking in the presence of a tone that was either pre-exposed or not prior to its pairing with reinforcement (a foot shock). Expt. 2 tested the effects of the DA antagonist, haloperidol, on LI in shell- and core-lesioned animals. Expt. 3 tested the effects of shell and core lesions on spontaneous and amphetamine-induced locomotion. In Expt. 1, LI, i.e., lower suppression of drinking in the pre-exposed as compared to the non-pre-exposed animals, was obtained in the sham-operated condition. Core and shell lesions produced distinct effects on LI. Animals with core lesions developed LI, but exhibited an overall lower suppression of drinking in comparison to the sham-operated animals. In contrast, shell lesions led to a disappearance of LI. Expt. 2 replicated the differential effects of shell and core lesions on LI, although in this experiment, core lesion did not attenuate suppression of drinking. Haloperidol prevented shell-induced abolition of LI. In Expt. 3, shell- but not core-lesioned animals were more active than sham controls following amphetamine administration. These results provide evidence for functional differences between the shell and core subregions, as well as for the involvement of the mesolimbic DA system in LI.},
author = {Weiner, I and Gal, G and Rawlins, J N P and Feldon, J},
doi = {10.1016/S0166-4328(96)00051-4},
isbn = {0166-4328 (Print){\$}\backslash{\$}r0166-4328 (Linking)},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {activity,core,latent inhibition,nucleus accumbens,rat,shell},
month = {nov},
number = {1-2},
pages = {123--133},
pmid = {8950008},
publisher = {Society for Neuroscience},
title = {{Differential involvement of the shell and core subterritories of the nucleus accumbens in latent inhibition and amphetamine-induced activity}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8950008},
volume = {81},
year = {1996}
}
@article{Ambroggi2008,
abstract = {Both the nucleus accumbens (NAc) and basolateral amygdala (BLA) contribute to learned behavioral choice. Neurons in both structures that encode reward-predictive cues may underlie the decision to respond to such cues, but the neural circuits by which the BLA influences reward-seeking behavior have not been established. Here, we test the hypothesis that the BLA drives NAc neuronal responses to reward-predictive cues. First, using a disconnection experiment, we show that the BLA and dopamine projections to the NAc interact to promote the reward-seeking behavioral response. Next, we demonstrate that BLA neuronal responses to cues precede those of NAc neurons and that cue-evoked excitation of NAc neurons depends on BLA input. These results indicate that BLA input is required for dopamine to enhance the cue-evoked firing of NAc neurons and that this enhanced firing promotes reward-seeking behavior.},
author = {Ambroggi, Frederic and Ishikawa, Akinori and Fields, Howard L and Nicola, Saleem M},
doi = {10.1016/j.neuron.2008.07.004},
issn = {1097-4199},
journal = {Neuron},
keywords = {Amygdala,Amygdala: cytology,Amygdala: physiology,Animals,Appetitive Behavior,Appetitive Behavior: physiology,Choice Behavior,Choice Behavior: physiology,Discrimination Learning,Discrimination Learning: physiology,Dopamine,Dopamine: physiology,Glycopeptides,Male,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurons,Neurons: physiology,Nucleus Accumbens,Nucleus Accumbens: cytology,Nucleus Accumbens: physiology,Rats,Rats, Long-Evans,Rats, Sprague-Dawley,Reaction Time,Reaction Time: physiology,Reward},
number = {4},
pages = {648--61},
pmid = {18760700},
title = {{Basolateral amygdala neurons facilitate reward-seeking behavior by exciting nucleus accumbens neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18760700},
volume = {59},
year = {2008}
}
@article{Strait2016,
abstract = {When we evaluate an option, how is our representation of its value bound to the 30 option's identity? We examined neuronal activity in four key reward regions of the brain: 31 orbitofrontal cortex (OFC), ventromedial prefrontal cortex (vmPFC), ventral striatum (VS), 32 and dorsal anterior cingulate cortex (dACC), in several two-option gambling tasks with 33 lateralized and asynchronous presentation of offers. We found that neuronal responses in all 34 areas are sensitive to the spatial positions of both offers and of choices. This selectivity is 35 strongest in reward-sensitive neurons, indicating that it is not a property of a specialized 36 subpopulation. We did not find any anatomical organization to these responses, suggesting 37 that they may be difficult to detect with aggregate measures like neuroimaging and lesion 38 studies. These results suggest that value coding is linked to object identity and suggest a 39},
author = {Strait, Caleb E and Sleezer, Brianna J and Blanchard, Tommy C and Azab, Habiba and Castagno, Meghan D and Hayden, Benjamin Y},
doi = {10.1152/jn.00325.2015},
isbn = {1522-1598(Electronic);0022-3077(Print)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {binding,decision making,prefrontal cortex,spatial tuning,value comparison},
month = {mar},
number = {3},
pages = {1098--1111},
pmid = {26631146},
publisher = {American Physiological Society Bethesda, MD},
title = {{Neuronal selectivity for spatial positions of offers and choices in five reward regions}},
url = {http://jn.physiology.org/lookup/doi/10.1152/jn.00325.2015},
volume = {115},
year = {2016}
}
@article{Bissonette2013,
abstract = {Neurons in the ventral striatum (VS) fire to cues that predict differently valued rewards. It is unclear whether this activity represents the value associated with the expected reward or the level of motivation induced by reward anticipation. To distinguish between the two, we trained rats on a task in which we varied value independently from motivation by manipulating the size of the reward expected on correct trials and the threat of punishment expected upon errors. We found that separate populations of neurons in VS encode expected value and motivation.},
author = {Bissonette, Gregory B and Burton, Amanda C and Gentry, Ronny N and Goldstein, Brandon L and Hearn, Taylor N and Barnett, Brian R and Kashtelyan, Vadim and Roesch, Matthew R},
doi = {10.1371/journal.pone.0064673},
editor = {Zhuang, Xiaoxi},
isbn = {1932-6203 (Electronic){\$}\backslash{\$}r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
month = {may},
number = {5},
pages = {e64673},
pmid = {23724077},
publisher = {Public Library of Science},
title = {{Separate Populations of Neurons in Ventral Striatum Encode Value and Motivation}},
url = {http://dx.plos.org/10.1371/journal.pone.0064673},
volume = {8},
year = {2013}
}
@article{Bowman1996a,
author = {Bowman, E. M. and Aigner, T. G. and Richmond, B. J.},
journal = {J Neurophysiol},
number = {3},
pages = {1061--1073},
title = {{Neural signals in the monkey ventral striatum related to motivation for juice and cocaine rewards}},
url = {http://jn.physiology.org/cgi/content/abstract/75/3/1061},
volume = {75},
year = {1996}
}
@article{Goto2008,
abstract = {The nucleus accumbens regulates goal-directed behaviors by integrating information from limbic structures and the prefrontal cortex. Here, we review recent studies in an attempt to provide an integrated view of the control of information processing in the nucleus accumbens in terms of the regulation of goal-directed behaviors and how disruption of these functions might underlie the pathological states in drug addiction and other psychiatric disorders. We propose a model that could account for the results of several studies investigating limbic-system interactions in the nucleus accumbens and their modulation by dopamine and provide testable hypotheses for how these might relate to the pathophysiology of major psychiatric disorders.},
author = {Goto, Yukiori and Grace, Anthony A},
doi = {10.1016/j.tins.2008.08.002},
file = {::},
issn = {0166-2236},
journal = {Trends in neurosciences},
keywords = {Animals,Cerebral Cortex,Cerebral Cortex: physiology,Humans,Limbic System,Limbic System: physiology,Mental Processes,Mental Processes: physiology,Models, Biological,Neural Pathways,Neural Pathways: physiology,Nucleus Accumbens,Nucleus Accumbens: physiology},
month = {nov},
number = {11},
pages = {552--8},
pmid = {18786735},
title = {{Limbic and cortical information processing in the nucleus accumbens.}},
url = {http://www.sciencedirect.com/science/article/pii/S0166223608001884},
volume = {31},
year = {2008}
}
@article{Robinson2009,
abstract = {Background: If presentation of a stimulus (conditional stimulus, CS) reliably predicts delivery of a reward, the CS will come to evoke a conditional response (CR) through Pavlovian learning, and the CS may also acquire incentive motivational properties. Thus, CSs can have both predictive and incentive properties. We ask here whether it is possible to dissociate the predictive versus incentive properties of a CS in rats by considering individual differences in the nature of the CR. Methods: We used Pavlovian procedures to study the ability of a localizable CS (an illuminated lever) to acquire two properties of an incentive stimulus-the ability to attract and the ability to act as a conditional reinforcer. Results: For some rats, the CS evoked a "sign-tracking" CR, consisting of approach toward and engagement with the CS itself. For other rats, the CS instead produced a "goal-tracking" CR: approach was directed away from the CS toward the site of food delivery. For sign-trackers (but not goal-trackers) the CS also acted as an effective conditional reinforcer. Conclusions: The predictive and incentive properties of a CS can be dissociated by considering individual differences in the CR. In a given animal, a cue that is predictive of reward, supporting Pavlovian learning, may or may not be attributed with incentive salience. This procedure may provide a powerful means to test hypotheses regarding the role of neural systems in learning versus incentive motivational functions and to study individual variation in the extent to which reward-associated stimuli act as incentive stimuli. {\{}{\textcopyright}{\}} 2009 Society of Biological Psychiatry.},
author = {Robinson, Terry E and Flagel, Shelly B},
doi = {10.1016/j.biopsych.2008.09.006},
isbn = {0006-3223},
issn = {00063223},
journal = {Biological Psychiatry},
keywords = {Autoshaping,Pavlovian conditioning,conditional reinforcement,goal-tracking,incentive motivation,incentive salience,learning,sign-tracking},
month = {may},
number = {10},
pages = {869--873},
pmid = {18930184},
title = {{Dissociating the Predictive and Incentive Motivational Properties of Reward-Related Cues Through the Study of Individual Differences}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18930184 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2737368 http://linkinghub.elsevier.com/retrieve/pii/S0006322308010949},
volume = {65},
year = {2009}
}
@article{flagel2011,
author = {Flagel, Shelly B and Clark, Jeremy J and Robinson, Terry E and Mayo, Leah and Czuj, Alayna and Willuhn, Ingo and Akers, Christina A and Clinton, Sarah M and Phillips, Paul E M and Akil, Huda},
doi = {10.1038/nature09588},
journal = {Nature},
number = {7328},
pages = {53--57},
title = {{A selective role for dopamine in stimulus-reward learning}},
volume = {469},
year = {2011}
}
@article{Floresco2008,
abstract = {Reinstatement of previously extinguished instrumental responding for drug-related cues has been used as an animal model for relapse of drug abuse, and is differentially affected by inactivation of the core and shell subregions of the nucleus accumbens (NAc). To compare the roles of these subregions in reinstatement induced by cues associated with natural and drug rewards, the present study assessed the effects of inactivation of the NAc core and shell on cue-induced reinstatement of food-seeking behavior. Rats acquired a lever pressing response for food reward paired with a light/tone conditioned stimulus (CS). They were then subjected to extinction, where both food and the CS were withheld. Reinstatement of responding was measured during response-contingent presentations of the CS. Following saline infusions into the NAc core or shell, rats displayed a significant increase in lever pressing during reinstatement sessions. Inactivation of the core, induced by infusion of GABA agonists muscimol and baclofen, attenuated responding for the CS, but did not affect pavlovian approach toward the food receptacle. In contrast, inactivation of the shell had the opposite effect, potentiating responding relative to vehicle treatments. These data suggest that the NAc core and shell play opposing, yet complementary roles in mediating the influence that food-associated conditioned stimuli exert over behavior. The core enables reward-related stimuli to bias the direction and vigor of instrumental responding. In contrast, the shell facilitates alterations in behavior in response to changes in the incentive value of conditioned stimuli. The fact that the NAc core appears to play a similar role in cue-induced reinstatement induced by both natural and drug rewards suggests that this region of the ventral striatum may be a final common pathway through which both drug- and food-associated stimuli may influence the direction and magnitude of ongoing behavior. {\{}{\textcopyright}{\}} 2008 IBRO.},
author = {Floresco, S B and McLaughlin, R J and Haluk, D M},
doi = {10.1016/j.neuroscience.2008.04.004},
isbn = {0306-4522 (Print){\$}\backslash{\$}r0306-4522 (Linking)},
issn = {03064522},
journal = {Neuroscience},
keywords = {drug addiction,instrumental learning,pavlovian conditioning,rat,relapse},
month = {jun},
number = {3},
pages = {877--884},
pmid = {18479836},
publisher = {Pergamon},
title = {{Opposing roles for the nucleus accumbens core and shell in cue-induced reinstatement of food-seeking behavior}},
url = {https://www.sciencedirect.com/science/article/pii/S0306452208005435},
volume = {154},
year = {2008}
}
@article{Rigotti2013,
abstract = {Nature (2013). doi:10.1038/nature12160},
author = {Rigotti, Mattia and Barak, Omri and Warden, Melissa R and Wang, Xiao Jing and Daw, Nathaniel D and Miller, Earl K and Fusi, Stefano},
doi = {10.1038/nature12160},
isbn = {doi:10.1038/nature12160},
issn = {00280836},
journal = {Nature},
month = {may},
number = {7451},
pages = {585--590},
pmid = {23685452},
publisher = {NIH Public Access},
title = {{The importance of mixed selectivity in complex cognitive tasks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23685452 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4412347},
volume = {497},
year = {2013}
}
@misc{Markou2013,
abstract = {The present review article summarizes and expands upon the discussions that were initiated during a meeting of the Cognitive Neuroscience Treatment Research to Improve Cognition in Schizophrenia (CNTRICS; http://cntrics.ucdavis.edu) meeting. A major goal of the CNTRICS meeting was to identify experimental procedures and measures that can be used in laboratory animals to assess psychological constructs that are related to the psychopathology of schizophrenia. The issues discussed in this review reflect the deliberations of the Motivation Working Group of the CNTRICS meeting, which included most of the authors of this article as well as additional participants. After receiving task nominations from the general research community, this working group was asked to identify experimental procedures in laboratory animals that can assess aspects of reinforcement learning and motivation that may be relevant for research on the negative symptoms of schizophrenia, as well as other disorders characterized by deficits in reinforcement learning and motivation. The tasks described here that assess reinforcement learning are the Autoshaping Task, Probabilistic Reward Learning Tasks, and the Response Bias Probabilistic Reward Task. The tasks described here that assess motivation are Outcome Devaluation and Contingency Degradation Tasks and Effort-Based Tasks. In addition to describing such methods and procedures, the present article provides a working vocabulary for research and theory in this field, as well as an industry perspective about how such tasks may be used in drug discovery. It is hoped that this review can aid investigators who are conducting research in this complex area, promote translational studies by highlighting shared research goals and fostering a common vocabulary across basic and clinical fields, and facilitate the development of medications for the treatment of symptoms mediated by reinforcement learning and motivational deficits. {\textcopyright} 2013 Elsevier Ltd.},
author = {Markou, Athina and Salamone, John D. and Bussey, Timothy J. and Mar, Adam C. and Brunner, Daniela and Gilmour, Gary and Balsam, Peter},
booktitle = {Neuroscience and Biobehavioral Reviews},
doi = {10.1016/j.neubiorev.2013.08.007},
isbn = {1873-7528 (Electronic)$\backslash$r0149-7634 (Linking)},
issn = {01497634},
keywords = {Cognition,Learning,Motivation,Reinforcement,Reward},
month = {nov},
number = {9},
pages = {2149--2165},
pmid = {23994273},
publisher = {Pergamon},
title = {{Measuring reinforcement learning and motivation constructs in experimental animals: Relevance to the negative symptoms of schizophrenia}},
url = {https://www.sciencedirect.com/science/article/pii/S0149763413001978},
volume = {37},
year = {2013}
}
@article{Koya2009,
abstract = {Learned associations between effects of abused drugs and the drug administration environment are important in drug addiction. Histochemical and electrophysiological studies suggest that these associations are encoded in sparsely distributed nucleus accumbens neurons that are selectively activated by drugs and drug-associated cues. Although correlations have been observed between nucleus accumbens neuronal activity and responsivity to drugs and drug cues, no technique exists for selectively manipulating these activated neurons and establishing their causal role in behavioral effects of drugs and drug cues. Here we describe a new approach, which we term the 'Daun02 inactivation method', that selectively inactivates a minority of neurons previously activated by cocaine in an environment repeatedly paired with cocaine to demonstrate a causal role for these activated neurons in context-specific cocaine-induced psychomotor sensitization in rats. This method provides a new tool for studying the causal roles of selectively activated neurons in behavioral effects of drugs and drug cues and in other learned behaviors.},
author = {Koya, Eisuke and Golden, Sam A and Harvey, Brandon K and Guez-Barber, Danielle H and Berkow, Alexander and Simmons, Danielle E and Bossert, Jennifer M and Nair, Sunila G and Uejima, Jamie L and Marin, Marcelo T and Mitchell, Timothy B and Farquhar, David and Ghosh, Sukhen C and Mattson, Brandi J and Hope, Bruce T},
doi = {10.1038/nn.2364},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Behavior, Animal,Behavior, Animal: drug effects,Behavior, Animal: physiology,Cocaine,Cocaine-Related Disorders,Cocaine-Related Disorders: physiopathology,Cocaine: pharmacology,Cues,Daunorubicin,Daunorubicin: toxicity,Disease Models, Animal,Dopamine Uptake Inhibitors,Dopamine Uptake Inhibitors: pharmacology,Learning,Learning: drug effects,Learning: physiology,Male,Neuronal Plasticity,Neuronal Plasticity: drug effects,Neuronal Plasticity: physiology,Neurons,Neurons: drug effects,Neurons: physiology,Neuropharmacology,Neuropharmacology: methods,Neurotoxins,Neurotoxins: toxicity,Nucleus Accumbens,Nucleus Accumbens: drug effects,Nucleus Accumbens: physiology,Psychomotor Performance,Psychomotor Performance: drug effects,Psychomotor Performance: physiology,Rats,Rats, Sprague-Dawley,Rats, Transgenic},
month = {aug},
number = {8},
pages = {1069--73},
pmid = {19620976},
publisher = {Nature Publishing Group},
shorttitle = {Nat Neurosci},
title = {{Targeted disruption of cocaine-activated nucleus accumbens neurons prevents context-specific sensitization.}},
url = {http://dx.doi.org/10.1038/nn.2364},
volume = {12},
year = {2009}
}
@article{Alvarez2016,
abstract = {The study by Calipari et al. in PNAS provides a glimpse into the in vivo pattern of neuronal activation in the mouse nucleus accumbens during the acquisition and expression of learned reward–context associations (1). The nucleus accumbens sits in the ventral part of the mouse striatum, and is required for reward-motivated learning. The activity of neurons in this region is thought to code information on the reward value of cues and contexts. Two distinct subpopulations of striatal neurons can be identified based on their anatomical projections and the degree of expression of dopamine D1 and D2 receptors. Striatal neurons expressing D1 receptors (D1-expressing neurons) have been shown to enhance reward learning, whereas striatal neurons expressing D2 receptors (D2-expressing neurons) have been shown to reduce reward learning when activated via optogenetic stimulation (2, 3). These manipulations, together with decades of experimentation in the field, have led to consensus around a general model in which the outputs of D1-expressing neurons and D2-expressing neurons exert opposing actions on coding of reward value and where the balance of activity between these outputs determines the final state (Fig. 1A). Based on this conceptual framework, predictions can be made about the activity of D1- and D2-expressing neurons during reward learning. However, recording the activity of the striatal neurons in a cell-specific manner has been very difficult. To this end, Calipari et al. (1) introduce the genetically coded calcium indicator GCaMP6 selectively in D1- or D2-expressing neurons of the nucleus accumbens, and use fiber photometry to monitor the calcium signals generated in this cell-specific fashion during the acquisition of condition place preference for cocaine. It is important to stress that although each detected calcium signal is generated by the firing of one or more},
author = {Alvarez, Veronica A},
doi = {10.1073/pnas.1601162113},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {mar},
number = {10},
pages = {2560--2562},
pmid = {26917689},
publisher = {National Academy of Sciences},
title = {{Clues on the coding of reward cues by the nucleus accumbens}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1601162113},
volume = {113},
year = {2016}
}
@article{Brown1968,
abstract = {Reliable acquisition of the pigeon's key-peck response resulted from repeated unconditional (response-independent) presentations of food after the response key was illuminated momentarily. Comparison groups showed that acquisition was dependent upon light-food pairings, in that order.},
author = {Brown, P L and Jenkins, H M},
doi = {10.1901/jeab.1968.11-1},
isbn = {0022-5002 (Print){\$}\backslash{\$}r0022-5002 (Linking)},
issn = {0022-5002},
journal = {Journal of the experimental analysis of behavior},
month = {jan},
number = {1},
pages = {1--8},
pmid = {5636851},
publisher = {Blackwell Publishing Ltd},
title = {{Auto-shaping of the pigeon's key-peck.}},
url = {http://www.pubmedcentral.gov/articlerender.fcgi?artid=1338436},
volume = {11},
year = {1968}
}
@article{Hamid2015,
abstract = {Dopamine cell firing can encode errors in reward prediction, providing a learning signal to guide future behavior. Yet dopamine is also a key modulator of motivation, invigorating current behavior. Existing theories propose that fast (phasic) dopamine fluctuations support learning, whereas much slower (tonic) dopamine changes are involved in motivation. We examined dopamine release in the nucleus accumbens across multiple time scales, using complementary microdialysis and voltammetric methods during adaptive decision-making. We found that minute-by-minute dopamine levels covaried with reward rate and motivational vigor. Second-by-second dopamine release encoded an estimate of temporally discounted future reward (a value function). Changing dopamine immediately altered willingness to work and reinforced preceding action choices by encoding temporal-difference reward prediction errors. Our results indicate that dopamine conveys a single, rapidly evolving decision variable, the available reward for investment of effort, which is employed for both learning and motivational functions.},
author = {Hamid, Arif A and Pettibone, Jeffrey R and Mabrouk, Omar S and Hetrick, Vaughn L and Schmidt, Robert and {Vander Weele}, Caitlin M and Kennedy, Robert T and Aragona, Brandon J and Berke, Joshua D},
doi = {10.1038/nn.4173},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {1},
pages = {117--126},
pmid = {26595651},
title = {{Mesolimbic dopamine signals the value of work}},
url = {http://dx.doi.org/10.1038/nn.4173},
volume = {19},
year = {2015}
}
@article{Wassum2009,
abstract = {It generally is assumed that a common neural substrate mediates both the palatability and the reward value of nutritive events. However, recent evidence suggests this assumption may not be true. Whereas opioid circuitry in both the nucleus accumbens and ventral pallidum has been reported to mediate taste-reactivity responses to palatable events, the assignment of reward or inventive value to goal-directed actions has been found to involve the basolateral amygdala. Here we found that, in rats, the neural processes mediating palatability and incentive value are indeed dissociable. Naloxone infused into either the ventral pallidum or nucleus accumbens shell blocked the increase in sucrose palatability induced by an increase in food deprivation without affecting the performance of sucrose-related actions. Conversely, naloxone infused into the basolateral amygdala blocked food deprivation-induced changes in sucrose-related actions without affecting sucrose palatability. This double dissociation of opioid-mediated changes in palatability and incentive value suggests that the role of endogenous opioids in reward processing does not depend on a single neural circuit. Rather, changes in palatability and in the incentive value assigned to rewarding events seem to be mediated by distinct neural processes.},
author = {Wassum, K M and Ostlund, S B and Maidment, N T and Balleine, B W},
doi = {10.1073/pnas.0905874106},
isbn = {1091-6490 (Electronic){\$}\backslash{\$}n0027-8424 (Linking)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {jul},
number = {30},
pages = {12512--12517},
pmid = {19597155},
publisher = {National Academy of Sciences},
title = {{Distinct opioid circuits determine the palatability and the desirability of rewarding events.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19597155{\%}7B{\%}25{\%}7D5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2718390},
volume = {106},
year = {2009}
}
@article{Peters2008,
abstract = {The rat prelimbic prefrontal cortex and nucleus accumbens core are critical for initiating cocaine seeking. In contrast, the neural circuitry responsible for inhibiting cocaine seeking during extinction is unknown. The present findings using inhibition of selected brain nuclei with GABA agonists show that the suppression of cocaine seeking produced by previous extinction training required activity in the rat infralimbic cortex. Conversely, the reinstatement of drug seeking by a cocaine injection in extinguished animals was suppressed by increasing neuronal activity in infralimbic cortex with the glutamate agonist AMPA. The cocaine seeking induced by inactivating infralimbic cortex resembled other forms of reinstated drug seeking by depending on activity in prelimbic cortex and the basolateral amygdala. A primary efferent projection from the infralimbic cortex is to the nucleus accumbens shell. Akin to infralimbic cortex, inhibition of the accumbens shell induced cocaine seeking in extinguished rats. However, bilateral inhibition of the shell also elicited increased locomotor activity. Nonetheless, unilateral inhibition of the accumbens shell did not increase motor activity, and simultaneous unilateral inactivation of the infralimbic cortex and shell induced cocaine seeking, suggesting that an interaction between these two structures is necessary for extinction training to inhibit cocaine seeking. The infralimbic cortex and accumbens shell appear to be recruited by extinction learning because inactivation of these structures before extinction training did not alter cocaine seeking. Together, these findings suggest that a neuronal network involving the infralimbic cortex and accumbens shell is recruited by extinction training to suppress cocaine seeking.},
author = {Peters, J and LaLumiere, R T and Kalivas, P W},
doi = {10.1523/JNEUROSCI.1045-08.2008},
isbn = {1529-2401 (Electronic){\$}\backslash{\$}n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jun},
number = {23},
pages = {6046--6053},
pmid = {18524910},
publisher = {Society for Neuroscience},
title = {{Infralimbic Prefrontal Cortex Is Responsible for Inhibiting Cocaine Seeking in Extinguished Rats}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1045-08.2008},
volume = {28},
year = {2008}
}
@article{Joel2002,
abstract = {A large number of computational models of information processing in the basal ganglia have been developed in recent years. Prominent in these are actor-critic models of basal ganglia functioning, which build on the strong resemblance between dopamine neuron activity and the temporal difference prediction error signal in the critic, and between dopamine-dependent long-term synaptic plasticity in the striatum and learning guided by a prediction error signal in the actor. We selectively review several actor-critic models of the basal ganglia with an emphasis on two important aspects: the way in which models of the critic reproduce the temporal dynamics of dopamine firing, and the extent to which models of the actor take into account known basal ganglia anatomy and physiology. To complement the efforts to relate basal ganglia mechanisms to reinforcement learning (RL), we introduce an alternative approach to modeling a critic network, which uses Evolutionary Computation techniques to 'evolve' an optimal RL mechanism, and relate the evolved mechanism to the basic model of the critic. We conclude our discussion of models of the critic by a critical discussion of the anatomical plausibility of implementations of a critic in basal ganglia circuitry, and conclude that such implementations build on assumptions that are inconsistent with the known anatomy of the basal ganglia. We return to the actor component of the actor-critic model, which is usually modeled at the striatal level with very little detail. We describe an alternative model of the basal ganglia which takes into account several important, and previously neglected, anatomical and physiological characteristics of basal ganglia-thalamocortical connectivity and suggests that the basal ganglia performs reinforcement-biased dimensionality reduction of cortical inputs. We further suggest that since such selective encoding may bias the representation at the level of the frontal cortex towards the selection of rewarded plans and actions, the reinforcement-driven dimensionality reduction framework may serve as a basis for basal ganglia actor models. We conclude with a short discussion of the dual role of the dopamine signal in RL and in behavioral switching.},
author = {Joel, Daphna and Niv, Yael and Ruppin, Eytan},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {Animals,Basal Ganglia,Basal Ganglia: anatomy {\&} histology,Basal Ganglia: physiology,Biological,Humans,Learning,Learning: physiology,Models,Nerve Net,Nerve Net: physiology},
number = {4-6},
pages = {535--47},
pmid = {12371510},
title = {{Actor-critic models of the basal ganglia: new anatomical and computational perspectives.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12371510},
volume = {15},
year = {2002}
}
@article{Hart2014,
abstract = {Making predictions about the rewards associated with environmental stimuli and updating those predictions through feedback is an essential aspect of adaptive behavior. Theorists have argued that dopamine encodes a reward prediction error (RPE) signal that is used in such a reinforcement learning process. Recent work with fMRI has demonstrated that the BOLD signal in dopaminergic target areas meets both necessary and sufficient conditions of an axiomatic model of the RPE hypothesis. However, there has been no direct evidence that dopamine release itself also meets necessary and sufficient criteria for encoding an RPE signal. Further, the fact that dopamine neurons have low tonic firing rates that yield a limited dynamic range for encoding negative RPEs has led to significant debate about whether positive and negative prediction errors are encoded on a similar scale. To address both of these issues, we used fast-scan cyclic voltammetry to measure reward-evoked dopamine release at carbon fiber electrodes chronically implanted in the nucleus accumbens core of rats trained on a probabilistic decision-making task. We demonstrate that dopamine concentrations transmit a bidirectional RPE signal with symmetrical encoding of positive and negative RPEs. Our findings strengthen the case that changes in dopamine concentration alone are sufficient to encode the full range of RPEs necessary for reinforcement learning.},
author = {Hart, Andrew S and Rutledge, Robb B and Glimcher, Paul W and Phillips, Paul E M},
doi = {10.1523/JNEUROSCI.2489-13.2014},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {jan},
number = {3},
pages = {698--704},
pmid = {24431428},
title = {{Phasic dopamine release in the rat nucleus accumbens symmetrically encodes a reward prediction error term.}},
url = {http://www.jneurosci.org/content/34/3/698.short?rss=1},
volume = {34},
year = {2014}
}
@article{Carelli2004,
abstract = {An understanding of the neurobiological basis of drug addiction requires examination of real-time (subsecond) cellular and chemical responses in the brain reward system during drug-seeking and drug-taking behavior. Electrophysiological and electrochemical studies in the rodent nucleus accumbens have examined changes in cell firing and rapid dopamine signaling during crucial periods of behavioral responding for drugs, and show the associative nature of those signals. These findings are considered with respect to the functional microcircuitry in the nucleus accumbens that underlies goal-directed behavior and the role of this circuit in drug addiction.},
author = {Carelli, Regina M and Wightman, R Mark},
doi = {10.1016/j.conb.2004.10.001},
isbn = {0959-4388 (Print){\$}\backslash{\$}n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {dec},
number = {6},
pages = {763--768},
pmid = {15582381},
publisher = {Elsevier Current Trends},
title = {{Functional microcircuitry in the accumbens underlying drug addiction: Insights from real-time signaling during behavior}},
url = {http://www.sciencedirect.com/science/article/pii/S0959438804001539},
volume = {14},
year = {2004}
}
@article{Schultz2015,
abstract = {Rewards are crucial objects that induce learning, approach behavior, choices, and emotions. Whereas emotions are difficult to investigate in animals, the learning function is mediated by neuronal reward prediction error signals which implement basic constructs of reinforcement learning theory. These signals are found in dopamine neurons, which emit a global reward signal to striatum and frontal cortex, and in specific neurons in striatum, amygdala, and frontal cortex projecting to select neuronal populations. The approach and choice functions involve subjective value, which is objectively assessed by behavioral choices eliciting internal, subjective reward preferences. Utility is the formal mathematical characterization of subjective value and a prime decision variable in economic choice theory. It is coded as utility prediction error by phasic dopamine responses. Utility can incorporate various influences, including risk, delay, effort, and social interaction. Appropriate for formal decision mechanisms, rewards are coded as object value, action value, difference value, and chosen value by specific neurons. Although all reward, reinforcement, and decision variables are theoretical constructs, their neuronal signals constitute measurable physical implementations and as such confirm the validity of these concepts. The neuronal reward signals provide guidance for behavior while constraining the free will to act.},
author = {Schultz, Wolfram},
doi = {10.1152/physrev.00023.2014},
isbn = {0031-9333},
issn = {0031-9333},
journal = {Physiological Reviews},
month = {jul},
number = {3},
pages = {853--951},
pmid = {26109341},
title = {{Neuronal Reward and Decision Signals: From Theories to Data}},
url = {http://physrev.physiology.org/lookup/doi/10.1152/physrev.00023.2014},
volume = {95},
year = {2015}
}
@book{atlas,
address = {San Diego},
author = {Paxinos, G and Watson, C},
edition = {4},
publisher = {Academic Press},
title = {{The Rat Brain in Stereotaxic Coordinates}},
year = {1998}
}
@article{Setlow2003,
abstract = {A growing body of evidence implicates the ventral striatum in using
information acquired through associative learning. The present study
examined the activity of ventral striatal neurons in awake, behaving
rats during go/no-go odor discrimination learning and reversal. Many
neurons fired selectively to odor cues predictive of either appetitive
(sucrose) or aversive (quinine) outcomes. Few neurons were selective
when first exposed to the odors, but many acquired this differential
activity as rats learned the significance of the cues. A substantial
proportion of these neurons encoded the cues' learned motivational
significance, and these neurons tended to reverse their firing selectivity
after reversal of odor-outcome contingencies. Other neurons that
became selectively activated during learning did not reverse, but
instead appeared to encode specific combinations of cues and associated
motor responses. The results support a role for ventral striatum
in using the learned significance, both appetitive and aversive,
of predictive cues to guide behavior.},
author = {Setlow, Barry and Schoenbaum, Geoffrey and Gallagher, Michela},
journal = {Neuron},
keywords = {Action Potentials; Animals; Avoidance Learning; Ba,Animal; Conditioning (Psychology); Discrimination,Long-Evans; Reward; Smell; Sucrose; Taste},
month = {may},
number = {4},
pages = {625--636},
pmid = {12765613},
title = {{Neural encoding in ventral striatum during olfactory discrimination learning.}},
volume = {38},
year = {2003}
}
@article{Schultz1997,
author = {Schultz, W and Dayan, P and Montague, P R},
journal = {Science},
pages = {1593­1599},
title = {{A neural substrate of prediction and reward}},
volume = {275},
year = {1997}
}
@article{Saunders2012,
abstract = {The role of dopamine in reward is a topic of debate. For example, some have argued that phasic dopamine signaling provides a prediction-error signal necessary for stimulus-reward learning, whereas others have hypothesized that dopamine is not necessary for learning per se, but for attributing incentive motivational value ('incentive salience') to reward cues. These psychological processes are difficult to tease apart, because they tend to change together. To disentangle them we took advantage of natural individual variation in the extent to which reward cues are attributed with incentive salience, and asked whether dopamine (specifically in the core of the nucleus accumbens) is necessary for the expression of two forms of pavlovian-conditioned approach behavior--one in which the cue acquires powerful motivational properties (sign-tracking) and another closely related one in which it does not (goal-tracking). After acquisition of these conditioned responses (CRs), intra-accumbens injection of the dopamine receptor antagonist flupenthixol markedly impaired the expression of a sign-tracking CR, but not a goal-tracking CR. Furthermore, dopamine antagonism did not produce a gradual extinction-like decline in behavior, but maximally impaired expression of a sign-tracking CR on the very first trial, indicating the effect was not due to new learning (i.e. it occurred in the absence of new prediction-error computations). The data support the view that dopamine in the accumbens core is not necessary for learning stimulus-reward associations, but for attributing incentive salience to reward cues, transforming predictive conditional stimuli into incentive stimuli with powerful motivational properties.},
author = {Saunders, Benjamin T and Robinson, Terry E},
doi = {10.1111/j.1460-9568.2012.08217.x},
isbn = {1460-9568 (Electronic) 0953-816X (Linking)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Goal-tracking,Learning,Motivation,Rat,Sign-tracking},
month = {aug},
number = {4},
pages = {2521--2532},
pmid = {22780554},
publisher = {NIH Public Access},
title = {{The role of dopamine in the accumbens core in the expression of pavlovian-conditioned responses}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22780554 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3424374},
volume = {36},
year = {2012}
}
@article{Lee2012,
abstract = {Reinforcement learning is an adaptive process in which an animal utilizes its previous experience to improve the outcomes of future choices. Computational theories of reinforcement learning play a central role in the newly emerging areas of neuroeconomics and decision neuroscience. In this framework, actions are chosen according to their value functions, which describe how much future reward is expected from each action. Value functions can be adjusted not only through reward and penalty, but also by the animal's knowledge of its current environment. Studies have revealed that a large proportion of the brain is involved in representing and updating value functions and using them to choose an action. However, how the nature of a behavioral task affects the neural mechanisms of reinforcement learning remains incompletely understood. Future studies should uncover the principles by which different computational elements of reinforcement learning are dynamically coordinated across the entire brain.},
author = {Lee, Daeyeol and Seo, Hyojung and Jung, Min Whan},
doi = {10.1146/annurev-neuro-062111-150512},
isbn = {0147-006X},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {neuroeconomics,prefrontal cortex,reward,striatum,uncertainty},
number = {1},
pages = {287--308},
pmid = {22462543},
title = {{Neural Basis of Reinforcement Learning and Decision Making}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-062111-150512},
volume = {35},
year = {2012}
}
@article{Atallah2014,
abstract = {The ventromedial striatum (VMS) is a node in circuits underpinning both affect and reinforcement learning. The cellular bases of these functions and especially their potential linkages have been unclear. VMS cholinergic interneurons, however, have been singled out as being related both to affect and to reinforcement-based conditioning, raising the possibility that unique aspects of their signaling could account for these functions. Here we show that VMS tonically active neurons (TANs), including putative cholinergic interneurons, generate unique bidirectional outcome responses during reward-based learning, reporting both positive (reward) and negative (reward omission) outcomes when behavioral change is prompted by switches in reinforcement contingencies. VMS output neurons (SPNs), by contrast, are nearly insensitive to switches in reinforcement contingencies, gradually losing outcome signaling while maintaining responses at trial initiation and goal approach. Thus, TANs and SPNs in the VMS provide distinct signals optimized for different aspects of the learning process. •Plasticity in ventromedial striatum during reward learning is cell-type specific•Cholinergic interneurons signal outcome and track reinforcement contingencies•Spiny projection neurons (SPNs) lose outcome responses during learning•SPNs maintain responses at trial initiation and goal approach during learning. Atallah etal. demonstrate that in the ventromedial striatum, a region related to emotion, special sets of neurons signal the success or failure of behaviors as animals learn. After learning, this signal subsides, suggesting that it is a true learning signal. {\{}{\textcopyright}{\}} 2014 Elsevier Inc.},
author = {Atallah, Hisham E and McCool, Andrew D and Howe, Mark W and Graybiel, Ann M},
doi = {10.1016/j.neuron.2014.04.021},
isbn = {1097-4199 (Electronic){\$}\backslash{\$}n0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
month = {jun},
number = {5},
pages = {1145--1156},
pmid = {24908491},
publisher = {Cell Press},
title = {{Neurons in the ventral striatum exhibit cell-type-specific representations of outcome during learning}},
url = {https://www.sciencedirect.com/science/article/pii/S0896627314003353},
volume = {82},
year = {2014}
}
@article{Sjulson2017,
abstract = {Conditioned place preference (CPP) is a widely used model of addiction-related behavior whose underlying mechanism is not understood. In this study, we used dual site silicon probe recordings in freely moving mice to examine interactions between the hippocampus and nucleus accumbens in cocaine CPP. We found that CPP was associated with recruitment of nucleus accumbens medium spiny neurons to fire in the cocaine-paired location, and this recruitment was driven predominantly by selective strengthening of hippocampal inputs arising from place cells that encode the cocaine-paired location. These findings provide in vivo evidence that the synaptic potentiation in the accumbens caused by repeated cocaine administration preferentially affects inputs that were active at the time of drug exposure. This provides a potential physiological mechanism by which drug use becomes associated with specific environmental contexts.},
author = {Sjulson, Lucas and Peyrache, Adrien and Cumpelik, Andrea and Cassataro, Daniela and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.1101/105890},
journal = {bioRxiv},
month = {may},
pages = {105890},
publisher = {Cold Spring Harbor Laboratory},
title = {{Cocaine place conditioning strengthens location-specific hippocampal inputs to the nucleus accumbens}},
url = {https://www.biorxiv.org/content/early/2017/05/12/105890},
year = {2017}
}
@article{carelli94,
author = {Carelli, R M and Deadwyler, S A},
journal = {Journal of Neuroscience},
number = {12},
pages = {7735--7746},
title = {{A comparison of nucleus accumbens neuronal firing patterns during cocaine self-administration and water reinforcement in rats}},
volume = {14},
year = {1994}
}
@article{McDannald2011,
abstract = {In many cases, learning is thought to be driven by differences between the value of rewards we expect and rewards we actually receive. Yet learning can also occur when the identity of the reward we receive is not as expected, even if its value remains unchanged. Learning from changes in reward identity implies access to an internal model of the environment, from which information about the identity of the expected reward can be derived. As a result, such learning is not easily accounted for by model-free reinforcement learning theories such as temporal difference reinforcement learning (TDRL), which predicate learning on changes in reward value, but not identity. Here, we used unblocking procedures to assess learning driven by value- versus identity-based prediction errors. Rats were trained to associate distinct visual cues with different food quantities and identities. These cues were subsequently presented in compound with novel auditory cues and the reward quantity or identity was selectively changed. Unblocking was assessed by presenting the auditory cues alone in a probe test. Consistent with neural implementations of TDRL models, we found that the ventral striatum was necessary for learning in response to changes in reward value. However, this area, along with orbitofrontal cortex, was also required for learning driven by changes in reward identity. This observation requires that existing models of TDRL in the ventral striatum be modified to include information about the specific features of expected outcomes derived from model-based representations, and that the role of orbitofrontal cortex in these models be clearly delineated.},
author = {McDannald, Michael A and Lucantonio, Federica and Burke, Kathryn A and Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1523/JNEUROSCI.5499-10.2011},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Analysis of Variance,Animals,Association Learning,Association Learning: physiology,Basal Ganglia,Basal Ganglia: injuries,Basal Ganglia: physiology,Cues,Male,Prefrontal Cortex,Prefrontal Cortex: injuries,Prefrontal Cortex: physiology,Rats,Rats, Long-Evans,Reinforcement (Psychology),Statistics, Nonparametric},
month = {feb},
number = {7},
pages = {2700--5},
pmid = {21325538},
title = {{Ventral striatum and orbitofrontal cortex are both required for model-based, but not model-free, reinforcement learning.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3079289{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {31},
year = {2011}
}
@article{Aggarwal2012a,
abstract = {In the past few decades there has been remarkable convergence of machine learning with neurobiological understanding of reinforcement learning mechanisms, exemplified by temporal difference (TD) learning models. The anatomy of the basal ganglia provides a number of potential substrates for instantiation of the TD mechanism. In contrast to the traditional concept of direct and indirect pathway outputs from the striatum, we emphasize that projection neurons of the striatum are branched and individual striatofugal neurons innervate both globus pallidus externa and globus pallidus interna/substantia nigra (GPi/SNr). This suggests that the GPi/SNr has the necessary inputs to operate as the source of a TD signal. We also discuss the mechanism for the timing processes necessary for learning in the TD framework. The TD framework has been particularly successful in analysing electrophysiogical recordings from dopamine (DA) neurons during learning, in terms of reward prediction error. However, present understanding of the neural control of DA release is limited, and hence the neural mechanisms involved are incompletely understood. Inhibition is very conspicuously present among the inputs to the DA neurons, with inhibitory synapses accounting for the majority of synapses on DA neurons. Furthermore, synchronous firing of the DA neuron population requires disinhibition and excitation to occur together in a coordinated manner. We conclude that the inhibitory circuits impinging directly or indirectly on the DA neurons play a central role in the control of DA neuron activity and further investigation of these circuits may provide important insight into the biological mechanisms of reinforcement learning.},
author = {Aggarwal, Mayank and Hyland, Brian I and Wickens, Jeffery R},
doi = {10.1111/j.1460-9568.2012.08055.x},
isbn = {1460-9568},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Basal ganglia,GABA,Striatum,Temporal difference},
number = {7},
pages = {1115--1123},
pmid = {22487041},
title = {{Neural control of dopamine neurotransmission: Implications for reinforcement learning}},
url = {https://s3.amazonaws.com/objects.readcube.com/articles/downloaded/wiley/f1b7d51b5e40ce16bb3a504630a2333c8920fdfbbb477143fd37672b602018d2.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256{\%}7B{\&}{\%}7DX-Amz-Credential=AKIAIS5LBPCM5JPOCDGQ{\%}7B{\%}25{\%}7D2F20170321{\%}7B{\%}25{\%}7D2Fus-east-1{\%}7B{\%}25{\%}7D2Fs3{\%}7B{\%}25{\%}7D2Faws4{\%}7B{\_}{\%}7Drequest{\%}7B{\&}{\%}7D},
volume = {35},
year = {2012}
}
@article{nicola04a,
author = {Nicola, Saleem M and Yun, Irene A and Wakabayashi, Ken T and Fields, Howard L},
journal = {Journal of Neurophysiology},
number = {4},
pages = {1840--1865},
title = {{Cue-Evoked Firing of Nucleus Accumbens Neurons Encodes Motivational Significance During a Discriminative Stimulus Task}},
volume = {91},
year = {2004}
}
@article{Frank2004,
abstract = {To what extent do we learn from the positive versus negative outcomes of our decisions? The neuromodulator dopamine plays a key role in these reinforcement learning processes. Patients with Parkinson's disease, who have depleted dopamine in the basal ganglia, are impaired in tasks that require learning from trial and error. Here, we show, using two cognitive procedural learning tasks, that Parkinson's patients off medication are better at learning to avoid choices that lead to negative outcomes than they are at learning from positive outcomes. Dopamine medication reverses this bias, making patients more sensitive to positive than negative outcomes. This pattern was predicted by our biologically based computational model of basal ganglia-dopamine interactions in cognition, which has separate pathways for "Go" and "NoGo" responses that are differentially modulated by positive and negative reinforcement.},
author = {Frank, Michael J and Seeberger, Lauren C and O'Reilly, Randall C},
doi = {10.1126/science.1102941},
isbn = {1095-9203 (Electronic){\$}\backslash{\$}n0036-8075 (Linking)},
issn = {00368075},
journal = {Science},
month = {dec},
number = {5703},
pages = {1940--1943},
pmid = {15528409},
title = {{By carrot or by stick: Cognitive reinforcement learning in Parkinsonism}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15528409 http://www.sciencemag.org/cgi/doi/10.1126/science.1102941},
volume = {306},
year = {2004}
}
@article{Kaczkurkin2015,
abstract = {A review of the literature demonstrates a lack of research on fear-generalization processes in many anxiety disorders including obsessive-compulsive disorder (OCD) and posttraumatic stress disorder (PTSD). Chapter 2 represents the first study that attempted to investigate the generalization of conditioned fear in individuals with obsessive-compulsive traits using startle EMG and behavioral measures. The results of this study demonstrated that individuals with high levels of Threat Estimation as measured by the Obsessive Beliefs Questionnaire (OBQ-44) displayed overgeneralization of fear responses to a greater range of stimuli resembling the danger cue than those with low levels of Threat Estimation. In addition, despite etiological theories proposing that fear conditioning and overgeneralization of fear play prominent roles in the development and maintenance of PTSD, little research had been done on the neurobiological mechanisms that contribute to fear conditioning processes in PTSD patients and none have been specifically conducted on generalization. Chapter 3 investigated the neurobiological substrates associated with the overgeneralization of conditioned fear in PTSD patients using behavioral, skin conductance, and functional magnetic resonance imaging (fMRI) measures. This study provides evidence that PTSD patients demonstrate overgeneralization of conditioned fear in the dorsal medial prefrontal cortex, bilateral insula, left and right caudate, left inferior parietal lobule, and right superior frontal gyrus. This body of work provides novel evidence regarding the generalization of conditioned fear in OCD and PTSD. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
author = {Kaczkurkin, Antonia},
isbn = {0419-4217(Print)},
journal = {Dissertation Abstracts International: Section B: The Sciences and Engineering},
number = {3-B(E)},
pages = {No Pagination Specified},
title = {{The contribution of fear conditioning to pathological anxiety: An investigation of conditioned fear generalization in ocd traits and ptsd}},
url = {https://conservancy.umn.edu/bitstream/handle/11299/167172/Kaczkurkin{\%}7B{\_}{\%}7Dumn{\%}7B{\_}{\%}7D0130E{\%}7B{\_}{\%}7D14221.pdf?sequence=1{\%}7B{\&}{\%}7DisAllowed=y http://ovidsp.ovid.com/ovidweb.cgi?T=JS{\%}7B{\&}{\%}7DCSC=Y{\%}7B{\&}{\%}7DNEWS=N{\%}7B{\&}{\%}7DPAGE=fulltext{\%}7B{\&}{\%}7DD=psyc12{\%}7B{\&}{\%}7DAN=2015-99180-249{\%}7B{\%}25{\%}7D0Ahttp://zp2yn2et6f.search.serialssolutions.com/?},
volume = {76},
year = {2015}
}
@article{Durstewitz2010,
abstract = {One of the most intriguing aspects of adaptive behavior involves the inference of regularities and rules in ever-changing environments. Rules are often deduced through evidence-based learning which relies on the prefrontal cortex (PFC). This is a highly dynamic process, evolving trial by trial and therefore may not be adequately captured by averaging single-unit responses over numerous repetitions. Here, we employed advanced statistical techniques to visualize the trajectories of ensembles of simultaneously recorded medial PFC neurons on a trial-by-trial basis as rats deduced a novel rule in a set-shifting task. Neural populations formed clearly distinct and lasting representations of familiar and novel rules by entering unique network states. During rule acquisition, the recorded ensembles often exhibited abrupt transitions, rather than evolving continuously, in tight temporal relation to behavioral performance shifts. These results support the idea that rule learning is an evidence-based decision process, perhaps accompanied by moments of sudden insight.},
author = {Durstewitz, Daniel and Vittoz, Nicole M. and Floresco, Stan B. and Seamans, Jeremy K.},
doi = {10.1016/j.neuron.2010.03.029},
issn = {08966273},
journal = {Neuron},
keywords = {Animals,Behavior, Animal,Behavior, Animal: physiology,Choice Behavior,Choice Behavior: physiology,Cues,Discrimination Learning,Discrimination Learning: physiology,Electrodes, Implanted,Electrophysiology,Male,Nerve Net,Nerve Net: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Prefrontal Cortex,Prefrontal Cortex: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Rats,Rats, Long-Evans,Reaction Time,Reaction Time: physiology,Space Perception,Space Perception: physiology},
month = {may},
number = {3},
pages = {438--448},
pmid = {20471356},
title = {{Abrupt Transitions between Prefrontal Neural Ensemble States Accompany Behavioral Transitions during Rule Learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20471356},
volume = {66},
year = {2010}
}
@article{Aitken2016,
abstract = {Environmental reward-predictive stimuli provide a major source of motivation for instrumental reward-seeking activity and this has been linked to dopamine signaling in the nucleus accumbens (NAc) core. This cue-induced incentive motivation can be quite general, not restricted to instrumental actions that earn the same unique reward, and is also typically regulated by one's current need state, such that cues only motivate actions when this is adaptive. But it remains unknown whether cue-evoked dopamine signaling is similarly regulated by need state. Here, we used fast-scan cyclic voltammetry to monitor dopamine concentration changes in the NAc core of rats during a Pavlovian-to-instrumental transfer task in which the motivating influence of two cues, each signaling a distinct food reward (sucrose or food pellets), over an action earning a third unique food reward (polycose) was assessed in a state of hunger and of satiety. Both cues elicited a robust NAc dopamine response when hungry. The magnitude of the sucrose cue-evoked dopamine response correlated with the Pavlovian-to-instrumental transfer effect that was selectively induced by this stimulus. Satiety attenuated these cue-evoked dopamine responses and behavioral responding, even though rats had never experienced the specific food rewards in this state. These data demonstrate that cue-evoked NAc core responses are sensitive to current need state, one critical variable that determines the current adaptive utility of cue-motivated behavior. Food-predictive stimuli motivate food-seeking behavior. Here, we show that food cues evoke a robust nucleus accumbens core dopamine response when hungry that correlates with the cue's ability to invigorate general food seeking. This response is attenuated when sated, demonstrating that food cue-evoked accumbens dopamine responses are sensitive to the need state information that determines the current adaptive utility of cue-motivated action.},
author = {Aitken, Tara J and Greenfield, Venuz Y and Wassum, Kate M},
doi = {10.1111/jnc.13494},
issn = {14714159},
journal = {Journal of Neurochemistry},
keywords = {Pavlovian-to-instrumental transfer,hunger,mesolimbic dopamine,reward,satiety,voltammetry},
month = {mar},
number = {5},
pages = {1026--1036},
pmid = {26715366},
title = {{Nucleus accumbens core dopamine signaling tracks the need-based motivational value of food-paired cues}},
url = {http://doi.wiley.com/10.1111/jnc.13494},
volume = {136},
year = {2016}
}
@article{Syed2015,
abstract = {It is widely held that dopamine signaling encodes predictions of future rewards and such predictions are regularly used to drive behavior, but the relationship between these two is poorly defined. We found in rats that nucleus accumbens dopamine following a reward-predicting cue was attenuated unless movement was correctly initiated. Our results indicate that dopamine release in this region is contingent on correct action initiation and not just reward prediction.},
author = {Syed, Emilie C J and Grima, Laura L and Magill, Peter J and Bogacz, Rafal and Brown, Peter and Walton, Mark E},
doi = {10.1038/nn.4187},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1546-1726},
journal = {Nature neuroscience},
number = {December},
pages = {1--6},
pmid = {26642087},
title = {{Action initiation shapes mesolimbic dopamine encoding of future rewards.}},
url = {http://www.nature.com/doifinder/10.1038/nn.4187{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26642087},
volume = {19},
year = {2015}
}
@article{Hall2001,
abstract = {Pavlovian conditioned cues exert a powerful influence on instrumental actions directed towards a common reward, this is known as Pavlovian-to-instrumental transfer (PIT). The nucleus accumbens (NAcc) has been hypothesized to function as an interface between limbic cortical structures required for associative conditioning, like the amygdala, and response mechanisms through which instrumental behaviour can be selected and performed. Here we have used selective excitotoxic lesions to investigate the involvement of subnuclei of the amygdala as well as the core and shell regions of the nucleus accumbens on PIT in rats. Within the amygdala, selective lesions of the central nucleus (CeN), but not of the basolateral nucleus (BLA), abolished the PIT effect. In addition, selective lesions of the NAcc core, but not the NAcc shell, also abolished PIT. None of the lesions impaired the acquisition of Pavlovian food cup approaches or instrumental responding itself. These data demonstrate that the CeN and NAcc core are central components of the neural system mediating the impact of Pavlovian cues on instrumental responding. We suggest that this effect may depend upon the regulation of the dopaminergic innervation of the NAcc core by projections from the CeN to the ventral tegmental area.},
author = {Hall, J and Parkinson, J A and Connor, T M and Dickinson, A and Everitt, B J},
doi = {10.1046/j.0953-816X.2001.01577.x},
isbn = {0953-816X (Print){\$}\backslash{\$}r0953-816X (Linking)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Motivation,Pavlovian conditioning,Pavlovian-to-instrumental transfer,Rat},
month = {may},
number = {10},
pages = {1984--1992},
pmid = {11403692},
publisher = {Blackwell Science Ltd},
title = {{Involvement of the central nucleus of the amygdala and nucleus accumbens core in mediating pavlovian influences on instrumental behaviour}},
url = {http://doi.wiley.com/10.1046/j.0953-816x.2001.01577.x},
volume = {13},
year = {2001}
}
@article{Hauber2000,
abstract = {Expectancy of future reward is an important factor guiding the speed of instrumental behavior. The present study sought to explore whether signals transmitted via the NMDA subtype of glutamate receptors and via dopamine D(2) receptors in the nucleus accumbens (NAc) are critical for the determination of reaction times (RTs) of instrumental responses by the expectancy of future reward. A simple RT task for rats demanding conditioned lever release was used in which the upcoming reward magnitude (5 or 1 pellet) was signaled in advance by discriminative stimuli. In trained rats, RTs of conditioned responses with expectancy of a high reward magnitude were found to be significantly shorter. The shortening of RTs by stimuli predictive of high reward to be obtained was dose-dependently impaired by bilateral intra-NAc infusion of the competitive NMDA antagonist dl-2-amino-5-phosphonovaleric acid (APV) (1, 2, or 10 microg in 0.5 microl/side), but not by infusion of the preferential dopamine D(2) antagonist haloperidol (5 and 12.5 microg in 0.5 microl/side) or by infusion of vehicle (0.5 microl/side). In conclusion, the data reveal that in well trained animals stimulation of intra-NAc NMDA, but not of dopamine D(2), receptors, is critically involved in guiding the speed of instrumental responses according to stimuli predictive of the upcoming reward magnitude.},
author = {Hauber, W and Bohn, I and Giertler, C},
doi = {20/16/6282 [pii]},
isbn = {0270-6474 (Print){\$}\backslash{\$}r0270-6474 (Linking)},
issn = {02706474},
journal = {J Neurosci},
keywords = {*Reward,Animal/drug effects/*physiology,Animals,Behavior,Dopamine D2/drug effects/*metabolism,Male,Motor Activity/drug effects/physiology,N-Methyl-D-Aspartate/drug effects/*metabolism,Neuropsychological Tests,Nucleus Accumbens/cytology/drug effects/*metabolis,Psychomotor Performance/drug effects/*physiology,Rats,Reaction Time/drug effects/physiology,Receptors,Sprague-Dawley},
month = {aug},
number = {16},
pages = {6282--6288},
pmid = {10934279},
publisher = {Society for Neuroscience},
title = {{NMDA, but not dopamine D(2), receptors in the rat nucleus accumbens areinvolved in guidance of instrumental behavior by stimuli predicting reward magnitude}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10934279},
volume = {20},
year = {2000}
}
@inproceedings{Maia2011,
abstract = {Over the last decade and a half, reinforcement learning models have fostered an increasingly sophisticated understanding of the functions of dopamine and cortico-basal ganglia-thalamo-cortical (CBGTC) circuits. More recently, these models, and the insights that they afford, have started to be used to understand important aspects of several psychiatric and neurological disorders that involve disturbances of the dopaminergic system and CBGTC circuits. We review this approach and its existing and potential applications to Parkinson's disease, Tourette's syndrome, attention-deficit/hyperactivity disorder, addiction, schizophrenia and preclinical animal models used to screen new antipsychotic drugs. The approach's proven explanatory and predictive power bodes well for the continued growth of computational psychiatry and computational neurology.},
author = {Maia, Tiago V and Frank, Michael J},
booktitle = {Nature Neuroscience},
doi = {10.1038/nn.2723},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {10976256},
keywords = {Learning algorithms},
month = {feb},
number = {2},
pages = {154--162},
pmid = {21270784},
publisher = {Nature Publishing Group},
title = {{From reinforcement learning models to psychiatric and neurological disorders}},
url = {http://www.nature.com/articles/nn.2723},
volume = {14},
year = {2011}
}
@incollection{Carelli2009,
abstract = {Drug addiction in humans is a chronic disease characterized by compulsive drug intake followed by periods of abstinence and relapse. Electrophysiological recordings in behaving rodents have provided critical information regarding cellular mechanisms underlying this behavior. This approach, combined with the drug self-administration procedure, allows for an analysis of cell firing during key features of drug-seeking behaviors. Here, animal studies that examined the activity of neurons within the brain reward system (particularly the nucleus accumbens, NAc) during drug self-administration are reviewed. These findings reveal important insight into neural mechanisms underlying goal-directed behaviors and how drugs of abuse alter this system and lead to addiction. {\{}{\textcopyright}{\}} 2009 Elsevier Ltd All rights reserved.},
author = {Carelli, R M},
booktitle = {Encyclopedia of Neuroscience},
doi = {10.1016/B978-008045046-9.01546-1},
isbn = {9780080450469},
keywords = {Abstinence,Abuse,Accumbens,Addiction,Alcohol,Behavior,Cocaine,Cortex,Electrophysiology,Heroin,Reinforcement,Reward},
pages = {677--682},
publisher = {Elsevier},
title = {{Drug Addiction: Behavioral Neurophysiology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780080450469015461},
year = {2010}
}
@article{DiCiano2001,
abstract = {Stimuli paired with primary rewards can acquire emotional valence and the ability to elicit automatic, Pavlovian approach responses that have been shown to be mediated by the nucleus accumbens. The present experiment investigated the effects of infusions of glutamatergic or dopaminergic receptor antagonists into the core of the nucleus accumbens on the acquisition and performance of Pavlovian discriminated approach to an appetitive conditioned stimulus. Rats were trained on an autoshaping task in which a conditioned stimulus (CS+; a lever) was inserted into the operant chamber for 10 sec, after which a food pellet was delivered. Presentation of another lever (CS-) was never followed by food. Subjects developed a conditioned response of approaching and contacting the CS+ selectively, although food delivery was not in any way contingent on the animals' response. A triple dissociation in the effects of AP-5, LY293558 [(3SR, 4aRS, 6RS, 8aRS)-6-[2-(iH-tetrazol-5-yl)ethyl]-1,2,3,4,4a,5,6,7,8,8a-decahydroiso-qui noline-3-carboxylic acid], and alpha-flupenthixol infused into the nucleus accumbens core on the acquisition and performance of this conditioned response was observed. The AMPA/kainate receptor antagonist LY293558 disrupted discriminated approach performance but not acquisition, as evidenced by increased approaches to the CS-. In contrast, the NMDA receptor antagonist AP-5 impaired only the acquisition, but not performance, of autoshaping whereas the dopamine D1/D2 receptor antagonist alpha-flupenthixol decreased approaches to the CS+ during both acquisition and performance. The data are discussed with reference to dissociable interactions of these receptor types with limbic cortical and dopaminergic afferents to the nucleus accumbens core during the acquisition and expression of Pavlovian conditioned approach.},
author = {Ciano, Patricia Di and Cardinal, Rudolf N and Cowell, Rosie A and Little, Simon J and Everitt, Barry J and {Di Ciano}, P and Cardinal, Rudolf N and Cowell, Rosie A and Little, Simon J and Everitt, Barry J},
doi = {21/23/9471 [pii]},
isbn = {1529-2401 (Electronic){\$}\backslash{\$}n0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {2-Amino-5-phosphonovalerate/administration {\{}{\&}{\}} dosag,2001,AMPA/antagonists {\{}{\&}{\}} inhibitors/*metaboli,Animal,Animal/drug effects,Appetitive Behavior/drug effects/physiology,Behavior,Catheterization,Classical/drug effects/*physiology,Conditioning,Dopamine Antagonists/administration {\{}{\&}{\}} dosage,Dopamine/*metabolism,Dose-Response Relationship,Drug,Excitatory Amino Acid Antagonists/administration {\{}{\&}{\}},Flupenthixol/administration {\{}{\&}{\}} dosage,Inbred Strains,Isoquinolines/administration {\{}{\&}{\}} dosage,Learning/drug effects,Male,Microinjections,N-Methyl-D-Aspartate/antagonists {\{}{\&}{\}} inhi,Non-U.S. Gov't,Nucleus Accumbens/drug effects/*metabolism,Operant/drug effects/physiology,Rats,Receptors,Support,Tetrazoles/administration {\{}{\&}{\}} dosage,abolished the acquisition of,ampa,au-,autoshaping,conditioned stimulus,dopamine,dopaminergic depletions of the,glutamate,lesions of the,moreover,nacc,nmda,nucleus accumbens core,parkinson et al,toshaping},
month = {dec},
number = {23},
pages = {9471--9477},
pmid = {11717381},
title = {{Differential involvement of NMDA, AMPA/kainate, and dopamine receptors in the nucleus accumbens core in the acquisition and performance of pavlovian approach behavior}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve{\%}7B{\&}{\%}7Ddb=PubMed{\%}7B{\&}{\%}7Ddopt=Citation{\%}7B{\&}{\%}7Dlist{\%}7B{\_}{\%}7Duids=11717381},
volume = {21},
year = {2001}
}
@article{mulder05,
author = {Mulder, A B and Shibata, R and Trullier, O and Wiener, S I},
journal = {Experimental Brain Research},
pages = {32--43},
title = {{Spatially selective reward site responses in tonically active neurons of the nucleus accumbens in behaving rats}},
volume = {163},
year = {2005}
}
@article{DuHoffmann2014,
abstract = {Approach to reward is a fundamental adaptive behavior, disruption of which is a core symptom of addiction and depression. Nucleus accumbens (NAc) dopamine is required for reward-predictive cues to activate vigorous reward seeking, but the underlying neural mechanism is unknown. Reward-predictive cues elicit both dopamine release in the NAc and excitations and inhibitions in NAc neurons. However, a direct link has not been established between dopamine receptor activation, NAc cue-evoked neuronal activity, and reward-seeking behavior. Here, we use a novel microelectrode array that enables simultaneous recording of neuronal firing and local dopamine receptor antagonist injection. We demonstrate that, in the NAc of rats performing a discriminative stimulus task for sucrose reward, blockade of either D1 or D2 receptors selectively attenuates excitation, but not inhibition, evoked by reward-predictive cues. Furthermore, we establish that this dopamine-dependent signal is necessary for reward-seeking behavior. These results demonstrate a neural mechanism by which NAc dopamine invigorates environmentally cued reward-seeking behavior.},
author = {du Hoffmann, J and Nicola, S M},
doi = {10.1523/JNEUROSCI.3492-14.2014},
isbn = {0270-6474 1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {cue-excited neurons,discriminative stimulus,dopamine,nucleus accumbens,reward seeking},
month = {oct},
number = {43},
pages = {14349--14364},
pmid = {25339748},
title = {{Dopamine Invigorates Reward Seeking by Promoting Cue-Evoked Excitation in the Nucleus Accumbens}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3492-14.2014},
volume = {34},
year = {2014}
}
@article{Costa2016,
abstract = {Reinforcement learning (RL) theories posit that dopaminergic signals are integrated within the striatum to associate choices with outcomes. Often overlooked is that the amygdala also receives dopaminergic input and is involved in Pavlovian processes that influence choice behavior. To determine the relative contributions of the ventral striatum (VS) and amygdala to appetitive RL, we tested rhesus macaques with VS or amygdala lesions on deterministic and stochastic versions of a two-arm bandit reversal learning task. When learning was characterized with an RL model relative to controls, amygdala lesions caused general decreases in learning from positive feedback and choice consistency. By comparison, VS lesions only affected learning in the stochastic task. Moreover, the VS lesions hastened the monkeys' choice reaction times, which emphasized a speed-accuracy trade-off that accounted for errors in deterministic learning. These results update standard accounts of RL by emphasizing distinct contributions of the amygdala and VS to RL.},
author = {Costa, Vincent D. and {Dal Monte}, Olga and Lucas, Daniel R. and Murray, Elisabeth A. and Averbeck, Bruno B.},
doi = {10.1016/j.neuron.2016.09.025},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {505--517},
title = {{Amygdala and Ventral Striatum Make Distinct Contributions to Reinforcement Learning}},
url = {http://www.sciencedirect.com/science/article/pii/S0896627316305840},
volume = {92},
year = {2016}
}
@article{Wyvell2000,
abstract = {Amphetamine microinjection into the nucleus accumbens shell enhanced the ability of a Pavlovian reward cue to trigger increased instrumental performance for sucrose reward in a pure conditioned incentive paradigm. Rats were first trained to press one of two levers to obtain sucrose pellets. They were separately conditioned to associate a Pavlovian cue (30 sec light) with free sucrose pellets. On test days, the rats received bilateral microinjection of intra-accumbens vehicle or amphetamine (0.0, 2.0, 10.0, or 20.0 microgram/0.5 microliter), and lever pressing was tested in the absence of any reinforcement contingency, while the Pavlovian cue alone was freely presented at intervals throughout the session. Amphetamine microinjection selectively potentiated the cue-elicited increase in sucrose-associated lever pressing, although instrumental responding was not reinforced by either sucrose or the cue during the test. Intra-accumbens amphetamine can therefore potentiate cue-triggered incentive motivation for reward in the absence of primary or secondary reinforcement. Using the taste reactivity measure of hedonic impact, it was shown that intra-accumbens amphetamine failed to increase positive hedonic reaction patterns elicited by sucrose (i.e., sucrose "liking") at doses that effectively increase sucrose "wanting." We conclude that nucleus accumbens dopamine specifically mediates the ability of reward cues to trigger "wanting" (incentive salience) for their associated rewards, independent of both hedonic impact and response reinforcement.},
author = {Wyvell, C L and Berridge, K C},
doi = {http://www.jneurosci.org/content/21/19/7831},
isbn = {1529-2401 (Electronic){\$}\backslash{\$}n0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {ability,addiction,conditioned stimulus,dopamine,hedonia,incen-,incentive salience,instrumental,learning,limbic,mesolimbic,motivation,palat-,pavlovian,reinforcement,reward,shell,taste reactivity,tive,ventral striatum},
month = {nov},
number = {21},
pages = {8122--8130},
pmid = {11050134},
publisher = {Society for Neuroscience},
title = {{Intra-accumbens amphetamine increases the conditioned incentive salience of sucrose reward: enhancement of reward "wanting" without enhanced "liking" or response reinforcement}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11050134},
volume = {20},
year = {2000}
}
@article{Gradin2011,
abstract = {The dopamine system has been linked to anhedonia in depression and both the positive and negative symptoms of schizophrenia, but it remains unclear how dopamine dysfunction could mechanistically relate to observed symptoms. There is considerable evidence that phasic dopamine signals encode prediction error (differences between expected and actual outcomes), with reinforcement learning theories being based on prediction error-mediated learning of associations. It has been hypothesized that abnormal encoding of neural prediction error signals could underlie anhedonia in depression and negative symptoms in schizophrenia by disrupting learning and blunting the salience of rewarding events, and contribute to psychotic symptoms by promoting aberrant perceptions and the formation of delusions. To test this, we used model based functional magnetic resonance imaging and an instrumental reward-learning task to investigate the neural correlates of prediction errors and expected-reward values in patients with depression (n=15), patients with schizophrenia (n=14) and healthy controls (n=17). Both patient groups exhibited abnormalities in neural prediction errors, but the spatial pattern of abnormality differed, with the degree of abnormality correlating with syndrome severity. Specifically, reduced prediction errors in the striatum and midbrain were found in depression, with the extent of signal reduction in the bilateral caudate, nucleus accumbens and midbrain correlating with increased anhedonia severity. In schizophrenia, reduced prediction error signals were observed in the caudate, thalamus, insula and amygdala-hippocampal complex, with a trend for reduced prediction errors in the midbrain, and the degree of blunting in the encoding of prediction errors in the insula, amygdala-hippocampal complex and midbrain correlating with increased severity of psychotic symptoms. Schizophrenia was also associated with disruption in the encoding of expected-reward values in the bilateral amygdala-hippocampal complex and parahippocampal gyrus, with the degree of disruption correlating with psychotic symptom severity. Neural signal abnormalities did not correlate with negative symptom severity in schizophrenia. These findings support the suggestion that a disruption in the encoding of prediction error signals contributes to anhedonia symptoms in depression. In schizophrenia, the findings support the postulate of an abnormality in error-dependent updating of inferences and beliefs driving psychotic symptoms. Phasic dopamine abnormalities in depression and schizophrenia are suggested by our observation of prediction error abnormalities in dopamine-rich brain areas, given the evidence for dopamine encoding prediction errors. The findings are consistent with proposals that psychiatric syndromes reflect different disorders of neural valuation and incentive salience formation, which helps bridge the gap between biological and phenomenological levels of understanding.},
author = {Gradin, Victoria B and Kumar, Poornima and Waiter, Gordon and Ahearn, Trevor and Stickle, Catriona and Milders, Marteen and Reid, Ian and Hall, Jeremy and Steele, J Douglas},
doi = {10.1093/brain/awr059},
isbn = {0006-8950},
issn = {14602156},
journal = {Brain},
keywords = {dopamine,major depression,model based fMRI,prediction error,schizophrenia},
month = {jun},
number = {6},
pages = {1751--1764},
pmid = {21482548},
title = {{Expected value and prediction error abnormalities in depression and schizophrenia}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21482548 https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awr059},
volume = {134},
year = {2011}
}
@article{Asaad2017,
abstract = {To adapt successfully to our environments, we must use the outcomes of our choices to guide future behavior. Critically, we must be able to correctly assign credit for any particular outcome to the causal features which preceded it. In some cases, the causal features may be immediately evident, whereas in others they may be separated in time or intermingled with irrelevant environmental stimuli, creating a potentially nontrivial credit-assignment problem. We examined the neuronal representation of information relevant for credit assignment in the dorsolateral prefrontal cortex (dlPFC) of two male rhesus macaques performing a task that elicited key aspects of this problem. We found that neurons conveyed the information necessary for credit assignment. Specifically, neuronal activity reflected both the relevant cues and outcomes at the time of feedback and did so in a manner that was stable over time, in contrast to prior reports of representational instability in the dlPFC. Furthermore, these representations were most stable early in learning, when credit assignment was most needed. When the same features were not needed for credit assignment, these neuronal representations were much weaker or absent. These results demonstrate that the activity of dlPFC neurons conforms to the basic requirements of a system that performs credit assignment, and that spiking activity can serve as a stable mechanism that links causes and effects.SIGNIFICANCE STATEMENT Credit assignment is the process by which we infer the causes of our successes and failures. We found that neuronal activity in the dorsolateral prefrontal cortex conveyed the necessary information for performing credit assignment. Importantly, while there are various potential mechanisms to retain a "trace" of the causal events over time, we observed that spiking activity was sufficiently stable to act as the link between causes and effects, in contrast to prior reports that suggested spiking representations were unstable over time. In addition, we observed that this stability varied as a function of learning, such that the neural code was more reliable over time during early learning, when it was most needed.},
author = {Asaad, Wael F and Lauro, Peter M and Perge, J{\'{a}}nos A and Eskandar, Emad N},
doi = {10.1523/JNEUROSCI.3311-16.2017},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {credit assignment,learning,monkey,population coding,prefrontal cortex,single neuron},
month = {jul},
number = {29},
pages = {6995--7007},
pmid = {28634307},
publisher = {Society for Neuroscience},
title = {{Prefrontal Neurons Encode a Solution to the Credit-Assignment Problem}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3311-16.2017},
volume = {37},
year = {2017}
}
@article{Ito2008b,
author = {Ito, R. and Robbins, T.W. and Pennartz, C.M. and Everitt, B.J.},
journal = {Journal of Neuroscience},
number = {27},
pages = {6950--6959},
publisher = {Society for Neuroscience},
title = {{Functional interaction between the hippocampus and nucleus accumbens shell is necessary for the acquisition of appetitive spatial context conditioning}},
url = {http://neuro.cjb.net/content/28/27/6950.short},
volume = {28},
year = {2008}
}
@article{Yun2004,
author = {Yun, I A and Wakabayashi, K T and Fields, H L and Nicola, S M},
journal = {Journal of Neuroscience},
number = {12},
pages = {2923--2933},
title = {{The ventral tegmental area is required for the behavioral and nucleus accumbens neuronal firing responses to incentive cues}},
volume = {24},
year = {2004}
}
@book{hearst1974sign,
author = {Hearst, E and Jenkins, H M},
booktitle = {Psychonomic Society},
pages = {1--49},
publisher = {Psychonomic Society},
title = {{Sign-tracking: the stimulus-reinforcer relation and directed action}},
year = {1974}
}
@article{Cooch2015,
abstract = {The ventral striatum has long been proposed as an integrator of biologically significant associative information to drive actions. Although inputs from the amygdala and hippocampus have been much studied, the role of prominent inputs from orbitofrontal cortex (OFC) are less well understood. Here, we recorded single-unit activity from ventral striatum core in rats with sham or ipsilateral neurotoxic lesions of lateral OFC, as they performed an odour-guided spatial choice task. Consistent with prior reports, we found that spiking activity recorded in sham rats during cue sampling was related to both reward magnitude and reward identity, with higher firing rates observed for cues that predicted more reward. Lesioned rats also showed differential activity to the cues, but this activity was unbiased towards larger rewards. These data support a role for OFC in shaping activity in the ventral striatum to represent the biological significance of associative information in the environment.},
author = {Cooch, Nisha K and Stalnaker, Thomas A and Wied, Heather M and Bali-Chaudhary, Sheena and McDannald, Michael A and Liu, Tzu Lan and Schoenbaum, Geoffrey},
doi = {10.1038/ncomms8195},
isbn = {2041-1723 (Electronic){\$}\backslash{\$}r2041-1723 (Linking)},
issn = {20411723},
journal = {Nature Communications},
month = {jun},
pages = {7195},
pmid = {26006060},
publisher = {Nature Publishing Group},
title = {{Orbitofrontal lesions eliminate signalling of biological significance in cue-responsive ventral striatal neurons}},
url = {http://www.nature.com/doifinder/10.1038/ncomms8195},
volume = {6},
year = {2015}
}
@article{Floresco1997,
abstract = {The integrative role of the nucleus accumbens and subpallidal area in relaying hippocampal signals to the mesencephalic locomotor region in the brainstem was investigated electrophysiologically in urethan-anaesthetized rats. A behavioural study of the functional connections was also performed in freely moving rats. In the electrophysiological experiments, subpallidal output neurons to the pedunculoppntine nucleus and the adjacent ventral gray were first identified by their antidromic responses to electrical stimulation of the pedunculopontine nucleus. Hippocampal stimulation was then shown to inhibit orthodromically some of these subpallidal neurons. The inhibitory response was attenuated following microinjection of a dopamine D2 agonist (LY 171555), but not a D1 agonist (SKF 38393), into the accumbens. This suggests that signal transmission from the hippocampus to the subpallidal output neurons to the pedunculopontine nucleus is modulated by a D2 receptor-mediated mechanism in the nucleus accumbens. Injections of N-methyl-d-aspartate into the ventral subiculum of the hippocampus resulted in a threefold increase in locomotor responses. Injection of a D2 agonist into the accumbens reduced the hyperkinetic response dose-dependently and suggests that D2 receptors regulate locomotor responses initiated by the hippocampal-accumbens pathway. Injection of nipecotic acid, a GABA uptake inhibitor, into the subpallidal area or of procaine, a neural transmission blocker, into the region of the pedunculopontine nucleus, also reduced significantly the hippocampal-induced hyperkinetic response. These results provide evidence of limbic (e.g. hippocampus) influences on locomotor activity by way of nucleus accumbens-subpallidal-pedunculopontine nucleus connections which may contribute to adaptive behaviour. Signal transmission from the hippocampus may be regulated by a dopamine D1 receptor mechanism in the accumbens, presumably mediated by the converging mesolimbic dopaminergic input from the ventral tegmental area. ?? 1987.},
author = {Yang, C R and Mogenson, G J},
doi = {10.1016/0306-4522(87)90179-5},
isbn = {0306-4522 (Print)},
issn = {03064522},
journal = {Neuroscience},
keywords = {accumbens,and retrieve food efficiently,induced reversible lesions,is an essential,lidocaine-,neural networks,nucleus,prelimbic cortex,rats,spatial memory,subiculum,the ability to locate,ventral ca1},
month = {mar},
number = {3},
pages = {1041--1055},
pmid = {2963972},
title = {{Hippocampal signal transmission to the pedunculopontine nucleus and its regulation by dopamine D2 receptors in the nucleus accumbens: An electrophysiological and behavioural study}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9030646},
volume = {23},
year = {1987}
}
@article{kalivas05ajp,
author = {Kalivas, Peter W and Volkow, Nora D},
journal = {Am J Psychiatry},
pages = {1403--1413},
title = {{The Neural Basis of Addiction: A Pathology of Motivation and Choice}},
volume = {162},
year = {2005}
}
@article{Akaishi2016,
abstract = {In complex environments, many potential cues can guide a decision or be assigned responsibility for the outcome of the decision. We know little, however, about how humans and animals select relevant information sources that should guide behavior. We show that subjects solve this relevance selection and credit assignment problem by selecting one cue and its association with a particular outcome as the main focus of a hypothesis. To do this, we examined learning while using a task design that allowed us to estimate the focus of each subject's hypotheses on a trial-by-trial basis. When a prediction is confirmed by the outcome, then credit for the outcome is assigned to that cue rather than an alternative. Activity in medial frontal cortex is associated with the assignment of credit to the cue that is the main focus of the hypothesis. However, when the outcome disconfirms a prediction, the focus shifts between cues, and the credit for the outcome is assigned to an alternative cue. This process of reselection for credit assignment to an alternative cue is associated with lateral orbitofrontal cortex.

SIGNIFICANCE STATEMENT Learners should infer which features of environments are predictive of significant events, such as rewards. This “credit assignment” problem is particularly challenging when any of several cues might be predictive. We show that human subjects solve the credit assignment problem by implicitly “hypothesizing” which cue is relevant for predicting subsequent outcomes, and then credit is assigned according to this hypothesis. This process is associated with a distinctive pattern of activity in a part of medial frontal cortex. By contrast, when unexpected outcomes occur, hypotheses are redirected toward alternative cues, and this process is associated with activity in lateral orbitofrontal cortex.},
author = {Akaishi, R. and Kolling, N. and Brown, J. W. and Rushworth, M.},
doi = {10.1523/JNEUROSCI.3159-15.2016},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jan},
number = {4},
pages = {1096--1112},
publisher = {Society for Neuroscience},
title = {{Neural Mechanisms of Credit Assignment in a Multicue Environment}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3159-15.2016},
volume = {36},
year = {2016}
}
@article{Averbeck2017,
abstract = {Reinforcement learning (RL) is the behavioral process of learning the values of actions and objects. Most models of RL assume that the dopaminergic prediction error signal drives plasticity in frontal–striatal circuits. The striatum then encodes value representations that drive decision processes. However, the amygdala has also been shown to play an important role in forming Pavlovian stimulus–outcome associations. These Pavlovian associations can drive motivated behavior via the amygdala projections to the ventral striatum or the ventral tegmental area. The amygdala may, therefore, play a central role in RL. Here we compare the contributions of the amygdala and the striatum to RL and show that both the amygdala and striatum learn and represent expected values in RL tasks. Furthermore, value representations in the striatum may be inherited, to some extent, from the amygdala. The striatum may, therefore, play less of a primary role in learning stimulus– outcome associations in RL than previously suggested.},
author = {Averbeck, Bruno B and Costa, Vincent D},
doi = {10.1038/nn.4506},
isbn = {1097-6256},
issn = {15461726},
journal = {Nature Neuroscience},
keywords = {Motivation,Reward},
month = {apr},
number = {4},
pages = {505--512},
pmid = {28352111},
publisher = {Nature Publishing Group},
title = {{Motivational neural circuits underlying reinforcement learning}},
url = {http://www.nature.com/articles/nn.4506},
volume = {20},
year = {2017}
}
@article{Hyman2006a,
abstract = {Addiction is a state of compulsive drug use; despite treatment and
other attempts to control drug taking, addiction tends to persist.
Clinical and laboratory observations have converged on the hypothesis
that addiction represents the pathological usurpation of neural processes
that normally serve reward-related learning. The major substrates
of persistent compulsive drug use are hypothesized to be molecular
and cellular mechanisms that underlie long-term associative memories
in several forebrain circuits (involving the ventral and dorsal striatum
and prefrontal cortex) that receive input from midbrain dopamine
neurons. Here we review progress in identifying candidate mechanisms
of addiction. Expected online publication date for the Annual Review
of Neuroscience Volume 29 is June 16, 2006. Please see http://www.annualreviews.org/catalog/pub{\_}dates.asp
for revised estimates.},
author = {Hyman, Steven E and Malenka, Robert C and Nestler, Eric J},
doi = {10.1146/annurev.neuro.29.051605.113009},
journal = {Annu Rev Neurosci},
month = {apr},
pmid = {16704369},
title = {{Neural Mechanisms of Addiction: The Role of Reward-Related Learning and Memory.}},
url = {http://dx.doi.org/10.1146/annurev.neuro.29.051605.113009},
year = {2006}
}
@article{Floresco2006a,
abstract = {The ability to behave in a flexible manner is an executive function
mediated in part by different regions of the prefrontal cortex. The
present study investigated the role of two major efferents of the
prefrontal cortex, the nucleus accumbens (NAc) core and shell, in
behavioral flexibility using a maze-based strategy set-shifting task.
During initial discrimination training, rats learned to use either
an egocentric response or a visual-cue discrimination strategy to
obtain food reward. During the set shift, animals had to shift from
the previously acquired response or visual-cue-based strategy and
learn the alternate discrimination. Inactivation of the NAc core,
induced by infusion of the GABA agonists baclofen and muscimol, did
not impair initial acquisition of either a response or visual-cue
discrimination but severely disrupted shifting from one strategy
to another. Analysis of the type of errors revealed that impairments
in set shifting were not attributable to increased perseveration
but to a disruption of the acquisition and maintenance of a new strategy.
In contrast, inactivation of the NAc shell did not impair acquisition
of either a response or a visual-cue discrimination, or shifting
from one strategy to another. However, inactivation of the NAc shell
before initial discrimination training improved performance during
the set shift relative to control animals. These data indicate that
the NAc core and shell make dissociable contributions to behavioral
flexibility during set shifting. The NAc core facilitates the acquisition
and maintenance of novel behavioral strategies and elimination of
inappropriate response options, whereas the shell may mediate learning
about irrelevant stimuli.},
author = {Floresco, Stan B and Ghods-Sharifi, Sarvin and Vexelman, Claudia and Magyar, Orsolya},
doi = {10.1523/JNEUROSCI.4431-05.2006},
journal = {J Neurosci},
keywords = {Agonists; Analysis of Variance; Animals; Appetitiv,Animal; Conditioning,Long-Evans; Set (Psychology); Time Factors,Operant; Discrimination Learning; Extinction,Psychological; GABA ; Maze Learning; Muscimol; Nu},
month = {mar},
number = {9},
pages = {2449--2457},
pmid = {16510723},
title = {{Dissociable roles for the nucleus accumbens core and shell in regulating set shifting.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.4431-05.2006},
volume = {26},
year = {2006}
}
@article{Zaehle2013a,
abstract = {Theoretical models and empirical work indicate a critical role of the NAcc in salience processing. For instance, the NAcc not only responds to appetitive and aversive information, but it also signals novelty, contextual deviance, and action monitoring. However, because most studies have investigated only one specific type of salience independently, it remains unclear how the NAcc concurrently differentiates between different forms of salience. To investigate this issue, we used intracranial electroencephalography in human epilepsy patients together with a previously established visual oddball paradigm. Here, three different oddball categories(novel, neutral, and target images) were infrequently presented among a standard scene image, and subjects responded to the target via button press. This task allowed us to differentiate"item novelty" (new vs neutral oddballs) from"contextual deviance" (neutral oddballs vs standard images) and"targetness" (target vs neutral oddballs). Time-frequency analysis revealed a dissociation between item novelty and contextual deviance on the basis of decreases in either[IMG]/math/theta.gif" ALT="{\{}theta{\}}" BORDER="0"{\textgreater}(4-8 Hz) or{\{}beta{\}} power(20-30 Hz). Targetness, on the other hand, was signaled by positive deflections in the stimulus-locked local field potentials, which, importantly, correlated with subjects' reaction times. These findings indicate that, in an ongoing stream of information, the NAcc differentiates between types of salience by distinct neural mechanisms to guide goal-directed behavior.},
author = {Zaehle, T. and Bauch, E. M. and Hinrichs, H. and Schmitt, F. C. and Voges, J. and Heinze, H.-J. and Bunzeck, N.},
doi = {10.1523/JNEUROSCI.5276-12.2013},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {may},
number = {20},
pages = {8764--8771},
title = {{Nucleus Accumbens Activity Dissociates Different Forms of Salience: Evidence from Human Intracranial Recordings}},
url = {http://www.jneurosci.org/content/33/20/8764.short?rss=1},
volume = {33},
year = {2013}
}
@article{Schultz1993,
abstract = {The present investigation had two aims: (1) to study responses of dopamine neurons to stimuli with attentional and motivational significance during several steps of learning a behavioral task, and (2) to study the activity of dopamine neurons during the performance of cognitive tasks known to be impaired after lesions of these neurons. Monkeys that had previously learned a simple reaction time task were trained to perform a spatial delayed response task via two intermediate tasks. During the learning of each new task, a total of 25{\{}{\%}{\}} of 76 dopamine neurons showed phasic responses to the delivery of primary liquid reward, whereas only 9{\{}{\%}{\}} of 163 neurons responded to this event once task performance was established. This produced an average population response during but not after learning of each task. Reward responses during learning were significantly more numerous and pronounced in area A10, as compared to areas A8 and A9. Dopamine neurons also showed phasic responses to the two conditioned stimuli. These were the instruction cue, which was the first stimulus in each trial and indicated the target of the upcoming arm movement (58{\{}{\%}{\}} of 76 neurons during and 44{\{}{\%}{\}} of 163 neurons after learning), and the trigger stimulus, which was a conditioned incentive stimulus predicting reward and eliciting a saccadic eye movement and an arm reaching movement (38{\{}{\%}{\}} of neurons during and 40{\{}{\%}{\}} after learning). None of the dopamine neurons showed sustained activity in the delay between the instruction and trigger stimuli that would resemble the activity of neurons in dopamine terminal areas, such as the striatum and frontal cortex. Thus, dopamine neurons respond phasically to alerting external stimuli with behavioral significance whose detection is crucial for learning and performing delayed response tasks. The lack of sustained activity suggests that dopamine neurons do not encode representational processes, such as working memory, expectation of external stimuli or reward, or preparation of movement. Rather, dopamine neurons are involved with transient changes of impulse activity in basic attentional and motivational processes underlying learning and cognitive behavior.},
author = {Schultz, W and Apicella, P and Ljungberg, T},
doi = {8441015},
isbn = {0270-6474},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
number = {3},
pages = {900--913},
pmid = {8441015},
title = {{Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8441015},
volume = {13},
year = {1993}
}
@article{Chang2012,
abstract = {Initially-neutral cues paired with rewards are thought to acquire motivational significance, as if the incentive motivational value of the reward is transferred to the cue. Such cues may serve as secondary reinforcers to establish new learning, modulate the performance of instrumental action (Pavlovian-instrumental transfer, PIT), and be the targets of approach and other cue-directed behaviors. Here we examined the effects of lesions of the ventral striatal nucleus accumbens (ACb) and the basolateral amygdala (BLA) on the acquisition of discriminative autoshaped lever-pressing in rats. Insertion of one lever into the experimental chamber was reinforced by sucrose delivery, but insertion of another lever was not reinforced. Although sucrose was delivered independently of the rats' behavior, sham-lesioned rats rapidly came to press the reinforced but not the nonreinforced lever. Bilateral ACb lesions impaired the initial acquisition of sign-tracking but not its terminal levels. In contrast, BLA lesions produced substantial deficits in terminal levels of sign-tracking. Furthermore, whereas ACb lesions primarily affected the probability of lever press responses, BLA lesions mostly affected the rate of responding once it occurred. Finally, disconnection lesions that disrupted communication between ACb and BLA produced both sets of deficits. We suggest that ACb is important for initial acquisition of consummatory-like responses that incorporate hedonic aspects of the reward, while BLA serves to enhance such incentive salience once it is acquired.},
author = {Chang, Stephen E. and Wheeler, Daniel S. and Holland, Peter C.},
doi = {10.1016/j.nlm.2012.03.008},
issn = {10747427},
journal = {Neurobiology of Learning and Memory},
number = {4},
pages = {441--451},
title = {{Roles of nucleus accumbens and basolateral amygdala in autoshaped lever pressing}},
volume = {97},
year = {2012}
}
@article{Crone2005,
abstract = {The ability to retrieve and flexibly switch between task rules is seen as an important component of cognitive control. It is often assumed that lateral prefrontal cortex (latPFC) is important for switching between rules. However, activation associated with rule-switching is less reliably observed in latPFC than in medial PFC (specifically, pre-supplementary motor area). In this study, we tested the hypothesis that medial PFC is important for reconfiguration of task sets, whereas latPFC is important for retrieving, maintaining and implementing relevant rules (i.e. rule representation). Twenty young adults participated in a functional magnetic resonance imaging study in which they determined the correct response to a target stimulus on the basis of an instructional cue. For bivalent targets, the appropriate response depended on the currently relevant rule. In contrast, univalent targets were always associated with the same response. Brain regions of interest were characterized according to their responsiveness to bivalent and univalent targets, on both rule-switch and rule-repetition trials. The data support the hypothesis that rule representation and task-set reconfiguration are separable cognitive processes, associated with dissociable neural activation in latPFC and medial PFC, respectively. Activation profiles of posterior parietal cortex, basal ganglia and rostrolateral PFC are also examined and discussed.},
author = {Crone, Eveline A and Wendelken, Carter and Donohue, Sarah E and Bunge, Silvia A},
doi = {10.1093/cercor/bhi127},
isbn = {1047-3211 (Print){\$}\backslash{\$}n1047-3211 (Linking)},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {Context,Goal,Reconfiguration,Rule,Task set,Task switching,VLPFC,pre-SMA},
month = {jun},
number = {4},
pages = {475--486},
pmid = {16000652},
publisher = {Oxford University Press},
title = {{Neural evidence for dissociable components of task-switching}},
url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhi127},
volume = {16},
year = {2006}
}
@article{Maia2009,
abstract = {The field of reinforcement learning has greatly influenced the neuroscientific study of conditioning. This article provides an introduction to reinforcement learning followed by an examination of the successes and challenges using reinforcement learning to understand the neural bases of conditioning. Successes reviewed include (1) the mapping of positive and negative prediction errors to the firing of dopamine neurons and neurons in the lateral habenula, respectively; (2) the mapping of model-based and model-free reinforcement learning to associative and sensorimotor cortico-basal ganglia-thalamo-cortical circuits, respectively; and (3) the mapping of actor and critic to the dorsal and ventral striatum, respectively. Challenges reviewed consist of several behavioral and neural findings that are at odds with standard reinforcement-learning models, including, among others, evidence for hyperbolic discounting and adaptive coding. The article suggests ways of reconciling reinforcement-learning models with many of the challenging findings, and highlights the need for further theoretical developments where necessary. Additional information related to this study may be downloaded from http://cabn.psychonomic-journals.org/content/supplemental.},
author = {Maia, Tiago V},
doi = {10.3758/CABN.9.4.343},
issn = {1531-135X},
journal = {Cognitive, affective {\&} behavioral neuroscience},
keywords = {Animals,Brain,Brain: physiology,Conditioning (Psychology),Conditioning (Psychology): physiology,Dopamine,Dopamine: physiology,Humans,Models, Psychological,Neurons,Neurons: physiology,Reinforcement (Psychology)},
month = {dec},
number = {4},
pages = {343--64},
pmid = {19897789},
title = {{Reinforcement learning, conditioning, and the brain: Successes and challenges.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19897789},
volume = {9},
year = {2009}
}
@article{Giertler2004,
abstract = {The involvement of the nucleus accumbens (NAc) in the determination of reaction times (RTs) of instrumental responses by the expectancy of future reward was investigated. A simple RT task demanding conditioned lever release was used, in which the upcoming reward magnitude (5 versus 1 pellet) was signalled in advance by discriminative cues. In rats which acquired the task, RTs of instrumental responses were significantly shorter to the discriminative cue predictive of high reward magnitude. Inactivation of the NAc by lidocaine had no effect on RTs and their determination by cue-associated reward magnitudes, and did not affect the rate of correct responses. In keeping with an earlier study, intra-NAc infusion of amphetamine decreased RTs, impaired RT determination by cue-associated reward magnitudes and reduced the rate of correct responses. The unexpected finding that lidocaine inactivation of the NAc had no effect parallels previous data showing that lesions of NAc did not impair RT performance, while manipulation of intra-NAc glutamate or dopamine transmission impaired various aspects of RT performance in comparable tasks. It is suggested that experimental manipulations such as transient and permanent inactivation, which almost completely inhibit NAc neuronal output, allow alternative routes to be used to effectively control behaviour in the task employed here.},
author = {Giertler, C and Bohn, I and Hauber, W},
issn = {0955-8810},
journal = {Behavioural Pharmacology},
keywords = {Animals,Appetitive Behavior,Appetitive Behavior: physiology,Association Learning,Association Learning: physiology,Conditioning,Cues,Discrimination Learning,Discrimination Learning: physiology,Lidocaine,Male,Motivation,Nucleus Accumbens,Nucleus Accumbens: drug effects,Nucleus Accumbens: physiology,Operant,Operant: physiology,Rats,Reaction Time,Reaction Time: physiology,Sprague-Dawley},
month = {feb},
number = {1},
pages = {55--63},
pmid = {15075627},
title = {{Transient inactivation of the rat nucleus accumbens does not impair guidance of instrumental behaviour by stimuli predicting reward magnitude.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15075627},
volume = {15},
year = {2004}
}
@article{Berridge2012,
abstract = {Reward contains separable psychological components of learning, incentive motivation and pleasure. Most computational models have focused only on the learning component of reward, but the motivational component is equally important in reward circuitry, and even more directly controls behavior. Modeling the motivational component requires recognition of additional control factors besides learning. Here I discuss how mesocorticolimbic mechanisms generate the motivation component of incentive salience. Incentive salience takes Pavlovian learning and memory as one input and as an equally important input takes neurobiological state factors (e.g. drug states, appetite states, satiety states) that can vary independently of learning. Neurobiological state changes can produce unlearned fluctuations or even reversals in the ability of a previously learned reward cue to trigger motivation. Such fluctuations in cue-triggered motivation can dramatically depart from all previously learned values about the associated reward outcome. Thus, one consequence of the difference between incentive salience and learning can be to decouple cue-triggered motivation of the moment from previously learned values of how good the associated reward has been in the past. Another consequence can be to produce irrationally strong motivation urges that are not justified by any memories of previous reward values (and without distorting associative predictions of future reward value). Such irrationally strong motivation may be especially problematic in addiction. To understand these phenomena, future models of mesocorticolimbic reward function should address the neurobiological state factors that participate to control generation of incentive salience.},
author = {Berridge, Kent C},
doi = {10.1111/j.1460-9568.2012.07990.x},
issn = {1460-9568},
journal = {European journal of neuroscience},
month = {apr},
number = {7},
pages = {1124--43},
pmid = {22487042},
title = {{From prediction error to incentive salience: mesolimbic computation of reward motivation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22487042 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3325516},
volume = {35},
year = {2012}
}
@article{Deserno2015,
abstract = {Dual system theories suggest that behavioral control is parsed be- tween a deliberative “model-based” and a more reflexive “model- free” system. A balance of control exerted by these systems is thought to be related to dopamine neurotransmission. However, in the absence of direct measures of human dopamine, it remains unknown whether this reflects a quantitative relation with dopa- mine either in the striatum or other brain areas. Using a sequential decision task performed during functional magnetic resonance imaging, combined with striatal measures of dopamine using [18F]DOPA positron emission tomography, we show that higher presynaptic ventral striatal dopamine levels were associated with a behavioral bias toward more model-based control. Higher pre- synaptic dopamine in ventral striatum was associated with greater coding of model-based signatures in lateral prefrontal cortex and di- minished coding of model-free prediction errors in ventral striatum. Thus, interindividual variability in ventral striatal presynaptic dopa- mine reflects a balance in the behavioral expression and the neural signatures of model-free and model-based control. Our data provide a novel perspective on how alterations in presynaptic dopamine levels might be accompanied by a disruption of behavioral control as observed in aging or neuropsychiatric diseases such as schizo- phrenia and addiction. dopamine},
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Deserno, Lorenz and Huys, Quentin J M and Boehme, Rebecca and Buchert, Ralph and Heinze, Hans-Jochen and Grace, Anthony A and Dolan, Raymond J and Heinz, Andreas and Schlagenhauf, Florian},
doi = {10.1073/pnas.1417219112},
eprint = {arXiv:1408.1149},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {PET,decision making,dopamine,fMRI,reinforcement learning},
month = {feb},
number = {5},
pages = {1595--1600},
pmid = {25605941},
publisher = {National Academy of Sciences},
title = {{Ventral striatal dopamine reflects behavioral and neural signatures of model-based control during sequential decision making}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1417219112},
volume = {112},
year = {2015}
}
@article{Yang1984,
abstract = {Extracellular single unit recordings were obtained from neurones in the nucleus accumbens of urethane anaesthetized rats. Single pulse stimulation (300-800 {\$}\mu{\$}A, 0.15 ms, 0.5-1.5 Hz) of the ventral subiculum of the hippocampus strongly excited silent and spontaneously active (3-6 spikes/s) medial accumbens neurones. The majority of neurones excited by hippocampal stimulation were quiescent and identified only by the elicited action potentials. Neurones on the dorso-medial border of the nucleus accumbens and adjacent lateral septum, with a faster spontaneous discharge rate (8-12 spikes/s), were inhibited by hippocampal stimulation. In the ventral border of the accumbens and the olfactory tubercle, hippocampal stimulation also inhibited the fast-firing ({\{}{\textgreater}{\}} 20 spikes/s) neurones. When trains of 10 conditioning pulses (300-800 {\$}\mu{\$}A, 0.15 ms, 10 Hz) were delivered to the ventral tegmental area (VTA) 100 ms before each single-pulse stimulation of the hippocampus, the excitatory responses of the silent and spontaneously active accumbens neurones were attenuated. The possibility of this relatively prolonged attenuation effect being dopamine-mediated was supported by several lines of evidence. Dopamine, applied iontophoretically, reduced markedly the excitatory response of accumbens neurones to hippocampal stimulation. Iontophoretically applied dopamine mimicked the attenuating effect produced by VTA conditioning stimulation in the same neurone. The attenuating effects of VTA conditioning stimulation on the activation of accumbens neurones by hippocampal stimulation was reduced by: (1) administration of 6-hydroxydopamine to the VTA 2 days and 7-9 days prior to the recording session, (2) the intraperitoneal injection of haloperidol 1 h before the recording session, and (3) the iontophoretic application of trifluoperazine to accumbens neurones. These observations support the hypothesis that the attenuating effects of the mesolimbic dopamine system on limbic inputs to the nucleus accumbens may have a role in limbic-motor integration. {\{}{\textcopyright}{\}} 1984.},
author = {{R. Yang}, Charles and {J. Mogenson}, Gordon},
doi = {10.1016/0006-8993(84)90623-1},
issn = {00068993},
journal = {Brain Research},
keywords = {hippocampus,mesolimbic dopamine system,nucleus accumbens,ventral tegmental area},
month = {dec},
number = {1},
pages = {69--84},
pmid = {6151418},
publisher = {Society for Neuroscience},
title = {{Electrophysiological responses of neurones in the nucleus accumbens to hippocampal stimulation and the attenuation of the excitatory responses by the mesolimbic dopaminergic system}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6151418},
volume = {324},
year = {1984}
}
@article{Schonberg,
abstract = {The computational framework of reinforcement learning has been used to forward our understanding of the neural mechanisms underlying reward learning and decision-making behavior. It is known that humans vary widely in their performance in decision-making tasks. Here, we used a simple four-armed bandit task in which subjects are almost evenly split into two groups on the basis of their performance: those who do learn to favor choice of the optimal action and those who do not. Using models of reinforcement learning we sought to determine the neural basis of these intrinsic differences in performance by scanning both groups with functional magnetic resonance imaging. We scanned 29 subjects while they performed the reward-based decision-making task. Our results suggest that these two groups differ markedly in the degree to which reinforcement learning signals in the striatum are engaged during task performance. While the learners showed robust prediction error signals in both the ventral and dorsal striatum during learning, the nonlearner group showed a marked absence of such signals. Moreover, the magnitude of prediction error signals in a region of dorsal striatum correlated significantly with a measure of behavioral performance across all subjects. These findings support a crucial role of prediction error signals, likely originating from dopaminergic midbrain neurons, in enabling learning of action selection preferences on the basis of obtained rewards. Thus, spontaneously observed individual differences in decision making performance demonstrate the suggested dependence of this type of learning on the functional integrity of the dopaminergic striatal system in humans.},
author = {Schonberg, T and Daw, Nathaniel D and Joel, Daphna and O'Doherty, J P},
doi = {10.1523/JNEUROSCI.2496-07.2007},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {associative learning,basal ganglia,computational models,fMRI,instrumental conditioning,prediction errors},
number = {47},
pages = {12860--12867},
pmid = {18032658},
title = {{Reinforcement Learning Signals in the Human Striatum Distinguish Learners from Nonlearners during Reward-Based Decision Making}},
url = {http://www.jneurosci.org/content/jneuro/27/47/12860.full.pdf http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2496-07.2007},
volume = {27},
year = {2007}
}
@article{Roesch2009a,
abstract = {The ventral striatum (VS) is thought to serve as a gateway whereby associative information from the amygdala and prefrontal regions can influence motor output to guide behavior. If VS mediates this "limbic-motor" interface, then one might expect neural correlates in VS to reflect this information. Specifically, neural activity should reflect the integration of motivational value with subsequent behavior. To test this prediction, we recorded from single units in VS while rats performed a choice task in which different odor cues indicated that reward was available on the left or on the right. The value of reward associated with a left or rightward movement was manipulated in separate blocks of trials by either varying the delay preceding reward delivery or by changing reward size. Rats' behavior was influenced by the value of the expected reward and the response required to obtain it, and activity in the majority of cue-responsive VS neurons reflected the integration of these two variables. Unlike similar cue-evoked activity reported previously in dopamine neurons, these correlates were only observed if the directional response was subsequently executed. Furthermore, activity was correlated with the speed at which the rats' executed the response. These results are consistent with the notion that VS serves to integrate information about the value of an expected reward with motor output during decision making.},
author = {Roesch, Matthew R and Singh, Teghpal and Brown, P Leon and Mullins, Sylvina E and Schoenbaum, Geoffrey},
institution = {Department of Anatomy and Neurobiology, University of Maryland School of Medicine, Baltimore, Maryland 21201, USA.},
journal = {Journal of Neuroscience},
number = {42},
pages = {13365--13376},
publisher = {Soc Neuroscience},
title = {{Ventral striatal neurons encode the value of the chosen action in rats deciding between differently delayed or sized rewards.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2788608{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {29},
year = {2009}
}
@article{Lansink2009,
abstract = {Associating spatial locations with rewards is fundamental to survival
in natural environments and requires the integrity of the hippocampus
and ventral striatum. In joint multineuron recordings from these
areas, hippocampal-striatal ensembles reactivated together during
sleep. This process was especially strong in pairs in which the hippocampal
cell processed spatial information and ventral striatal firing correlated
to reward. Replay was dominated by cell pairs in which the hippocampal
"place" cell fired preferentially before the striatal reward-related
neuron. Our results suggest a plausible mechanism for consolidating
place-reward associations and are consistent with a central tenet
of consolidation theory, showing that the hippocampus leads reactivation
in a projection area.},
author = {Lansink, Carien S and Goltstein, Pieter M and Lankelma, Jan V and McNaughton, Bruce L and Pennartz, Cyriel M A},
journal = {PLoS Biol},
keywords = {Animals; Basal Ganglia; Emotions; Hippocampus; Mal,Wistar; Reward; Sleep,journalclub},
mendeley-tags = {journalclub},
month = {aug},
number = {8},
pages = {e1000173},
title = {{Hippocampus leads ventral striatum in replay of place-reward information.}},
url = {http://dx.doi.org/10.1371/journal.pbio.1000173},
volume = {7},
year = {2009}
}
@article{Karlsson2012,
abstract = {Regions within the prefrontal cortex are thought to process beliefs about the world, but little is known about the circuit dynamics underlying the formation and modification of these beliefs. Using a task that permits dissociation between the activity encoding an animal's internal state and that encoding aspects of behavior, we found that transient increases in the volatility of activity in the rat medial prefrontal cortex accompany periods when an animal's belief is modified after an environmental change. Activity across the majority of sampled neurons underwent marked, abrupt, and coordinated changes when prior belief was abandoned in favor of exploration of alternative strategies. These dynamics reflect network switches to a state of instability, which diminishes over the period of exploration as new stable representations are formed.},
author = {Karlsson, M. P. and Tervo, D. G. R. and Karpova, A. Y.},
doi = {10.1126/science.1226518},
issn = {0036-8075},
journal = {Science},
month = {oct},
number = {6103},
pages = {135--139},
title = {{Network Resets in Medial Prefrontal Cortex Mark the Onset of Behavioral Uncertainty}},
url = {http://www.sciencemag.org/content/338/6103/135.abstract},
volume = {338},
year = {2012}
}
@article{Walsh2011,
abstract = {When feedback follows a sequence of decisions, relationships between actions and outcomes can be difficult to learn. We used event-related potentials (ERPs) to understand how people overcome this temporal credit assignment problem. Participants performed a sequential decision task that required two decisions on each trial. The first decision led to an intermediate state that was predictive of the trial outcome, and the second decision was followed by positive or negative trial feedback. The feedback-related negativity (fERN), a component thought to reflect reward prediction error, followed negative feedback and negative intermediate states. This suggests that participants evaluated intermediate states in terms of expected future reward, and that these evaluations supported learning of earlier actions within sequences. We examine the predictions of several temporal-difference models to determine whether the behavioral and ERP results reflected a reinforcement-learning process.},
author = {Walsh, Matthew M. and Anderson, John R.},
doi = {10.3758/s13415-011-0027-0},
isbn = {1531-135X (Electronic)$\backslash$n1530-7026 (Linking)},
issn = {15307026},
journal = {Cognitive, Affective and Behavioral Neuroscience},
keywords = {Actor/critic,Credit assignment,Eligibility traces,Event-related potentials,Q-learning,SARSA,Temporal difference learning},
month = {jun},
number = {2},
pages = {131--143},
pmid = {21416212},
publisher = {Springer-Verlag},
title = {{Learning from delayed feedback: Neural responses in temporal credit assignment}},
url = {http://www.springerlink.com/index/10.3758/s13415-011-0027-0},
volume = {11},
year = {2011}
}
@article{Reynolds2008,
abstract = {The nucleus accumbens mediates both appetitive motivation for rewards and fearful motivation toward threats, which are generated in part by glutamate-related circuits organized in a keyboard fashion. At rostral sites of the medial shell, localized glutamate disruptions typically generate intense appetitive behaviors in rats, but the disruption incrementally generates fearful behaviors as microinjection sites move more caudally. We found that exposure to stressful environments caused caudal fear-generating zones to expand rostrally, filling approximately 90{\%} of the shell. Conversely, a preferred home environment caused fear-generating zones to shrink and appetitive-generating zones to expand caudally, filling approximately 90{\%} of the shell. Thus, the emotional environments retuned the generation of motivation in corticolimbic circuits.},
author = {Reynolds, Sheila M and Berridge, Kent C},
doi = {10.1038/nn2061},
isbn = {1097-6256 (Print)},
issn = {1097-6256},
journal = {Nature neuroscience},
month = {apr},
number = {4},
pages = {423--425},
pmid = {18344996},
title = {{Emotional environments retune the valence of appetitive versus fearful functions in nucleus accumbens.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18344996 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2717027},
volume = {11},
year = {2008}
}
@article{kapur03,
author = {Kapur, Shitij},
journal = {American Journal of Psychiatry},
number = {1},
pages = {13--23},
title = {{Psychosis as a State of Aberrant Salience: A Framework Linking Biology, Phenomenology, and Pharmacology in Schizophrenia}},
volume = {160},
year = {2003}
}
@article{Lansink2016,
abstract = {The use of information from the hippocampal memory system in motivated behavior depends on its communication with the ventral striatum. When an animal encounters cues that signal subsequent reward, its reward expectancy is raised. It is unknown, however, how this process affects hippocampal dynamics and their influence on target structures, such as ventral striatum. We show that, in rats, reward-predictive cues result in enhanced hippocampal theta and beta band rhythmic activity during subsequent action, compared with uncued goal-directed navigation. The beta band component, also labeled theta's harmonic, involves selective hippocampal CA1 cell groups showing frequency doubling of firing periodicity relative to theta rhythmicity and it partitions the theta cycle into segments showing clear versus poor spike timing organization. We found that theta phase precession occurred over a wider range than previously reported. This was apparent from spikes emitted near the peak of the theta cycle exhibiting large "phase precessing jumps" relative to spikes in foregoing cycles. Neither this phenomenon nor the regular manifestation of theta phase precession was affected by reward expectancy. Ventral striatal neuronal firing phase-locked not only to hippocampal theta, but also to beta band activity. Both hippocampus and ventral striatum showed increased synchronization between neuronal firing and local field potential activity during cued compared with uncued goal approaches. These results suggest that cue-triggered reward expectancy intensifies hippocampal output to target structures, such as the ventral striatum, by which the hippocampus may gain prioritized access to systems modulating motivated behaviors. SIGNIFICANCE STATEMENT Here we show that temporally discrete cues raising reward expectancy enhance both theta and beta band activity in the hippocampus once goal-directed navigation has been initiated. These rhythmic activities are associated with increased synchronization of neuronal firing patterns in the hippocampus and the connected ventral striatum. When transmitted to downstream target structures, this expectancy-related state of intensified processing in the hippocampus may modulate goal-directed action.},
author = {Lansink, C S and Meijer, G T and Lankelma, J V and Vinck, M A and Jackson, J C and Pennartz, C M A},
doi = {10.1523/JNEUROSCI.0682-16.2016},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {local field potential,motivation,navigation,nucleus accumbens,rhythm,tetrode},
month = {oct},
number = {41},
pages = {10598--10610},
pmid = {27733611},
publisher = {Society for Neuroscience},
title = {{Reward Expectancy Strengthens CA1 Theta and Beta Band Synchronization and Hippocampal-Ventral Striatal Coupling}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0682-16.2016},
volume = {36},
year = {2016}
}
@article{Parkinson2000,
abstract = {The nucleus accumbens (NAcc) has been implicated in a variety of forms of reward-related learning, reflecting its anatomical connections with limbic cortical structures. After confirming that excitotoxic lesions of the anterior cingulate cortex (Ant Cing) impaired the acquisition of appetitive Pavlovian conditioning in an autoshaping procedure, the effects of excitotoxic lesions to the NAcc core or shell on autoshaping were also assessed. Only selective core lesions impaired Pavlovian approach. A subsequent experiment studied the effects of a disconnection of the Ant Cing and NAcc core, using an asymmetric lesion procedure, to determine whether these structures interact sequentially as part of a limbic corticostriatal system. Such lesioned rats were also significantly impaired relative to controls at autoshaping. These results demonstrate that the NAcc core and Ant Cing are "nodes" of a corticostriatal circuit involved in stimulus-reward learning.},
author = {Parkinson, John A and Willoughby, Pamela J and Robbins, Trevor W and Everitt, Barry J},
doi = {10.1037//0735-7044.114.1.42},
isbn = {0735-7044 (Print){\$}\backslash{\$}r0735-7044 (Linking)},
issn = {07357044},
journal = {Behavioral Neuroscience},
number = {1},
pages = {42--63},
pmid = {10718261},
title = {{Disconnection of the anterior cingulate cortex and nucleus accumbens core impairs pavlovian approach behavior: Further evidence for limbic cortical-ventral striatopallidal systems}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0735-7044.114.1.42},
volume = {114},
year = {2000}
}
@article{Koob2010,
abstract = {Drug addiction is a chronically relapsing disorder that has been characterized by (1) compulsion to seek and take the drug, (2) loss of control in limiting intake, and (3) emergence of a negative emotional state (eg, dysphoria, anxiety, irritability) reflecting a motivational withdrawal syndrome when access to the drug is prevented. Drug addiction has been conceptualized as a disorder that involves elements of both impulsivity and compulsivity that yield a composite addiction cycle composed of three stages: 'binge/intoxication', 'withdrawal/negative affect', and 'preoccupation/anticipation' (craving). Animal and human imaging studies have revealed discrete circuits that mediate the three stages of the addiction cycle with key elements of the ventral tegmental area and ventral striatum as a focal point for the binge/intoxication stage, a key role for the extended amygdala in the withdrawal/negative affect stage, and a key role in the preoccupation/anticipation stage for a widely distributed network involving the orbitofrontal cortex-dorsal striatum, prefrontal cortex, basolateral amygdala, hippocampus, and insula involved in craving and the cingulate gyrus, dorsolateral prefrontal, and inferior frontal cortices in disrupted inhibitory control. The transition to addiction involves neuroplasticity in all of these structures that may begin with changes in the mesolimbic dopamine system and a cascade of neuroadaptations from the ventral striatum to dorsal striatum and orbitofrontal cortex and eventually dysregulation of the prefrontal cortex, cingulate gyrus, and extended amygdala. The delineation of the neurocircuitry of the evolving stages of the addiction syndrome forms a heuristic basis for the search for the molecular, genetic, and neuropharmacological neuroadaptations that are key to vulnerability for developing and maintaining addiction.},
author = {Koob, George F and Volkow, Nora D},
doi = {10.1038/npp.2009.110},
isbn = {1740-634X},
issn = {1740-634X},
journal = {Neuropsychopharmacology},
month = {jan},
number = {1},
pages = {217--38},
pmid = {19710631},
publisher = {Nature Publishing Group},
title = {{Neurocircuitry of addiction.}},
url = {http://www.nature.com/doifinder/10.1038/npp.2009.110 http://www.ncbi.nlm.nih.gov/pubmed/19710631{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2805560},
volume = {35},
year = {2010}
}
@article{DiCiano2008,
abstract = {Drug-paired conditioned reinforcers can maintain persistent instrumental responding, thus providing a model of some aspects of long-term drug addiction. The purpose of the present study was to investigate the effects of inactivating the dorsal striatum (DStr), nucleus accumbens (NAcc) core, or NAcc shell on different types of responding, each maintained by drug-paired conditioned reinforcers. Inactivations were achieved by infusing a combination of baclofen and muscimol prior to (1) persistent responding for a drug-paired conditioned reinforcer, (2) reacquisition of this instrumental response after extinction by omission of the contingent conditioned stimulus (CS), or (3) CS (cue)-induced reinstatement of the original (and different) instrumental response that had previously delivered cocaine. Inactivation of the DStr attenuated persistent responding for a cocaine-paired conditioned reinforcer, as well as its reacquisition after extinction of this response, while the only effect of inactivation of the NAcc shell was to increase CS (cue)-induced reinstatement of the extinguished instrumental response that had previously delivered cocaine. Inactivation of the NAcc core affected all measures of responding maintained by drug-paired conditioned reinforcers. These results are discussed with reference to the neural systems involved in different aspects of responding maintained by drug-paired conditioned reinforcers.},
author = {{Di Ciano}, Patricia and Robbins, Trevor W and Everitt, Barry J},
doi = {10.1038/sj.npp.1301522},
issn = {0893-133X},
journal = {Neuropsychopharmacology : official publication of the American College of Neuropsychopharmacology},
keywords = {Analysis of Variance,Animals,Behavior, Animal,Behavior, Animal: drug effects,Cocaine,Cocaine-Related Disorders,Cocaine-Related Disorders: psychology,Cocaine: administration {\&} dosage,Conditioning, Operant,Conditioning, Operant: drug effects,Conditioning, Operant: physiology,Corpus Striatum,Corpus Striatum: drug effects,Corpus Striatum: physiology,Cues,Dopamine Uptake Inhibitors,Dopamine Uptake Inhibitors: administration {\&} dosag,Exploratory Behavior,Exploratory Behavior: drug effects,Exploratory Behavior: physiology,Extinction, Psychological,Extinction, Psychological: drug effects,Male,Nucleus Accumbens,Nucleus Accumbens: anatomy {\&} histology,Nucleus Accumbens: drug effects,Nucleus Accumbens: physiology,Rats,Reinforcement (Psychology),Reinforcement Schedule},
month = {may},
number = {6},
pages = {1413--25},
pmid = {17712353},
publisher = {American College of Neuropsychopharmacology},
shorttitle = {Neuropsychopharmacology},
title = {{Differential effects of nucleus accumbens core, shell, or dorsal striatal inactivations on the persistence, reacquisition, or reinstatement of responding for a drug-paired conditioned reinforcer.}},
url = {http://dx.doi.org/10.1038/sj.npp.1301522},
volume = {33},
year = {2008}
}
@article{Bouton1993,
abstract = {In this article I review research and theory on the "interference paradigms" in Pavlovian learning. In these situations (e.g., extinction, counterconditioning, and latent inhibition), a conditioned stimulus (CS) is associated with different unconditioned stimuli (USs) or outcomes in different phases of the experiment; retroactive interference, proactive interference, or both are often observed. In all of the paradigms, contextual stimuli influence performance, and when information is available, so does the passage of time. Memories of both phases are retained, and performance may depend on which is retrieved. Despite the similarity of the paradigms, conditioning theories tend to explain them with separate mechanisms. They also do not provide an adequate account of the context's role, fail to predict the effects of time, and overemphasize the role of learning or storage deficits. By accepting 4 propositions about animal memory (i.e., contextual stimuli guide retrieval, time is a context, different memories are differentially dependent on context, and interference occurs at performance output), a memory retrieval framework can provide an integrated account of context, time, and performance in the various paradigms.},
author = {Bouton, M E},
issn = {0033-2909},
journal = {Psychological bulletin},
keywords = {Animals,Association Learning,Attention,Conditioning, Classical,Discrimination Learning,Humans,Inhibition (Psychology),Mental Recall,Retention (Psychology),Reversal Learning},
month = {jul},
number = {1},
pages = {80--99},
pmid = {8346330},
title = {{Context, time, and memory retrieval in the interference paradigms of Pavlovian learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8346330},
volume = {114},
year = {1993}
}
@article{Bornstein2011,
abstract = {The basal ganglia, in particular the striatum, are central to theories of behavioral control, and often identified as a seat of action selection. Reinforcement learning (RL) models-which have driven much recent experimental work on this region-cast striatum as a dynamic controller, integrating sensory and motivational information to construct efficient and enriching behavioral policies. Befitting this informationally central role, the BG sit at the nexus of multiple anatomical 'loops' of synaptic projections, connecting a wide range of cortical and subcortical structures. Numerous pioneering anatomical studies conducted over the past several decades have meticulously catalogued these loops, and labeled them according to the inferred functions of the connected regions. The specific cotermina of the projections are highly localized to several different subregions of the striatum, leading to the suggestion that these subregions perform complementary but distinct functions. However, until recently, the dominant computational framework outlined only a bipartite, dorsal/ventral, division of striatum. We review recent computational and experimental advances that argue for a more finely fractionated delineation. In particular, experimental data provide extensive insight into unique functions subserved by the dorsomedial striatum (DMS). These functions appear to correspond well with theories of a 'model-based' RL subunit, and may also shed light on the suborganization of ventral striatum. Finally, we discuss the limitations of these ideas and how they point the way toward future refinements of neurocomputational theories of striatal function, bringing them into contact with other areas of computational theory and other regions of the brain.},
author = {Bornstein, Aaron M and Daw, Nathaniel D},
doi = {10.1016/j.conb.2011.02.009},
issn = {1873-6882},
journal = {Current Opinion in Neurobiology},
month = {mar},
number = {3},
pages = {374--80},
pmid = {21429734},
title = {{Multiplicity of control in the basal ganglia: computational roles of striatal subregions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21429734},
volume = {21},
year = {2011}
}
@article{Mannella2013,
abstract = {Goal-directed behavior is a fundamental means by which animals can flexibly solve the challenges posed by variable external and internal conditions. Recently, the processes and brain mechanisms underlying such behavior have been extensively studied from behavioral, neuroscientific and computational perspectives. This research has highlighted the processes underlying goal-directed behavior and associated brain systems including prefrontal cortex, basal ganglia and, in particular therein, the nucleus accumbens (NAcc). This paper focusses on one particular process at the core of goal-directed behavior: how motivational value is assigned to goals on the basis of internal states and environmental stimuli, and how this supports goal selection processes. Various biological and computational accounts have been given of this problem and of related multiple neural and behavior phenomena, but we still lack an integrated hypothesis on the generation and use of value for goal selection. This paper proposes an hypothesis that aims to solve this problem and is based on this key elements: (a) amygdala and hippocampus establish the motivational value of stimuli and goals; (b) prefrontal cortex encodes various types of action outcomes; (c) NAcc integrates different sources of value, representing them in terms of a common currency with the aid of dopamine, and thereby plays a major role in selecting action outcomes within prefrontal cortex. The "goals" pursued by the organism are the outcomes selected by these processes. The hypothesis is developed in the context of a critical review of relevant biological and computational literature which offer it support. The paper shows how the hypothesis has the potential to integrate existing interpretations of motivational value and goal selection.},
author = {Mannella, Francesco and Gurney, Kevin and Baldassarre, Gianluca},
doi = {10.3389/fnbeh.2013.00135},
isbn = {1662-5153 (Electronic){\$}\backslash{\$}r1662-5153 (Linking)},
issn = {1662-5153},
journal = {Frontiers in Behavioral Neuroscience},
keywords = {amygdala (amg),appetitive and novelty value,bio-behavioural and computational perspectives,goal selection,hippocampus (Hip),nucleus accumbens (NAcc),prefrontal cortex (PFC)},
pages = {135},
pmid = {24167476},
publisher = {Frontiers},
title = {{The nucleus accumbens as a nexus between values and goals in goal-directed behavior: a review and a new hypothesis}},
url = {http://journal.frontiersin.org/article/10.3389/fnbeh.2013.00135/abstract},
volume = {7},
year = {2013}
}
@article{Samejima2005,
abstract = {The estimation of the reward an action will yield is critical in decision-making. To elucidate the role of the basal ganglia in this process, we recorded striatal neurons of monkeys who chose between left and right handle turns, based on the estimated reward probabilities of the actions. During a delay period before the choices, the activity of more than one-third of striatal projection neurons was selective to the values of one of the two actions. Fewer neurons were tuned to relative values or action choice. These results suggest representation of action values in the striatum, which can guide action selection in the basal ganglia circuit.},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.5367},
author = {Samejima, Kazuyuki and Ueda, Yasumasa and Doya, Kenji and Kimura, Minoru},
doi = {10.1126/science.1115270},
eprint = {arXiv:1308.5367},
isbn = {0036-8075},
issn = {00368075},
journal = {Science},
month = {nov},
number = {5752},
pages = {1337--1340},
pmid = {16311337},
publisher = {American Association for the Advancement of Science},
title = {{Neuroscience: Representation of action-specific reward values in the striatum}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16311337},
volume = {310},
year = {2005}
}
@article{Khamassi2008b,
author = {Khamassi, M. and Mulder, A.B. and Tabuchi, E. and Douchamps, V. and Wiener, S.I.},
journal = {European Journal of Neuroscience},
pages = {1849--1866},
title = {{Anticipatory reward signals in ventral striatal neurons of behaving rats}},
url = {http://www.isir.upmc.fr/files/2008ACLI932.pdf},
volume = {28},
year = {2008}
}
@article{Ikemoto2007,
abstract = {Anatomical and functional refinements of the meso-limbic dopamine system of the rat are discussed. Present experiments suggest that dopaminergic neurons localized in the posteromedial ventral tegmental area (VTA) and central linear nucleus raphe selectively project to the ventromedial striatum (medial olfactory tubercle and medial nucleus accumbens shell), whereas the anteromedial VTA has few if any projections to the ventral striatum, and the lateral VTA largely projects to the ventrolateral striatum (accumbens core, lateral shell and lateral tubercle). These findings complement the recent behavioral findings that cocaine and amphetamine are more rewarding when administered into the ventromedial striatum than into the ventrolateral striatum. Drugs such as nicotine and opiates are more rewarding when administered into the posterior VTA or the central linear nucleus than into the anterior VTA. A review of the literature suggests that (1) the midbrain has corresponding zones for the accumbens core and medial shell; (2) the striatal portion of the olfactory tubercle is a ventral extension of the nucleus accumbens shell; and (3) a model of two dopamine projection systems from the ventral midbrain to the ventral striatum is useful for understanding reward function. The medial projection system is important in the regulation of arousal characterized by affect and drive and plays a different role in goal-directed learning than the lateral projection system, as described in the variation-selection hypothesis of striatal functional organization.},
author = {Ikemoto, Satoshi},
doi = {10.1016/j.brainresrev.2007.05.004},
issn = {0165-0173},
journal = {Brain research reviews},
keywords = {Animals,Brain Mapping,Central Nervous System Stimulants,Central Nervous System Stimulants: pharmacology,Cocaine,Cocaine: pharmacology,Dopamine,Dopamine Uptake Inhibitors,Dopamine Uptake Inhibitors: pharmacology,Dopamine: metabolism,Efferent Pathways,Efferent Pathways: anatomy {\&} histology,Efferent Pathways: physiology,Fluorescent Dyes,Immunohistochemistry,Male,Models, Neurological,Nucleus Accumbens,Nucleus Accumbens: anatomy {\&} histology,Nucleus Accumbens: physiology,Olfactory Pathways,Olfactory Pathways: anatomy {\&} histology,Olfactory Pathways: drug effects,Olfactory Pathways: physiology,Psychotropic Drugs,Psychotropic Drugs: pharmacology,Rats,Rats, Wistar,Reward,Tyrosine 3-Monooxygenase,Tyrosine 3-Monooxygenase: metabolism,Ventral Tegmental Area,Ventral Tegmental Area: anatomy {\&} histology,Ventral Tegmental Area: physiology},
month = {nov},
number = {1},
pages = {27--78},
pmid = {17574681},
title = {{Dopamine reward circuitry: two projection systems from the ventral midbrain to the nucleus accumbens-olfactory tubercle complex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2134972{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {56},
year = {2007}
}
@article{Estes1943,
abstract = {"A series of presentations of a tone followed by food to a group of rats resulted in the conditioning of an anticipatory state to the tone, the primary index being the discriminative effect of the tone upon a lever-pressing response which had previously been reinforced with food but in no way associated with the tone. During a test period subsequent to the series of tone-food combinations, the rate of lever pressing was markedly increased during intervals when the tone was sounding and depressed during silent intervals, although the response had never been associated with the tone prior to the test period." (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Estes, W K},
doi = {10.1037/h0058316},
issn = {00221015},
journal = {Journal of Experimental Psychology},
keywords = { CONDITIONING, DISCRIMINATION, INTELLIGENCE (INCL. ATTENT, RAT,CONDITIONING,DISCRIMINATION,LEARNING,RAT},
number = {2},
pages = {150--155},
title = {{Discriminative conditioning. I. A discriminative property of conditioned anticipation}},
url = {http://content.apa.org/journals/xge/32/2/150},
volume = {32},
year = {1943}
}
@article{Ishikawa2008a,
abstract = {Cue-elicited phasic changes in firing of nucleus accumbens (NAc) neurons
can facilitate reward-seeking behavior. Here, we test the hypothesis
that the medial prefrontal cortex (mPFC), which sends a dense glutamatergic
projection to the NAc core, contributes to NAc neuronal firing responses
to reward-predictive cues. Rats trained to perform an operant response
to a cue for sucrose were implanted with recording electrodes in
the core of the NAc and microinjection cannulas in the dorsal mPFC
(dmPFC). The cue-evoked firing of NAc neurons was reduced by bilateral
injection of GABA(A) and GABA(B) agonists into the dmPFC concomitant
with loss of behavioral responding to the cue. In addition, unilateral
dmPFC inactivation reduced ipsilateral cue excitations and contralateral
cue inhibitions. These findings indicate that cue-evoked excitations
and inhibitions of NAc core neurons depend on dmPFC projections to
the NAc and that these phasic changes contribute to the behavioral
response to reward-predictive cues.},
author = {Ishikawa, Akinori and Ambroggi, Frederic and Nicola, Saleem M and Fields, Howard L},
doi = {10.1523/JNEUROSCI.0253-08.2008},
journal = {J Neurosci},
keywords = {Animal; Cues; Electrophysiology; GABA Agonists; M,Animals; Behavior,GABA-A; Receptors,GABA-B; Reward; Synaptic Transmission,Long-Evans; Receptors},
month = {may},
number = {19},
pages = {5088--5098},
pmid = {18463262},
title = {{Dorsomedial prefrontal cortex contribution to behavioral and nucleus accumbens neuronal responses to incentive cues.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.0253-08.2008},
volume = {28},
year = {2008}
}
@article{Steinberg2013,
author = {Steinberg, Elizabeth E and Keiflin, Ronald and Boivin, Josiah R and Witten, Ilana B and Deisseroth, Karl and Janak, Patricia H},
doi = {10.1038/nn.3413},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {may},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Neurosci},
title = {{A causal link between prediction errors, dopamine neurons and learning}},
url = {http://dx.doi.org/10.1038/nn.3413},
volume = {advance on},
year = {2013}
}
@techreport{ODoherty2003,
abstract = {Temporal difference learning has been proposed as a model for Pavlovian conditioning, in which an animal learns to predict delivery of reward following presentation of a conditioned stimulus (CS). A key component of this model is a prediction error signal, which, before learning, responds at the time of presentation of reward but, after learning, shifts its response to the time of onset of the CS. In order to test for regions manifesting this signal profile, subjects were scanned using event-related fMRI while undergoing appetitive conditioning with a pleasant taste reward. Regression analyses revealed that responses in ventral striatum and orbitofrontal cortex were significantly correlated with this error signal, suggesting that, during appetitive conditioning, computations described by temporal difference learning are expressed in the human brain.},
author = {O'Doherty, John P and Dayan, Peter and Friston, Karl and Critchley, Hugo and Dolan, Raymond J},
booktitle = {Neuron},
doi = {10.1016/S0896-6273(03)00169-7},
isbn = {0896-6273},
issn = {08966273},
number = {2},
pages = {329--337},
pmid = {12718865},
title = {{Temporal difference models and reward-related learning in the human brain}},
volume = {38},
year = {2003}
}
@article{Malhotra2015,
annote = {NULL},
author = {Malhotra, Sushant and Cross, Rob W. and Zhang, Anqi and {Van Der Meer}, Matthijs A A},
journal = {European Journal of Neuroscience},
keywords = {Local field potential,Nucleus accumbens,Phase-amplitude coupling,Striatum,Value},
number = {10},
pages = {2818--2832},
publisher = {Blackwell Publishing Ltd},
title = {{Ventral striatal gamma oscillations are highly variable from trial to trial, and are dominated by behavioural state, and only weakly influenced by outcome value}},
volume = {42},
year = {2015}
}
@article{Day2006,
author = {Day, Jeremy J. and Wheeler, Robert A. and Roitman, Mitchell F. and Carelli, Regina M.},
doi = {10.1111/j.1460-9568.2006.04654.x},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {addiction,associative learning,conditioning,electrophysiology,reward},
month = {mar},
number = {5},
pages = {1341--1351},
publisher = {Blackwell Publishing Ltd},
title = {{Nucleus accumbens neurons encode Pavlovian approach behaviors: evidence from an autoshaping paradigm}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2006.04654.x},
volume = {23},
year = {2006}
}
@article{ODoherty2012,
abstract = {Neural computational accounts of reward-learning have been dominated by the hypothesis that dopamine neurons behave like a reward-prediction error and thus facilitate reinforcement learning in striatal target neurons. While this framework is consistent with a lot of behavioral and neural evidence, this theory fails to account for a number of behavioral and neurobiological observations. In this special issue of EJN we feature a combination of theoretical and experimental papers highlighting some of the explanatory challenges faced by simple reinforcement-learning models and describing some of the ways in which the framework is being extended in order to address these challenges.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {O'Doherty, John P},
doi = {10.1111/j.1460-9568.2012.08074.x},
eprint = {NIHMS150003},
isbn = {1460-9568 (Electronic){\$}\backslash{\$}n0953-816X (Linking)},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Basal ganglia,Computational neuroscience,Conditioning,Decision-making,Prefrontal cortex},
month = {apr},
number = {7},
pages = {987--990},
pmid = {22487029},
publisher = {Blackwell Publishing Ltd},
title = {{Beyond simple reinforcement learning: The computational neurobiology of reward-learning and valuation}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2012.08074.x},
volume = {35},
year = {2012}
}
@article{Chau2015,
abstract = {Recent studies have challenged the view that orbitofrontal cortex (OFC) and amygdala mediate flexible reward-guided behavior. We trained macaques to perform an object discrimination reversal task during fMRI sessions and identified a lateral OFC (lOFC) region in which activity predicted adaptive win-stay/lose-shift behavior. Amygdala and lOFC activity was more strongly coupled on lose-shift trials. However, lOFC-amygdala coupling was also modulated by the relevance of reward information in a manner consistent with a role in establishing how credit for reward should be assigned. Day-to-day fluctuations in signals and signal coupling were correlated with day-to-day fluctuation in performance. A second experiment confirmed the existence of signals for adaptive stay/shift behavior in lOFC and reflecting irrelevant reward in the amygdala in a probabilistic learning task. Our data demonstrate that OFC and amygdala each make unique contributions to flexible behavior and credit assignment.},
author = {Chau, Bolton K.H. and Sallet, J{\'{e}}r{\^{o}}me and Papageorgiou, Georgios K. and Noonan, MaryAnn P. and Bell, Andrew H. and Walton, Mark E. and Rushworth, Matthew F.S.},
doi = {10.1016/J.NEURON.2015.08.018},
issn = {0896-6273},
journal = {Neuron},
month = {sep},
number = {5},
pages = {1106--1118},
publisher = {Cell Press},
title = {{Contrasting Roles for Orbitofrontal Cortex and Amygdala in Credit Assignment and Learning in Macaques}},
url = {https://www.sciencedirect.com/science/article/pii/S0896627315007126},
volume = {87},
year = {2015}
}
@article{Pennartz2004,
author = {Pennartz, C M A and Lee, E and Verheul, J and Lipa, P and Barnes, C A and McNaughton, B L},
journal = {Journal of Neuroscience},
number = {29},
pages = {6446--6456},
title = {{The Ventral Striatum in Off-Line Processing: Ensemble Reactivation during Sleep and Modulation by Hippocampal Ripples}},
volume = {24},
year = {2004}
}
@article{Dejean2016,
abstract = {Affective memories associated with the negative emotional state experienced during opiate withdrawal are central in maintaining drug taking, seeking, and relapse. Nucleus accumbens (NAC) is a key structure for both acute withdrawal and withdrawal memories reactivation, but the NAC neuron coding properties underpinning the expression of these memories remain largely unknown. Here we aimed at deciphering the role of NAC neurons in the encoding and retrieval of opiate withdrawal memory. Chronic single neuron and local field potentials recordings were performed in morphine-dependent rats and placebo controls. Animals were subjected to an unbiased conditioned placed aversion protocol with one compartment (CS+) paired with naloxone-precipitated withdrawal, a second compartment with saline injection (CS-), and a third being neutral (no pairing). After conditioning, animals displayed a typical place aversion for CS+ and developed a preference for CS- characteristic of safety learning. We found that distinct NAC neurons code for CS+ or CS-. Both populations also displayed highly specific oscillatory dynamics, CS+ and CS- neurons, respectively, following 80 Hz (G80) and 60 Hz (G60) local field potential gamma rhythms. Finally, we found that the balance between G60 and G80 rhythms strongly correlated both with the ongoing behavior of the animal and the strength of the conditioning. We demonstrate here that the aversive and preferred environments are underpinned by distinct groups of NAC neurons as well as specific oscillatory dynamics. This suggest that G60/G80 interplay-established through the conditioning process-serves as a robust and versatile mechanism for a fine coding of the environment emotional weight.Neuropsychopharmacology advance online publication, 4 January 2017; doi:10.1038/npp.2016.272.},
author = {Dejean, Cyril and Sitko, Mathieu and Girardeau, Paul and Bennabi, Amine and Caill{\'{e}}, St{\'{e}}phanie and Cador, Martine and Boraud, Thomas and {Le Moine}, Catherine},
doi = {10.1038/npp.2016.272},
issn = {0893-133X},
journal = {Neuropsychopharmacology},
month = {dec},
number = {5},
pages = {1157--1168},
pmid = {27922595},
title = {{Memories of Opiate Withdrawal Emotional States Correlate with Specific Gamma Oscillations in the Nucleus Accumbens}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27922595 http://www.nature.com/doifinder/10.1038/npp.2016.272},
volume = {42},
year = {2017}
}
@article{Schultz2016,
abstract = {Reward prediction errors consist of the differences between received and predicted rewards. They are crucial for basic forms of learning about rewards and make us strive for more rewards-an evolutionary beneficial trait. Most dopamine neurons in the midbrain of humans, monkeys, and rodents signal a reward prediction error; they are activated by more reward than predicted (positive prediction error), remain at baseline activity for fully predicted rewards, and show depressed activity with less reward than predicted (negative prediction error). The dopamine signal increases nonlinearly with reward value and codes formal economic utility. Drugs of addiction generate, hijack, and amplify the dopamine reward signal and induce exaggerated, uncontrolled dopamine effects on neuronal plasticity. The striatum, amygdala, and frontal cortex also show reward prediction error coding, but only in subpopulations of neurons. Thus, the important concept of reward prediction errors is implemented in neuronal hardware.{\$}\backslash{\$}n{\$}\backslash{\$}nAbstract available from the publisher.{\$}\backslash{\$}n{\$}\backslash{\$}nAbstract available from the publisher.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Schultz, Wolfram},
doi = {10.1038/nrn.2015.26},
eprint = {9809069v1},
isbn = {3-540-27590-8},
issn = {12948322},
journal = {Dialogues in Clinical Neuroscience},
keywords = {Dopamine,Neuron,Neurophysiology,Prediction,Reward,Striatum,Substantia nigra,Ventral tegmental area},
month = {feb},
number = {1},
pages = {23--32},
pmid = {27069377},
primaryClass = {arXiv:gr-qc},
publisher = {Nature Publishing Group},
title = {{Dopamine reward prediction error coding}},
url = {http://www.nature.com/doifinder/10.1038/nrn.2015.26},
volume = {18},
year = {2016}
}
