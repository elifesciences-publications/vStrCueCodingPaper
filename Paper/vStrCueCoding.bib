Automatically generated by Mendeley Desktop 1.17.12
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Roitman2005,
author = {Roitman, Mitchell F. and Wheeler, Robert A. and Carelli, Regina M.},
doi = {10.1016/j.neuron.2004.12.055},
issn = {08966273},
journal = {Neuron},
month = {feb},
number = {4},
pages = {587--597},
title = {{Nucleus Accumbens Neurons Are Innately Tuned for Rewarding and Aversive Taste Stimuli, Encode Their Predictors, and Are Linked to Motor Output}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627305000681},
volume = {45},
year = {2005}
}
@article{Reynolds2008,
author = {Reynolds, Sheila M and Berridge, Kent C},
doi = {10.1038/nn2061},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {apr},
number = {4},
pages = {423--425},
publisher = {Nature Publishing Group},
title = {{Emotional environments retune the valence of appetitive versus fearful functions in nucleus accumbens}},
url = {http://www.nature.com/doifinder/10.1038/nn2061},
volume = {11},
year = {2008}
}
@article{Nicola2010a,
abstract = {Dopamine released in the nucleus accumbens is thought to contribute to the decision to exert effort to seek reward. This hypothesis is supported by findings that performance of tasks requiring higher levels of effort is more susceptible to disruption by manipulations that reduce accumbens dopamine function than tasks that require less effort. However, performance of some low-effort cue-responding tasks is highly dependent on accumbens dopamine. To reconcile these disparate results, we made detailed behavioral observations of rats performing various operant tasks and determined how injection of dopamine receptor antagonists into the accumbens influenced specific aspects of the animals' behavior. Strikingly, once animals began a chain of operant responses, the antagonists did not affect the ability to continue the chain until reward delivery. Instead, when rats left the operandum, the antagonists severely impaired the ability to return. We show that this impairment is specific to situations in which the animal must determine a new set of approach actions on each approach occasion; this behavior is called "flexible approach." Both high-effort operant tasks and some low-effort cue-responding tasks require dopamine receptor activation in the accumbens because animals pause their responding and explore the chamber, and accumbens dopamine is required to terminate these pauses with flexible approach to the operandum. The flexible approach hypothesis provides a unified framework for understanding the contribution of the accumbens and its dopamine projection to reward-seeking behavior.},
author = {Nicola, Saleem M},
doi = {10.1523/JNEUROSCI.3958-10.2010},
file = {:C$\backslash$:/Users/mvdmlab/Google Drive/Project/Literature/dopamine/2010 Nicola J Neuro - flexible approach nAc and DA.pdf:pdf},
isbn = {0270-6474},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
number = {49},
pages = {16585--16600},
pmid = {21147998},
title = {{The flexible approach hypothesis: unification of effort and cue-responding hypotheses for the role of nucleus accumbens dopamine in the activation of reward-seeking behavior.}},
volume = {30},
year = {2010}
}
@article{Deserno2015,
abstract = {Dual system theories suggest that behavioral control is parsed between a deliberative "model-based" and a more reflexive "model-free" system. A balance of control exerted by these systems is thought to be related to dopamine neurotransmission. However, in the absence of direct measures of human dopamine, it remains unknown whether this reflects a quantitative relation with dopamine either in the striatum or other brain areas. Using a sequential decision task performed during functional magnetic resonance imaging, combined with striatal measures of dopamine using [(18)F]DOPA positron emission tomography, we show that higher presynaptic ventral striatal dopamine levels were associated with a behavioral bias toward more model-based control. Higher presynaptic dopamine in ventral striatum was associated with greater coding of model-based signatures in lateral prefrontal cortex and diminished coding of model-free prediction errors in ventral striatum. Thus, interindividual variability in ventral striatal presynaptic dopamine reflects a balance in the behavioral expression and the neural signatures of model-free and model-based control. Our data provide a novel perspective on how alterations in presynaptic dopamine levels might be accompanied by a disruption of behavioral control as observed in aging or neuropsychiatric diseases such as schizophrenia and addiction.},
author = {Deserno, Lorenz and Huys, Quentin J M and Boehme, Rebecca and Buchert, Ralph and Heinze, Hans-Jochen and Grace, Anthony A and Dolan, Raymond J and Heinz, Andreas and Schlagenhauf, Florian},
doi = {10.1073/pnas.1417219112},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Deserno et al. - 2015 - Ventral striatal dopamine reflects behavioral and neural signatures of model-based control during sequential dec.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {PET,decision making,dopamine,fMRI,reinforcement learning},
month = {feb},
number = {5},
pages = {1595--600},
pmid = {25605941},
publisher = {National Academy of Sciences},
title = {{Ventral striatal dopamine reflects behavioral and neural signatures of model-based control during sequential decision making.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25605941 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4321318},
volume = {112},
year = {2015}
}
@article{Durstewitz2010,
abstract = {One of the most intriguing aspects of adaptive behavior involves the inference of regularities and rules in ever-changing environments. Rules are often deduced through evidence-based learning which relies on the prefrontal cortex (PFC). This is a highly dynamic process, evolving trial by trial and therefore may not be adequately captured by averaging single-unit responses over numerous repetitions. Here, we employed advanced statistical techniques to visualize the trajectories of ensembles of simultaneously recorded medial PFC neurons on a trial-by-trial basis as rats deduced a novel rule in a set-shifting task. Neural populations formed clearly distinct and lasting representations of familiar and novel rules by entering unique network states. During rule acquisition, the recorded ensembles often exhibited abrupt transitions, rather than evolving continuously, in tight temporal relation to behavioral performance shifts. These results support the idea that rule learning is an evidence-based decision process, perhaps accompanied by moments of sudden insight. ?? 2010 Elsevier Inc.},
author = {Durstewitz, Daniel and Vittoz, Nicole M. and Floresco, Stan B. and Seamans, Jeremy K.},
doi = {10.1016/j.neuron.2010.03.029},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
pages = {438--448},
pmid = {20471356},
title = {{Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning}},
volume = {66},
year = {2010}
}
@article{Takahashi2016,
abstract = {Dopamine neurons signal reward prediction errors. This requires accurate reward predictions. It has been suggested that the ventral striatum provides these predictions. Here we tested this hypothesis by recording from putative dopamine neurons in the VTA of rats performing a task in which prediction errors were induced by shifting reward timing or number. In controls, the neurons exhibited error signals in response to both manipulations. However, dopamine neurons in rats with ipsilateral ventral striatal lesions exhibited errors only to changes in number and failed to respond to changes in timing of reward. These results, supported by computational modeling, indicate that predictions about the temporal specificity and the number of expected reward are dissociable and that dopaminergic prediction-error signals rely on the ventral striatum for the former but not the latter.},
author = {Takahashi, Yuji K. and Langdon, Angela J. and Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1016/j.neuron.2016.05.015},
issn = {08966273},
journal = {Neuron},
month = {jul},
number = {1},
pages = {182--193},
pmid = {27292535},
title = {{Temporal Specificity of Reward Prediction Errors Signaled by Putative Dopamine Neurons in Rat VTA Depends on Ventral Striatum}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27292535 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4938771 http://linkinghub.elsevier.com/retrieve/pii/S0896627316301751},
volume = {91},
year = {2016}
}
@article{Chang2013a,
abstract = {Certain Pavlovian conditioned stimuli (CSs) paired with food unconditioned stimuli (USs) come to elicit approach and even consumption-like behaviors in rats (sign-tracking). We investigated the effects of lesions of the nucleus accumbens core (ACbC) or shell (ACbS) on the acquisition of sign-tracking in a discriminative autoshaping procedure in which presentation of one lever CS was followed by delivery of sucrose, and another was not. Although we previously found that bilateral lesions of the whole ACb disrupted the initial acquisition of sign-tracking, neither ACbC or ACbS lesions affected the rate or percentage of trials in which rats pressed the CS+. In addition, detailed video analysis showed no effect of either lesion on the topography of the sign-tracking conditioned response (CR). These and other results from lesion studies of autoshaping contrast with those from previous sign-tracking experiments that used purely visual cues (Parkinson et al., 2000a,b), suggesting that the neural circuitry involved in assigning incentive value depends upon the nature of the CS.},
author = {Chang, Stephen E. and Holland, Peter C.},
doi = {10.1016/j.bbr.2013.07.046},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {ACbC,ACbS,Autoshaping,BLA,CR,CS,CeA,DA,Incentive salience,Nucleus accumbens core,Nucleus accumbens shell,US,VTA,amygdala central nucleus,basolateral amygdala,conditioned response,conditioned stimulus,dopamine,nucleus accumbens core,nucleus accumbens shell,unconditioned stimulus,ventral tegmental area},
month = {nov},
pages = {36--42},
pmid = {23933141},
title = {{Effects of nucleus accumbens core and shell lesions on autoshaped lever-pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23933141 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3815957 http://linkinghub.elsevier.com/retrieve/pii/S0166432813004580},
volume = {256},
year = {2013}
}
@incollection{Carelli2009,
abstract = {Drug addiction in humans is a chronic disease characterized by compulsive drug intake followed by periods of abstinence and relapse. Electrophysiological recordings in behaving rodents have provided critical information regarding cellular mechanisms underlying this behavior. This approach, combined with the drug self-administration procedure, allows for an analysis of cell firing during key features of drug-seeking behaviors. Here, animal studies that examined the activity of neurons within the brain reward system (particularly the nucleus accumbens, NAc) during drug self-administration are reviewed. These findings reveal important insight into neural mechanisms underlying goal-directed behaviors and how drugs of abuse alter this system and lead to addiction.},
author = {Carelli, R.M.},
booktitle = {Encyclopedia of Neuroscience},
doi = {10.1016/B978-008045046-9.01546-1},
isbn = {9780080450469},
pages = {677--682},
publisher = {Elsevier},
title = {{Drug Addiction: Behavioral Neurophysiology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780080450469015461},
year = {2009}
}
@article{Hauber2000,
abstract = {Expectancy of future reward is an important factor guiding the speed of instrumental behavior. The present study sought to explore whether signals transmitted via the NMDA subtype of glutamate receptors and via dopamine D(2) receptors in the nucleus accumbens (NAc) are critical for the determination of reaction times (RTs) of instrumental responses by the expectancy of future reward. A simple RT task for rats demanding conditioned lever release was used in which the upcoming reward magnitude (5 or 1 pellet) was signaled in advance by discriminative stimuli. In trained rats, RTs of conditioned responses with expectancy of a high reward magnitude were found to be significantly shorter. The shortening of RTs by stimuli predictive of high reward to be obtained was dose-dependently impaired by bilateral intra-NAc infusion of the competitive NMDA antagonist dl-2-amino-5-phosphonovaleric acid (APV) (1, 2, or 10 microg in 0.5 microl/side), but not by infusion of the preferential dopamine D(2) antagonist haloperidol (5 and 12.5 microg in 0.5 microl/side) or by infusion of vehicle (0.5 microl/side). In conclusion, the data reveal that in well trained animals stimulation of intra-NAc NMDA, but not of dopamine D(2), receptors, is critically involved in guiding the speed of instrumental responses according to stimuli predictive of the upcoming reward magnitude.},
author = {Hauber, W and Bohn, I and Giertler, C},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {aug},
number = {16},
pages = {6282--8},
pmid = {10934279},
publisher = {Society for Neuroscience},
title = {{NMDA, but not dopamine D(2), receptors in the rat nucleus accumbens areinvolved in guidance of instrumental behavior by stimuli predicting reward magnitude.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10934279},
volume = {20},
year = {2000}
}
@misc{Karlsson2012,
abstract = {Regions within the prefrontal cortex are thought to process beliefs about the world, but little is known about the circuit dynamics underlying the formation and modification of these beliefs. Using a task that permits dissociation between the activity encoding an animal's internal state and that encoding aspects of behavior, we found that transient increases in the volatility of activity in the rat medial prefrontal cortex accompany periods when an animal's belief is modified after an environmental change. Activity across the majority of sampled neurons underwent marked, abrupt, and coordinated changes when prior belief was abandoned in favor of exploration of alternative strategies. These dynamics reflect network switches to a state of instability, which diminishes over the period of exploration as new stable representations are formed.},
author = {Karlsson, M. P. and Tervo, D. G. R. and Karpova, A. Y.},
booktitle = {Science},
doi = {10.1126/science.1226518},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {0036-8075},
pages = {135--139},
pmid = {23042898},
title = {{Network Resets in Medial Prefrontal Cortex Mark the Onset of Behavioral Uncertainty}},
volume = {338},
year = {2012}
}
@article{Ikemoto2007,
abstract = {Anatomical and functional refinements of the meso-limbic dopamine system of the rat are discussed. Present experiments suggest that dopaminergic neurons localized in the posteromedial ventral tegmental area (VTA) and central linear nucleus raphe selectively project to the ventromedial striatum (medial olfactory tubercle and medial nucleus accumbens shell), whereas the anteromedial VTA has few if any projections to the ventral striatum, and the lateral VTA largely projects to the ventrolateral striatum (accumbens core, lateral shell and lateral tubercle). These findings complement the recent behavioral findings that cocaine and amphetamine are more rewarding when administered into the ventromedial striatum than into the ventrolateral striatum. Drugs such as nicotine and opiates are more rewarding when administered into the posterior VTA or the central linear nucleus than into the anterior VTA. A review of the literature suggests that (1) the midbrain has corresponding zones for the accumbens core and medial shell; (2) the striatal portion of the olfactory tubercle is a ventral extension of the nucleus accumbens shell; and (3) a model of two dopamine projection systems from the ventral midbrain to the ventral striatum is useful for understanding reward function. The medial projection system is important in the regulation of arousal characterized by affect and drive and plays a different role in goal-directed learning than the lateral projection system, as described in the variation-selection hypothesis of striatal functional organization.},
author = {Ikemoto, Satoshi},
doi = {10.1016/j.brainresrev.2007.05.004},
issn = {01650173},
journal = {Brain Research Reviews},
month = {nov},
number = {1},
pages = {27--78},
pmid = {17574681},
title = {{Dopamine reward circuitry: Two projection systems from the ventral midbrain to the nucleus accumbens–olfactory tubercle complex}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17574681 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2134972 http://linkinghub.elsevier.com/retrieve/pii/S0165017307000756},
volume = {56},
year = {2007}
}
@article{Ito2008,
abstract = {The nucleus accumbens (NAc) has been implicated in a variety of associative processes that are dependent on the integrity of the amygdala and hippocampus (HPC). However, the extent to which the two subregions of the NAc, the core and shell, form differentiated circuits within the amygdala- and hippocampal-ventral striatal circuitry remains unclear. The present study investigated the effects of selective excitotoxic lesions of the nucleus accumbens shell or core subregion on appetitive elemental cue and context conditioning, shown previously to be dependent on the basolateral amygdala and hippocampus, respectively. Rats were trained sequentially to acquire discrete conditioned stimulus-sucrose conditioning, followed by spatial context-sucrose conditioning in a place preference apparatus characterized by three topographically identical chambers, the chambers being discriminable only on the basis of path integration. NAc shell lesions selectively impaired the acquisition of conditioned place preference and the use of spatial information to retrieve information about a discrete cue, whereas, as expected, NAc core lesions attenuated the acquisition of cue conditioning compared with sham rats. In a subsequent experiment, disconnection of the HPC from the NAc shell using unilateral asymmetric lesions of each structure resulted in a pattern of impairment in place conditioning and context-dependent cue retrieval similar to that produced by NAc shell lesions. These data not only suggest that the NAc core and shell subregions subserve distinct associative processes but also that the NAc shell and HPC are important functional components of a limbic corticostriatal network involved in spatial context conditioning.},
author = {Ito, Rutsuko and Robbins, Trevor W and Pennartz, Cyriel M and Everitt, Barry J},
doi = {10.1523/JNEUROSCI.1615-08.2008},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ito et al. - 2008 - Functional interaction between the hippocampus and nucleus accumbens shell is necessary for the acquisition of appet.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {jul},
number = {27},
pages = {6950--9},
pmid = {18596169},
publisher = {Society for Neuroscience},
title = {{Functional interaction between the hippocampus and nucleus accumbens shell is necessary for the acquisition of appetitive spatial context conditioning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18596169 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3844800},
volume = {28},
year = {2008}
}
@article{Wheeler2009,
abstract = {An important goal of cocaine addiction research is to understand the neurobiological mechanisms underlying this disease state. Here, we review studies from our laboratory that examined nucleus accumbens (NAc) cell firing and rapid dopamine signaling using electrophysiological and electrochemical recordings in behaving rodents. A major advantage of these techniques is that they allow for the characterization of NAc activity and rapid dopamine release during specific phases of motivated behavior. Moreover, each approach enables an examination of the dynamic nature of NAc signaling as a function of factors such as hedonics and associative learning. We show that NAc neurons differentially respond to rewarding and aversive stimuli and their predictors in a bivalent manner. This differential responding is modifiable and can be altered by the presentation of other natural rewards or cocaine. Likewise, the dynamic nature of NAc cell firing is also reflected in the differential activation of distinct populations of NAc neurons during goal-directed behaviors for natural versus drug rewards, and the heightened activation of some NAc neurons following cocaine abstinence. Our electrochemical data also show that rapid dopamine signaling in the NAc reflects primary rewards and their predictors and appears to modulate specific NAc neuronal responses. In some cases, these influences are observed in a regionally specific manner that matches previous pharmacological manipulations. Collectively, these findings provide critical insight into the functional organization of the NAc that can be used to guide additional studies aimed at dissecting the neural code underlying compulsive drug-seeking behavior.},
author = {Wheeler, Robert A. and Carelli, Regina M.},
doi = {10.1016/J.NEUROPHARM.2008.06.028},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wheeler, Carelli - 2009 - Dissecting motivational circuitry to understand substance abuse.pdf:pdf},
issn = {0028-3908},
journal = {Neuropharmacology},
month = {jan},
pages = {149--159},
publisher = {Pergamon},
title = {{Dissecting motivational circuitry to understand substance abuse}},
url = {http://www.sciencedirect.com/science/article/pii/S0028390808002189},
volume = {56},
year = {2009}
}
@article{Hall2001,
author = {Hall, Jeremy and Parkinson, John A. and Connor, Thomas M. and Dickinson, Anthony and Everitt, Barry J.},
doi = {10.1046/j.0953-816x.2001.01577.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall et al. - 2001 - Involvement of the central nucleus of the amygdala and nucleus accumbens core in mediating Pavlovian influences on.pdf:pdf},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Pavlovian conditioning,Pavlovian‐to‐instrumental transfer,motivation,rat},
month = {may},
number = {10},
pages = {1984--1992},
publisher = {Blackwell Science Ltd},
title = {{Involvement of the central nucleus of the amygdala and nucleus accumbens core in mediating Pavlovian influences on instrumental behaviour}},
url = {http://doi.wiley.com/10.1046/j.0953-816x.2001.01577.x},
volume = {13},
year = {2001}
}
@article{Brown1968,
author = {Brown, Paul L. and Jenkins, Herbert M.},
doi = {10.1901/jeab.1968.11-1},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown, Jenkins - 1968 - Auto-shaping of the pigeon's key-peck1.pdf:pdf},
issn = {0022-5002},
journal = {Journal of the Experimental Analysis of Behavior},
month = {jan},
number = {1},
pages = {1--8},
publisher = {Blackwell Publishing Ltd},
title = {{Auto-shaping of the pigeon's key-peck1}},
url = {http://www.pubmedcentral.gov/articlerender.fcgi?artid=1338436},
volume = {11},
year = {1968}
}
@techreport{ODoherty2003,
abstract = {Temporal difference learning has been proposed as a model for Pavlovian conditioning, in which an animal learns to predict delivery of reward following presentation of a conditioned stimulus (CS). A key component of this model is a prediction error signal, which, before learning, responds at the time of presentation of reward but, after learning, shifts its response to the time of onset of the CS. In order to test for regions manifesting this signal profile, subjects were scanned using event-related fMRI while undergoing appetitive conditioning with a pleasant taste reward. Regression analyses revealed that responses in ventral striatum and orbitofrontal cortex were significantly correlated with this error signal, suggesting that, during appetitive conditioning, computations described by temporal difference learning are expressed in the human brain.},
author = {O'Doherty, John P and Dayan, Peter and Friston, Karl and Critchley, Hugo and Dolan, Raymond J},
booktitle = {Neuron},
doi = {10.1016/S0896-6273(03)00169-7},
isbn = {0896-6273},
issn = {08966273},
pages = {329--337},
pmid = {12718865},
title = {{Temporal difference models and reward-related learning in the human brain.}},
volume = {38},
year = {2003}
}
@article{Schultz2015,
author = {Schultz, Wolfram},
doi = {10.1152/physrev.00023.2014},
issn = {0031-9333},
journal = {Physiological Reviews},
month = {jul},
number = {3},
pages = {853--951},
title = {{Neuronal Reward and Decision Signals: From Theories to Data}},
url = {http://physrev.physiology.org/lookup/doi/10.1152/physrev.00023.2014},
volume = {95},
year = {2015}
}
@article{Koya2009,
abstract = {Learned associations between effects of abused drugs and the drug administration environment are important in drug addiction. Histochemical and electrophysiological studies suggest that these associations are encoded in sparsely distributed nucleus accumbens neurons that are selectively activated by drugs and drug-associated cues. Although correlations have been observed between nucleus accumbens neuronal activity and responsivity to drugs and drug cues, no technique exists for selectively manipulating these activated neurons and establishing their causal role in behavioral effects of drugs and drug cues. Here we describe a new approach, which we term the 'Daun02 inactivation method', that selectively inactivates a minority of neurons previously activated by cocaine in an environment repeatedly paired with cocaine to demonstrate a causal role for these activated neurons in context-specific cocaine-induced psychomotor sensitization in rats. This method provides a new tool for studying the causal roles of selectively activated neurons in behavioral effects of drugs and drug cues and in other learned behaviors.},
author = {Koya, Eisuke and Golden, Sam A and Harvey, Brandon K and Guez-Barber, Danielle H and Berkow, Alexander and Simmons, Danielle E and Bossert, Jennifer M and Nair, Sunila G and Uejima, Jamie L and Marin, Marcelo T and Mitchell, Timothy B and Farquhar, David and Ghosh, Sukhen C and Mattson, Brandi J and Hope, Bruce T},
doi = {10.1038/nn.2364},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature neuroscience},
pages = {1069--1073},
pmid = {19620976},
title = {{Targeted disruption of cocaine-activated nucleus accumbens neurons prevents context-specific sensitization.}},
volume = {12},
year = {2009}
}
@article{Carelli1994,
abstract = {The firing patterns of nucleus accumbens (NA) neurons in the rat were recorded during cocaine self-administration and responding for water. Recordings were obtained from permanently implanted multiple-electrode arrays (eight microwires) inserted bilaterally into rostral portions of the NA in subjects (n = 18) exhibiting stable cocaine self-administration (0.33 mg/infusion), and during stable responding for water reinforcement. Electronically isolated and identified NA neurons exhibited four distinct patterns of phasic activity relative to the reinforced response. Three of these firing patterns were observed during both cocaine self-administration and water reinforcement sessions. Response-related activity was categorized by cells that showed an anticipatory increase in firing rate during the preresponse phase (type PR), and by cells that were excited (type RFE) or inhibited (type RFI) following the response in the reinforcement phase. PR and RFE cells showed significantly reduced peak firing during cocaine self-administration, compared to similar cells in water reinforcement sessions. A fourth type of NA firing pattern (type PR+RF) was observed only in cells recorded during cocaine self-administration sessions (Carelli et al., 1993b). PR+RF neurons exhibited two distinct peaks, one preceding the response and terminating at response completion (like PR cells), and a second peak immediately following the response (like RFE cells) with an inhibitory period between the two peaks (like RFI cells). The findings are discussed in terms of the role of the NA in mediating the reinforcing properties of both cocaine and water.},
author = {Carelli, R M and Deadwyler, S A},
isbn = {0270-6474 (Print)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
pages = {7735--7746},
pmid = {7996208},
title = {{A comparison of nucleus accumbens neuronal firing patterns during cocaine self-administration and water reinforcement in rats.}},
volume = {14},
year = {1994}
}
@misc{VanderMeer2011a,
abstract = {Extensive evidence implicates the ventral striatum in multiple distinct facets of action selection. Early work established a role in modulating ongoing behavior, as engaged by the energizing and directing influences of motivationally relevant cues and the willingness to expend effort in order to obtain reward. More recently, reinforcement learning models have suggested the notion of ventral striatum primarily as an evaluation step during learning, which serves as a critic to update a separate actor. Recent computational and experimental work may provide a resolution to the differences between these two theories through a careful parsing of behavior and the instrinsic heterogeneity that characterizes this complex structure. {\textcopyright} 2011 Elsevier Ltd.},
author = {van der Meer, Matthijs A A and Redish, A. David},
booktitle = {Current Opinion in Neurobiology},
doi = {10.1016/j.conb.2011.02.011},
isbn = {1873-6882 (Electronic)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
pages = {387--392},
pmid = {21420853},
title = {{Ventral striatum: A critical look at models of learning and evaluation}},
volume = {21},
year = {2011}
}
@article{Rigotti2013,
abstract = {Single-neuron activity in the prefrontal cortex (PFC) is tuned to mixtures of multiple task-related aspects. Such mixed selectivity is highly heterogeneous, seemingly disordered and therefore difficult to interpret. We analysed the neural activity recorded in monkeys during an object sequence memory task to identify a role of mixed selectivity in subserving the cognitive functions ascribed to the PFC. We show that mixed selectivity neurons encode distributed information about all task-relevant aspects. Each aspect can be decoded from the population of neurons even when single-cell selectivity to that aspect is eliminated. Moreover, mixed selectivity offers a significant computational advantage over specialized responses in terms of the repertoire of input-output functions implementable by readout neurons. This advantage originates from the highly diverse nonlinear selectivity to mixtures of task-relevant variables, a signature of high-dimensional neural representations. Crucially, this dimensionality is predictive of animal behaviour as it collapses in error trials. Our findings recommend a shift of focus for future studies from neurons that have easily interpretable response tuning to the widely observed, but rarely analysed, mixed selectivity neurons.},
author = {Rigotti, Mattia and Barak, Omri and Warden, Melissa R and Wang, Xiao-Jing and Daw, Nathaniel D and Miller, Earl K and Fusi, Stefano},
doi = {10.1038/nature12160},
issn = {1476-4687},
journal = {Nature},
month = {may},
number = {7451},
pages = {585--90},
pmid = {23685452},
publisher = {NIH Public Access},
title = {{The importance of mixed selectivity in complex cognitive tasks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23685452 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4412347},
volume = {497},
year = {2013}
}
@article{Wyvell2000,
abstract = {Amphetamine microinjection into the nucleus accumbens shell enhanced the ability of a Pavlovian reward cue to trigger increased instrumental performance for sucrose reward in a pure conditioned incentive paradigm. Rats were first trained to press one of two levers to obtain sucrose pellets. They were separately conditioned to associate a Pavlovian cue (30 sec light) with free sucrose pellets. On test days, the rats received bilateral microinjection of intra-accumbens vehicle or amphetamine (0.0, 2.0, 10.0, or 20.0 microgram/0.5 microliter), and lever pressing was tested in the absence of any reinforcement contingency, while the Pavlovian cue alone was freely presented at intervals throughout the session. Amphetamine microinjection selectively potentiated the cue-elicited increase in sucrose-associated lever pressing, although instrumental responding was not reinforced by either sucrose or the cue during the test. Intra-accumbens amphetamine can therefore potentiate cue-triggered incentive motivation for reward in the absence of primary or secondary reinforcement. Using the taste reactivity measure of hedonic impact, it was shown that intra-accumbens amphetamine failed to increase positive hedonic reaction patterns elicited by sucrose (i.e., sucrose "liking") at doses that effectively increase sucrose "wanting." We conclude that nucleus accumbens dopamine specifically mediates the ability of reward cues to trigger "wanting" (incentive salience) for their associated rewards, independent of both hedonic impact and response reinforcement.},
author = {Wyvell, C L and Berridge, K C},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wyvell, Berridge - 2000 - Intra-accumbens amphetamine increases the conditioned incentive salience of sucrose reward enhancement of rewa.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {nov},
number = {21},
pages = {8122--30},
pmid = {11050134},
publisher = {Society for Neuroscience},
title = {{Intra-accumbens amphetamine increases the conditioned incentive salience of sucrose reward: enhancement of reward "wanting" without enhanced "liking" or response reinforcement.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11050134},
volume = {20},
year = {2000}
}
@article{ODoherty2012,
author = {O'Doherty, John P.},
doi = {10.1111/j.1460-9568.2012.08074.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Doherty - 2012 - Beyond simple reinforcement learning the computational neurobiology of reward-learning and valuation.pdf:pdf},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {basal ganglia,computational neuroscience,conditioning,decision‐making,prefrontal cortex},
month = {apr},
number = {7},
pages = {987--990},
publisher = {Blackwell Publishing Ltd},
title = {{Beyond simple reinforcement learning: the computational neurobiology of reward-learning and valuation}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2012.08074.x},
volume = {35},
year = {2012}
}
@article{Berridge2012a,
author = {Berridge, Kent C.},
doi = {10.1111/j.1460-9568.2012.07990.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berridge - 2012 - From prediction error to incentive salience mesolimbic computation of reward motivation.pdf:pdf},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {dopamine,incentive salience,learning,mesolimbic,nucleus accumbens,prediction error},
month = {apr},
number = {7},
pages = {1124--1143},
publisher = {Blackwell Publishing Ltd},
title = {{From prediction error to incentive salience: mesolimbic computation of reward motivation}},
url = {http://doi.wiley.com/10.1111/j.1460-9568.2012.07990.x},
volume = {35},
year = {2012}
}
@article{Roesch2009,
abstract = {The ventral striatum (VS) is thought to serve as a gateway whereby associative information from the amygdala and prefrontal regions can influence motor output to guide behavior. If VS mediates this "limbic-motor" interface, then one might expect neural correlates in VS to reflect this information. Specifically, neural activity should reflect the integration of motivational value with subsequent behavior. To test this prediction, we recorded from single units in VS while rats performed a choice task in which different odor cues indicated that reward was available on the left or on the right. The value of reward associated with a left or rightward movement was manipulated in separate blocks of trials by either varying the delay preceding reward delivery or by changing reward size. Rats' behavior was influenced by the value of the expected reward and the response required to obtain it, and activity in the majority of cue-responsive VS neurons reflected the integration of these two variables. Unlike similar cue-evoked activity reported previously in dopamine neurons, these correlates were only observed if the directional response was subsequently executed. Furthermore, activity was correlated with the speed at which the rats' executed the response. These results are consistent with the notion that VS serves to integrate information about the value of an expected reward with motor output during decision making.},
author = {Roesch, Matthew R and Singh, Teghpal and Brown, P Leon and Mullins, Sylvina E and Schoenbaum, Geoffrey},
doi = {10.1523/JNEUROSCI.2572-09.2009},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
pages = {13365--13376},
pmid = {19846724},
title = {{Ventral striatal neurons encode the value of the chosen action in rats deciding between differently delayed or sized rewards.}},
volume = {29},
year = {2009}
}
@article{Bowman1996,
abstract = {1. The results of neuropsychological, neuropharmacological, and neurophysiological experiments have implicated the ventral striatum in reward-related processes. We designed a task to allow us to separate the effects of sensory, motor, and internal signals so that we could study the correlation between the activity of neurons in the ventral striatum and different motivational states. In this task, a visual stimulus was used to cue the monkeys as to their progress toward earning a reward. The monkeys performed more quickly and with fewer mistakes in the rewarded trials. After analyzing the behavioral results from three monkeys, we recorded from 143 neurons from two of the monkeys while they performed the task with either juice or cocaine reward. 2. In this task the monkey was required to release its grip on a bar when a small visual response cue changed colors from red (the wait signal) to green (the go signal). The duration of the wait signal was varied randomly. The cue became blue whenever the monkey successfully responded to the go signal within 1 s of its appearance. A reward was delivered after the monkey successfully completed one, two, or three trials. The schedules were randomly interleaved. A second visual stimulus that progressively brightened or dimmed signaled to the monkeys their progress toward earning a reward. This discriminative cue allowed the monkeys to judge the proportion of work remaining in the current ratio schedule of reinforcement. Data were collected from three monkeys while they performed this task. 3. The average reaction times became faster and error rates declined as the monkeys progressed toward completing the current schedule of reinforcement and thereby earning a reward, whereas the modal reaction time did not change. As the duration of the wait period before the go signal increased, the monkeys reacted more quickly but their error rates scarcely changed. From these results we infer that the effects of motivation and motor readiness in this task are generated by separate mechanisms rather than by a single mechanism subserving generalized arousal. 4. The activity of 138 ventral striatal neurons was sampled in two monkeys while they performed the task to earn juice reward. We saw tonic changes in activity throughout the trials, and we saw phasic activity following the reward. The activity of these neurons was markedly different during juice-rewarded trials than during correctly performed trials when no reward was forthcoming (or expected). The responses also were weakly, but significantly, related to the proximity of the reward in the schedules requiring more than one trial. 5. The monkeys worked to obtain intravenous cocaine while we recorded 62 neurons. For 57 of the neurons, we recorded activity while the monkeys worked in blocks of trials during which they self-administered cocaine after blocks during which they worked for juice. Although fewer neurons responded to cocaine than to juice reward (19 vs. 33{\%}), this difference was not significant. The neuronal response properties to cocaine and juice rewards were independent; that is, the responses when one was the reward one failed to predict the response when the other was the reward. In addition, the neuronal activity lost most of its selectivity for rewarded trials, i.e, the activity did not distinguish nearly as well between cocaine and sham rewards as between juice and sham rewards. 6. Our results show that mechanisms by which cocaine acts do not appear to be the same as the ones activated when the monkeys were presented with an oral juice reward. This finding raises the intriguing possibility that the effects of cocaine could be reduced selectively without blocking the effects of many natural rewards.},
author = {Bowman, E M and Aigner, T G and Richmond, B J},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowman, Aigner, Richmond - 1996 - Neural signals in the monkey ventral striatum related to motivation for juice and cocaine rewards.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
month = {mar},
number = {3},
pages = {1061--73},
pmid = {8867118},
publisher = {American Physiological Society},
title = {{Neural signals in the monkey ventral striatum related to motivation for juice and cocaine rewards.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8867118},
volume = {75},
year = {1996}
}
@article{Alvarez2016,
author = {Alvarez, Veronica A},
doi = {10.1073/pnas.1601162113},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alvarez - 2016 - Clues on the coding of reward cues by the nucleus accumbens.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {mar},
number = {10},
pages = {2560--2},
pmid = {26917689},
publisher = {National Academy of Sciences},
title = {{Clues on the coding of reward cues by the nucleus accumbens.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26917689 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4791018},
volume = {113},
year = {2016}
}
@article{Hyman2006,
abstract = {AbstractAddiction is a state of compulsive drug use; despite treatment and other attempts to control drug taking, addiction tends to persist. Clinical and laboratory observations have converged on the hypothesis that addiction represents the pathological usurpation of neural processes that normally serve reward-related learning. The major substrates of persistent compulsive drug use are hypothesized to be molecular and cellular mechanisms that underlie long-term associative memories in several forebrain circuits (involving the ventral and dorsal striatum and prefrontal cortex) that receive input from midbrain dopamine neurons. Here we review progress in identifying candidate mechanisms of addiction.},
author = {Hyman, Steven E. and Malenka, Robert C. and Nestler, Eric J.},
doi = {10.1146/annurev.neuro.29.051605.113009},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {associative memory,dependence,dopamine,drug,plasticity,reward},
month = {jul},
number = {1},
pages = {565--598},
publisher = {Annual Reviews},
title = {{NEURAL MECHANISMS OF ADDICTION: The Role of Reward-Related Learning and Memory}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.neuro.29.051605.113009},
volume = {29},
year = {2006}
}
@article{Floresco1997,
abstract = {The hippocampus, the prefrontal cortex, and the ventral striatum form interconnected neural circuits that may underlie aspects of spatial cognition and memory. In the present series of experiments, we investigated functional interactions between these areas in rats during the performance of delayed and nondelayed spatially cued radial-arm maze tasks. The two-phase delayed task consisted of a training phase that provided rats with information about where food would be located on the maze 30 min later during a test phase. The single-phase nondelayed task was identical to the test phase of the delayed task, but in the absence of a training phase rats lacked previous knowledge of the location of food on the maze. Transient inactivation of the ventral CA1/subiculum (vSub) by a bilateral injection of lidocaine disrupted performance on both tasks. Lidocaine injections into the vSub on one side of the brain and the prefrontal cortex on the other transiently disconnected these two brain regions and significantly impaired foraging during the delayed task but not the nondelayed task. Transient disconnections between the vSub and the nucleus accumbens produced the opposite effect, disrupting foraging during the nondelayed task but not during the delayed task. These data suggest that serial transmission of information between the vSub and the prefrontal cortex is required when trial-unique, short-term memory is used to guide prospective search behavior. In contrast, exploratory goal-directed locomotion in a novel situation not requiring previously acquired information about the location of food is dependent on serial transmission between the hippocampus and the nucleus accumbens. These results indicate that different aspects of spatially mediated behavior are subserved by separate, distributed limbic-cortical-striatal networks.},
author = {Floresco, S B and Seamans, J K and Phillips, a G},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Floresco, Seamans, Phillips - 1997 - Selective roles for hippocampal, prefrontal cortical, and ventral striatal circuits in radial-arm m.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Afferent Pathways,Afferent Pathways: drug effects,Afferent Pathways: physiology,Anesthetics, Local,Anesthetics, Local: pharmacology,Animals,Corpus Striatum,Corpus Striatum: drug effects,Corpus Striatum: physiology,Hippocampus,Hippocampus: drug effects,Hippocampus: physiology,Lidocaine,Lidocaine: pharmacology,Male,Maze Learning,Maze Learning: drug effects,Maze Learning: physiology,Memory,Memory: physiology,Nerve Net,Nerve Net: physiology,Nucleus Accumbens,Nucleus Accumbens: drug effects,Nucleus Accumbens: physiology,Prefrontal Cortex,Prefrontal Cortex: drug effects,Prefrontal Cortex: physiology,Rats,Spatial Behavior,Time Factors},
month = {mar},
number = {5},
pages = {1880--90},
pmid = {9030646},
title = {{Selective roles for hippocampal, prefrontal cortical, and ventral striatal circuits in radial-arm maze tasks with or without a delay.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9030646},
volume = {17},
year = {1997}
}
@article{Cooch2015,
author = {Cooch, Nisha K. and Stalnaker, Thomas A. and Wied, Heather M. and Bali-Chaudhary, Sheena and McDannald, Michael A. and Liu, Tzu-Lan and Schoenbaum, Geoffrey},
doi = {10.1038/ncomms8195},
issn = {2041-1723},
journal = {Nature Communications},
month = {jun},
pages = {7195},
publisher = {Nature Publishing Group},
title = {{Orbitofrontal lesions eliminate signalling of biological significance in cue-responsive ventral striatal neurons}},
url = {http://www.nature.com/doifinder/10.1038/ncomms8195},
volume = {6},
year = {2015}
}
@article{Salamone2012,
abstract = {Nucleus accumbens dopamine is known to play a role in motivational processes, and dysfunctions of mesolimbic dopamine may contribute to motivational symptoms of depression and other disorders, as well as features of substance abuse. Although it has become traditional to label dopamine neurons as “reward” neurons, this is an overgeneralization, and it is important to distinguish between aspects of motivation that are differentially affected by dopaminergic manipulations. For example, accumbens dopamine does not mediate primary food motivation or appetite, but is involved in appetitive and aversive motivational processes including behavioral activation, exertion of effort, approach behavior, sustained task engagement, Pavlovian processes, and instrumental learning. In this review, we discuss the complex roles of dopamine in behavioral functions related to motivation.},
author = {Salamone, John D. and Correa, Merc{\`{e}}},
doi = {10.1016/J.NEURON.2012.10.021},
issn = {0896-6273},
journal = {Neuron},
month = {nov},
number = {3},
pages = {470--485},
publisher = {Cell Press},
title = {{The Mysterious Motivational Functions of Mesolimbic Dopamine}},
url = {http://www.sciencedirect.com/science/article/pii/S0896627312009415},
volume = {76},
year = {2012}
}
@article{VanderMeer2009,
abstract = {Local field potential (LFP) oscillations in the brain reflect organization thought to be important for perception, attention, movement, and memory. In the basal ganglia, including dorsal striatum, dysfunctional LFP states are associated with Parkinson's disease, while in healthy subjects, dorsal striatal LFPs have been linked to decision-making processes. However, LFPs in ventral striatum have been less studied. We report that in rats running a spatial decision task, prominent gamma-50 (45-55 Hz) and gamma-80 (70-85 Hz) oscillations in ventral striatum had distinct relationships to behavior, task events, and spiking activity. Gamma-50 power increased sharply following reward delivery and before movement initiation, while in contrast, gamma-80 power ramped up gradually to reward locations. Gamma-50 power was low and contained little structure during early learning, but rapidly developed a stable pattern, while gamma-80 power was initially high before returning to a stable level within a similar timeframe. Putative fast-spiking interneurons (FSIs) showed phase, firing rate, and coherence relationships with gamma-50 and gamma-80, indicating that the observed LFP patterns are locally relevant. Furthermore, in a number of FSIs such relationships were specific to gamma-50 or gamma-80, suggesting that partially distinct FSI populations mediate the effects of gamma-50 and gamma-80.},
author = {van der Meer, Matthijs A A and Redish, A David},
doi = {10.3389/neuro.07.009.2009},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van der Meer, Redish - 2009 - Low and High Gamma Oscillations in Rat Ventral Striatum have Distinct Relationships to Behavior, Reward, a.pdf:pdf},
isbn = {ISSN 1662-5145},
issn = {16625145},
journal = {Frontiers in integrative neuroscience},
pages = {9},
pmid = {19562092},
title = {{Low and High Gamma Oscillations in Rat Ventral Striatum have Distinct Relationships to Behavior, Reward, and Spiking Activity on a Learned Spatial Decision Task.}},
volume = {3},
year = {2009}
}
@article{Setlow2003,
abstract = {A growing body of evidence implicates the ventral striatum in using information acquired through associative learning. The present study examined the activity of ventral striatal neurons in awake, behaving rats during go/no-go odor discrimination learning and reversal. Many neurons fired selectively to odor cues predictive of either appetitive (sucrose) or aversive (quinine) outcomes. Few neurons were selective when first exposed to the odors, but many acquired this differential activity as rats learned the significance of the cues. A substantial proportion of these neurons encoded the cues' learned motivational significance, and these neurons tended to reverse their firing selectivity after reversal of odor-outcome contingencies. Other neurons that became selectively activated during learning did not reverse, but instead appeared to encode specific combinations of cues and associated motor responses. The results support a role for ventral striatum in using the learned significance, both appetitive and aversive, of predictive cues to guide behavior.},
author = {Setlow, Barry and Schoenbaum, Geoffrey and Gallagher, Michela},
issn = {0896-6273},
journal = {Neuron},
month = {may},
number = {4},
pages = {625--36},
pmid = {12765613},
title = {{Neural encoding in ventral striatum during olfactory discrimination learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12765613},
volume = {38},
year = {2003}
}
@article{Fitzgerald2014,
abstract = {Multiple features of the environment are often imbued with motivational significance, and the relative importance of these can change across contexts. The ability to flexibly adjust evaluative processes so that currently important features of the environment alone drive behavior is critical to adaptive routines. We know relatively little about the neural mechanisms involved, including whether motivationally significant features are obligatorily evaluated or whether current relevance gates access to value-sensitive regions. We addressed these questions using functional magnetic resonance imaging data and a task design where human subjects had to choose whether to accept or reject an offer indicated by visual and auditory stimuli. By manipulating, on a trial-by-trial basis, which stimulus determined the value of the offer, we show choice activity in the ventral striatum solely reflects the value of the currently relevant stimulus, consistent with a model wherein behavioral relevance modulates the impact of sensory stimuli on value processing. Choice outcome signals in this same region covaried positively with wins on accept trials, and negatively with wins on reject trials, consistent with striatal activity at feedback reflecting correctness of response rather than reward processing per se. We conclude that ventral striatum activity during decision making is dynamically modulated by behavioral context, indexed here by task relevance and action selection.},
author = {Fitzgerald, Thomas H B and Schwartenbeck, Philipp and Dolan, Raymond J},
doi = {10.1523/JNEUROSCI.4389-13.2014},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {action value,multisensory,policy selection,reward,ventral striatum},
pages = {1271--9},
pmid = {24453318},
title = {{Reward-related activity in ventral striatum is action contingent and modulated by behavioral relevance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24453318},
volume = {34},
year = {2014}
}
@article{Cheer2007,
abstract = {Intracranial self-stimulation (ICSS) activates the neural pathways that mediate reward, including dopaminergic terminal areas such as the nucleus accumbens (NAc). However, a direct role of dopamine in ICSS-mediated reward has been questioned. Here, simultaneous voltammetric and electrophysiological recordings from the same electrode reveal that, at certain sites, the onset of anticipatory dopamine surges and changes in neuronal firing patterns during ICSS are coincident, whereas sites lacking dopamine changes also lack patterned firing. Intrashell microinfusion of a D1, but not a D2 receptor antagonist, blocks ICSS. An iontophoresis approach was implemented to explore the effect of dopamine antagonists on firing patterns without altering behavior. Similar to the microinfusion experiments, ICSS-related firing is selectively attenuated following D1 receptor blockade. This work establishes a temporal link between anticipatory rises of dopamine and firing patterns in the NAc shell during ICSS and suggests that they may play a similar role with natural rewards and during drug self-administration.},
author = {Cheer, Joseph F and Aragona, Brandon J and Heien, Michael L A V and Seipel, Andrew T and Carelli, Regina M and Wightman, R Mark},
doi = {10.1016/j.neuron.2007.03.021},
issn = {0896-6273},
journal = {Neuron},
keywords = {HUMDISEASE,SYSNEURO},
month = {apr},
number = {2},
pages = {237--44},
pmid = {17442245},
publisher = {Elsevier},
title = {{Coordinated accumbal dopamine release and neural activity drive goal-directed behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17442245},
volume = {54},
year = {2007}
}
@article{ChiYiuYim1982,
author = {{Chi Yiu Yim} and Mogenson, Gordon J.},
doi = {10.1016/0006-8993(82)90518-2},
issn = {00068993},
journal = {Brain Research},
month = {may},
number = {2},
pages = {401--415},
title = {{Response of nucleus accumbens neurons to amygdala stimulation and its modification by dopamine}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0006899382905182},
volume = {239},
year = {1982}
}
@article{Chang2012a,
abstract = {Initially-neutral cues paired with rewards are thought to acquire motivational significance, as if the incentive motivational value of the reward is transferred to the cue. Such cues may serve as secondary reinforcers to establish new learning, modulate the performance of instrumental action (Pavlovian-instrumental transfer, PIT), and be the targets of approach and other cue-directed behaviors. Here we examined the effects of lesions of the ventral striatal nucleus accumbens (ACb) and the basolateral amygdala (BLA) on the acquisition of discriminative autoshaped lever-pressing in rats. Insertion of one lever into the experimental chamber was reinforced by sucrose delivery, but insertion of another lever was not reinforced. Although sucrose was delivered independently of the rats' behavior, sham-lesioned rats rapidly came to press the reinforced but not the nonreinforced lever. Bilateral ACb lesions impaired the initial acquisition of sign-tracking but not its terminal levels. In contrast, BLA lesions produced substantial deficits in terminal levels of sign-tracking. Furthermore, whereas ACb lesions primarily affected the probability of lever press responses, BLA lesions mostly affected the rate of responding once it occurred. Finally, disconnection lesions that disrupted communication between ACb and BLA produced both sets of deficits. We suggest that ACb is important for initial acquisition of consummatory-like responses that incorporate hedonic aspects of the reward, while BLA serves to enhance such incentive salience once it is acquired.},
author = {Chang, Stephen E. and Wheeler, Daniel S. and Holland, Peter C.},
doi = {10.1016/j.nlm.2012.03.008},
issn = {10747427},
journal = {Neurobiology of Learning and Memory},
month = {may},
number = {4},
pages = {441--451},
pmid = {22469749},
title = {{Roles of nucleus accumbens and basolateral amygdala in autoshaped lever pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22469749 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3358568 http://linkinghub.elsevier.com/retrieve/pii/S107474271200038X},
volume = {97},
year = {2012}
}
@article{Syed2015,
author = {Syed, Emilie C J and Grima, Laura L and Magill, Peter J and Bogacz, Rafal and Brown, Peter and Walton, Mark E},
doi = {10.1038/nn.4187},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {dec},
number = {1},
pages = {34--36},
publisher = {Nature Research},
title = {{Action initiation shapes mesolimbic dopamine encoding of future rewards}},
url = {http://www.nature.com/doifinder/10.1038/nn.4187},
volume = {19},
year = {2015}
}
@article{Schultz1993,
author = {Schultz, Wolfram and Apicella, Paul and Ljungbergb, Tomas},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schultz, Apicella, Ljungbergb - 1993 - Responses of Monkey Dopamine Neurons to Reward and Conditioned Stimuli during Successive Steps of.pdf:pdf},
journal = {The Journal of Neuroscience},
number = {3},
pages = {900--913},
title = {{Responses of Monkey Dopamine Neurons to Reward and Conditioned Stimuli during Successive Steps of Learning a Delayed Response Task}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.318.4927{\&}rep=rep1{\&}type=pdf},
volume = {13},
year = {1993}
}
@article{Carelli2004,
abstract = {An understanding of the neurobiological basis of drug addiction requires examination of real-time (subsecond) cellular and chemical responses in the brain reward system during drug-seeking and drug-taking behavior. Electrophysiological and electrochemical studies in the rodent nucleus accumbens have examined changes in cell firing and rapid dopamine signaling during crucial periods of behavioral responding for drugs, and show the associative nature of those signals. These findings are considered with respect to the functional microcircuitry in the nucleus accumbens that underlies goal-directed behavior and the role of this circuit in drug addiction.},
author = {Carelli, Regina M and Wightman, R Mark},
doi = {10.1016/J.CONB.2004.10.001},
issn = {0959-4388},
journal = {Current Opinion in Neurobiology},
month = {dec},
number = {6},
pages = {763--768},
publisher = {Elsevier Current Trends},
title = {{Functional microcircuitry in the accumbens underlying drug addiction: insights from real-time signaling during behavior}},
url = {http://www.sciencedirect.com/science/article/pii/S0959438804001539},
volume = {14},
year = {2004}
}
@article{Stuber2011,
abstract = {The basolateral amygdala (BLA) has a crucial role in emotional learning irrespective of valence 1–5,21–23 . The BLA projection to the nucleus accumbens (NAc) is thought to modulate cue-triggered motivated behaviours 4,6,7,24,25 , but our understanding of the inter-action between these two brain regions has been limited by the inability to manipulate neural-circuit elements of this pathway selectively during behaviour. To circumvent this limitation, we used in vivo optogenetic stimulation or inhibition of glutamatergic fibres from the BLA to the NAc, coupled with intracranial phar-macology and ex vivo electrophysiology. Here we show that optical stimulation of the pathway from the BLA to the NAc in mice reinforces behavioural responding to earn additional optical stimulation of these synaptic inputs. Optical stimulation of these glutamatergic fibres required intra-NAc dopamine D1-type recep-tor signalling, but not D2-type receptor signalling. Brief optical inhibition of fibres from the BLA to the NAc reduced cue-evoked intake of sucrose, demonstrating an important role of this specific pathway in controlling naturally occurring reward-related beha-viour. Moreover, although optical stimulation of glutamatergic fibres from the medial prefrontal cortex to the NAc also elicited reliable excitatory synaptic responses, optical self-stimulation behaviour was not observed by activation of this pathway. These data indicate that whereas the BLA is important for processing both positive and negative affect, the glutamatergic pathway from the BLA to the NAc, in conjunction with dopamine signalling in the NAc, promotes motivated behavioural responding. Thus, opto-genetic manipulation of anatomically distinct synaptic inputs to the NAc reveals functionally distinct properties of these inputs in controlling reward-seeking behaviours. To stimulate excitatory fibres projecting from the BLA to the NAc selectively, we stereotaxically delivered adeno-associated viral vectors carrying the codon-optimized channelrhodopsin-2 gene fused in-frame to enhanced yellow fluorescent protein (ChR2–EYFP) 8 , driven by the Camk2a promoter, to transduce glutamatergic neurons locally in the BLA. Expression of ChR2–EYFP was observed after transduc-tion of neurons in the BLA (Fig. 1a). Whole-cell recordings from visually identified BLA pyramidal neurons expressing ChR2 showed that light stimulation frequencies (1–20 Hz, 5-ms light pulses) resulted in reliable firing in response to light, with minimal loss of spike fidelity at 20 Hz (Fig. 1b and Supplementary Fig. 1). This indicated that optic-ally induced firing via activation of ChR2 can excite BLA neurons at physiologically relevant frequencies 5,6},
author = {Stuber, Garret D and Sparta, Dennis R and Stamatakis, Alice M and {Van Leeuwen}, Wieke A and Hardjoprajitno, Juanita E and Cho, Saemi and Tye, Kay M and Kempadoo, Kimberly A and Zhang, Feng and Deisseroth, Karl and Bonci, Antonello},
doi = {10.1038/nature10194},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stuber et al. - 2011 - Excitatory transmission from the amygdala to nucleus accumbens facilitates reward seeking.pdf:pdf},
journal = {Nature},
title = {{Excitatory transmission from the amygdala to nucleus accumbens facilitates reward seeking}},
url = {http://www.nature.com/nature/journal/v475/n7356/pdf/nature10194.pdf},
volume = {475},
year = {2011}
}
@article{Rescorla1967,
author = {Rescorla, Robert A. and Solomon, Richard L.},
doi = {10.1037/h0024475},
issn = {1939-1471},
journal = {Psychological Review},
number = {3},
pages = {151--182},
title = {{Two-process learning theory: Relationships between Pavlovian conditioning and instrumental learning.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0024475},
volume = {74},
year = {1967}
}
@article{Floresco2015,
abstract = {Nearly 40 years of research on the function of the nucleus accumbens (NAc) has provided a wealth of information on its contributions to behavior but has also yielded controversies and misconceptions regarding these functions. A primary tenet of this review is that, rather than serving as a “reward” center, the NAc plays a key role in action selection, integrating cognitive and affective information processed by frontal and temporal lobe regions to augment the efficiency and vigor of appetitively or aversively motivated behaviors. Its involvement in these functions is most prominent when the appropriate course of action is ambiguous, uncertain, laden with distractors, or in a state of flux. To this end, different subregions of the NAc play dissociable roles in refining action selection, promoting approach toward motivationally relevant stimuli, suppressing inappropriate actions so that goals may be obtained more efficiently, and encoding action outcomes that guide the direction of subsequent ones.},
author = {Floresco, Stan B.},
doi = {10.1146/annurev-psych-010213-115159},
issn = {0066-4308},
journal = {Annual Review of Psychology},
keywords = {action selection,animal models,dopamine,fMRI,ventral striatum},
month = {jan},
number = {1},
pages = {25--52},
publisher = { Annual Reviews },
title = {{The Nucleus Accumbens: An Interface Between Cognition, Emotion, and Action}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-psych-010213-115159},
volume = {66},
year = {2015}
}
@article{Ito2015,
author = {Ito, Makoto and Doya, Kenji and Knowlton, BJ and Balleine, BW and Pennartz, CM},
doi = {10.1371/journal.pcbi.1004540},
editor = {Sporns, Olaf},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ito et al. - 2015 - Parallel Representation of Value-Based and Finite State-Based Strategies in the Ventral and Dorsal Striatum.pdf:pdf},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {nov},
number = {11},
pages = {e1004540},
publisher = {Public Library of Science},
title = {{Parallel Representation of Value-Based and Finite State-Based Strategies in the Ventral and Dorsal Striatum}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1004540},
volume = {11},
year = {2015}
}
@article{Stefani2006,
abstract = {The midbrain dopamine system has been ascribed roles in reward expectancy, error detection, prediction, and memory. However, these theories typically do not differentiate between dopamine response and action in different forebrain terminal fields. We measured dopamine release in the prefrontal cortex (PFC), nucleus accumbens (NAc), and dorsal striatum (DS) of rats exposed to the same maze apparatus under three behavioral conditions: a set-shift task in which reward depended on discrimination learning and extradimensional set-shifting, a yoked condition in which reward was intermittent and not under the control of the subject, and a "reward-retrieval" variant in which reward was certain on every trial. We found dissociable patterns of dopamine release associated with learning, uncertainty, and reward. Dopamine increased in all three regions when reward was contingent on rule learning and shifting or was uncertain. These increases were sustained after behavior. There was a significant correlation between the magnitude of increase in PFC dopamine and the rapidity with which rats shifted between discrimination rules. In the yoke condition, in which the receipt of reward was always uncertain, the opposite relationship between dopamine levels and likelihood of reward was observed. Predictable, noncontingent reward was associated with increased dopamine levels in the NAc and DS. In contrast, PFC dopamine did not increase significantly above baseline levels. Thus, the dopaminergic projections to the PFC and nucleus accumbens were selectively, yet differentially, activated in situations of uncertainty and cognitive demand, whereas the dopaminergic projection to the DS responded independently of task differences in learning and reward.},
author = {Stefani, Mark R and Moghaddam, Bita},
doi = {10.1523/JNEUROSCI.1656-06.2006},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stefani, Moghaddam - 2006 - Rule learning and reward contingency are associated with dissociable patterns of dopamine activation in the.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {aug},
number = {34},
pages = {8810--8},
pmid = {16928870},
publisher = {Society for Neuroscience},
title = {{Rule learning and reward contingency are associated with dissociable patterns of dopamine activation in the rat prefrontal cortex, nucleus accumbens, and dorsal striatum.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16928870 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2954608},
volume = {26},
year = {2006}
}
@article{Koob2010,
abstract = {Neurocircuitry of Addiction},
author = {Koob, George F and Volkow, Nora D},
doi = {10.1038/npp.2009.110},
issn = {0893-133X},
journal = {Neuropsychopharmacology},
month = {jan},
number = {1},
pages = {217--238},
publisher = {Nature Publishing Group},
title = {{Neurocircuitry of Addiction}},
url = {http://www.nature.com/articles/npp2009110},
volume = {35},
year = {2010}
}
@misc{Humphries2010,
abstract = {The basal ganglia are often conceptualised as three parallel domains that include all the constituent nuclei. The 'ventral domain' appears to be critical for learning flexible behaviours for exploration and foraging, as it is the recipient of converging inputs from amygdala, hippocampal formation and prefrontal cortex, putatively centres for stimulus evaluation, spatial navigation, and planning/contingency, respectively. However, compared to work on the dorsal domains, the rich potential for quantitative theories and models of the ventral domain remains largely untapped, and the purpose of this review is to provide the stimulus for this work. We systematically review the ventral domain's structures and internal organisation, and propose a functional architecture as the basis for computational models. Using a full schematic of the structure of inputs to the ventral striatum (nucleus accumbens core and shell), we argue for the existence of many identifiable processing channels on the basis of unique combinations of afferent inputs. We then identify the potential information represented in these channels by reconciling a broad range of studies from the hippocampal, amygdala and prefrontal cortex literatures with known properties of the ventral striatum from lesion, pharmacological, and electrophysiological studies. Dopamine's key role in learning is reviewed within the three current major computational frameworks; we also show that the shell-based basal ganglia sub-circuits are well placed to generate the phasic burst and dip responses of dopaminergic neurons. We detail dopamine's modulation of ventral basal ganglia's inputs by its actions on pre-synaptic terminals and post-synaptic membranes in the striatum, arguing that the complexity of these effects hint at computational roles for dopamine beyond current ideas. The ventral basal ganglia are revealed as a constellation of multiple functional systems for the learning and selection of flexible behaviours and of behavioural strategies, sharing the common operations of selection-by-disinhibition and of dopaminergic modulation. ?? 2009 Elsevier Ltd.},
author = {Humphries, Mark D. and Prescott, Tony J.},
booktitle = {Progress in Neurobiology},
doi = {10.1016/j.pneurobio.2009.11.003},
isbn = {1873-5118 (Electronic)$\backslash$n0301-0082 (Linking)},
issn = {03010082},
keywords = {Action selection,Core,Incentive salience,Nucleus accumbens,Reward prediction error,Shell,Spatial navigation},
pages = {385--417},
pmid = {19941931},
title = {{The ventral basal ganglia, a selection mechanism at the crossroads of space, strategy, and reward}},
volume = {90},
year = {2010}
}
@article{Day2007a,
abstract = {The ability to predict favorable outcomes using environmental cues is an essential part of learned behavior. Dopamine neurons in the midbrain encode such stimulus-reward relationships in a manner consistent with contemporary learning models, but it is unclear how encoding this translates into actual dopamine release in target regions. Here, we sampled dopamine levels in the rat nucleus accumbens on a rapid (100 ms) timescale using electrochemical technology during a classical conditioning procedure. Early in conditioning, transient dopamine-release events signaled a primary reward, but not predictive cues. After repeated cue-reward pairings, dopamine signals shifted in time to predictive cue onset and were no longer observed at reward delivery. In the absence of stimulus-reward conditioning, there was no shift in the dopamine signal. Consistent with proposed roles in reward prediction and incentive salience, these results indicate that rapid dopamine release provides a reward signal that is dynamically modified by associative learning.},
author = {Day, Jeremy J and Roitman, Mitchell F and Wightman, R Mark and Carelli, Regina M},
doi = {10.1038/nn1923},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Day et al. - Unknown - Associative learning mediates dynamic shifts in dopamine signaling in the nucleus accumbens.pdf:pdf},
isbn = {1097-6256 (Print)},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {8},
pages = {1020--1028},
pmid = {17603481},
title = {{Associative learning mediates dynamic shifts in dopamine signaling in the nucleus accumbens}},
url = {http://www.nature.com/neuro/journal/v10/n8/pdf/nn1923.pdf},
volume = {10},
year = {2007}
}
@article{Ikemoto2007a,
abstract = {Anatomical and functional refinements of the meso-limbic dopamine system of the rat are discussed. Present experiments suggest that dopaminergic neurons localized in the posteromedial ventral tegmental area (VTA) and central linear nucleus raphe selectively project to the ventromedial striatum (medial olfactory tubercle and medial nucleus accumbens shell), whereas the anteromedial VTA has few if any projections to the ventral striatum, and the lateral VTA largely projects to the ventrolateral striatum (accumbens core, lateral shell and lateral tubercle). These findings complement the recent behavioral findings that cocaine and amphetamine are more rewarding when administered into the ventromedial striatum than into the ventrolateral striatum. Drugs such as nicotine and opiates are more rewarding when administered into the posterior VTA or the central linear nucleus than into the anterior VTA. A review of the literature suggests that (1) the midbrain has corresponding zones for the accumbens core and medial shell; (2) the striatal portion of the olfactory tubercle is a ventral extension of the nucleus accumbens shell; and (3) a model of two dopamine projection systems from the ventral midbrain to the ventral striatum is useful for understanding reward function. The medial projection system is important in the regulation of arousal characterized by affect and drive and plays a different role in goal-directed learning than the lateral projection system, as described in the variation-selection hypothesis of striatal functional organization.},
author = {Ikemoto, Satoshi},
doi = {10.1016/j.brainresrev.2007.05.004},
issn = {01650173},
journal = {Brain Research Reviews},
month = {nov},
number = {1},
pages = {27--78},
pmid = {17574681},
title = {{Dopamine reward circuitry: Two projection systems from the ventral midbrain to the nucleus accumbens–olfactory tubercle complex}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17574681 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2134972 http://linkinghub.elsevier.com/retrieve/pii/S0165017307000756},
volume = {56},
year = {2007}
}
@article{Crone2005,
author = {Crone, E. A. and Wendelken, Carter and Donohue, Sarah E. and Bunge, Silvia A.},
doi = {10.1093/cercor/bhi127},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Crone et al. - 2005 - Neural Evidence for Dissociable Components of Task-switching.pdf:pdf},
issn = {1047-3211},
journal = {Cerebral Cortex},
keywords = {basal ganglia,brain,functional magnetic resonance imaging,mental processes,parietal lobe,prefrontal cortex,young adult},
month = {jun},
number = {4},
pages = {475--486},
publisher = {Oxford University Press},
title = {{Neural Evidence for Dissociable Components of Task-switching}},
url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhi127},
volume = {16},
year = {2005}
}
@article{VanderMeer2011,
abstract = {A functional interaction between the hippocampal formation and the ventral striatum is thought to contribute to the learning and expression of associations between places and rewards. However, the mechanism of how such associations may be learned and used is currently unknown. We recorded neural ensembles and local field potentials from the ventral striatum and CA1 simultaneously as rats ran a modified T-maze. Theta-modulated cells in ventral striatum almost invariably showed firing phase precession relative to the hippocampal theta rhythm. Across the population of ventral striatal cells, phase precession was preferentially associated with an anticipatory ramping of activity up to the reward sites. In contrast, CA1 population activity and phase precession were distributed more uniformly. Ventral striatal phase precession was stronger to hippocampal than ventral striatal theta and was accompanied by increased theta coherence with hippocampus, suggesting that this effect is hippocampally derived. These results suggest that the firing phase of ventral striatal neurons contains motivationally relevant information and that phase precession serves to bind hippocampal place representations to ventral striatal representations of reward.},
author = {van der Meer, Matthijs A A and Redish, A David},
doi = {10.1523/JNEUROSCI.4869-10.2011},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
pages = {2843--2854},
pmid = {21414906},
title = {{Theta phase precession in rat ventral striatum links place and reward information.}},
volume = {31},
year = {2011}
}
@article{Chang2012,
abstract = {Initially-neutral cues paired with rewards are thought to acquire motivational significance, as if the incentive motivational value of the reward is transferred to the cue. Such cues may serve as secondary reinforcers to establish new learning, modulate the performance of instrumental action (Pavlovian-instrumental transfer, PIT), and be the targets of approach and other cue-directed behaviors. Here we examined the effects of lesions of the ventral striatal nucleus accumbens (ACb) and the basolateral amygdala (BLA) on the acquisition of discriminative autoshaped lever-pressing in rats. Insertion of one lever into the experimental chamber was reinforced by sucrose delivery, but insertion of another lever was not reinforced. Although sucrose was delivered independently of the rats' behavior, sham-lesioned rats rapidly came to press the reinforced but not the nonreinforced lever. Bilateral ACb lesions impaired the initial acquisition of sign-tracking but not its terminal levels. In contrast, BLA lesions produced substantial deficits in terminal levels of sign-tracking. Furthermore, whereas ACb lesions primarily affected the probability of lever press responses, BLA lesions mostly affected the rate of responding once it occurred. Finally, disconnection lesions that disrupted communication between ACb and BLA produced both sets of deficits. We suggest that ACb is important for initial acquisition of consummatory-like responses that incorporate hedonic aspects of the reward, while BLA serves to enhance such incentive salience once it is acquired.},
author = {Chang, Stephen E. and Wheeler, Daniel S. and Holland, Peter C.},
doi = {10.1016/j.nlm.2012.03.008},
issn = {10747427},
journal = {Neurobiology of Learning and Memory},
month = {may},
number = {4},
pages = {441--451},
pmid = {22469749},
title = {{Roles of nucleus accumbens and basolateral amygdala in autoshaped lever pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22469749 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3358568 http://linkinghub.elsevier.com/retrieve/pii/S107474271200038X},
volume = {97},
year = {2012}
}
@article{DuHoffmann2014,
abstract = {Approach to reward is a fundamental adaptive behavior, disruption of which is a core symptom of addiction and depression. Nucleus accumbens (NAc) dopamine is required for reward-predictive cues to activate vigorous reward seeking, but the underlying neural mechanism is unknown. Reward-predictive cues elicit both dopamine release in the NAc and excitations and inhibitions in NAc neurons. However, a direct link has not been established between dopamine receptor activation, NAc cue-evoked neuronal activity, and reward-seeking behavior. Here, we use a novel microelectrode array that enables simultaneous recording of neuronal firing and local dopamine receptor antagonist injection. We demonstrate that, in the NAc of rats performing a discriminative stimulus task for sucrose reward, blockade of either D1 or D2 receptors selectively attenuates excitation, but not inhibition, evoked by reward-predictive cues. Furthermore, we establish that this dopamine-dependent signal is necessary for reward-seeking behavior. These results demonstrate a neural mechanism by which NAc dopamine invigorates environmentally cued reward-seeking behavior.},
author = {du Hoffmann, J. and Nicola, S. M.},
doi = {10.1523/JNEUROSCI.3492-14.2014},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {cue-excited neurons,discriminative stimulus,dopamine,nucleus accumbens,reward seeking},
month = {oct},
number = {43},
pages = {14349--14364},
pmid = {25339748},
title = {{Dopamine Invigorates Reward Seeking by Promoting Cue-Evoked Excitation in the Nucleus Accumbens}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25339748 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4205557 http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3492-14.2014},
volume = {34},
year = {2014}
}
@article{Wassum2009,
abstract = {It generally is assumed that a common neural substrate mediates both the palatability and the reward value of nutritive events. However, recent evidence suggests this assumption may not be true. Whereas opioid circuitry in both the nucleus accumbens and ventral pallidum has been reported to mediate taste-reactivity responses to palatable events, the assignment of reward or inventive value to goal-directed actions has been found to involve the basolateral amygdala. Here we found that, in rats, the neural processes mediating palatability and incentive value are indeed dissociable. Naloxone infused into either the ventral pallidum or nucleus accumbens shell blocked the increase in sucrose palatability induced by an increase in food deprivation without affecting the performance of sucrose-related actions. Conversely, naloxone infused into the basolateral amygdala blocked food deprivation-induced changes in sucrose-related actions without affecting sucrose palatability. This double dissociation of opioid-mediated changes in palatability and incentive value suggests that the role of endogenous opioids in reward processing does not depend on a single neural circuit. Rather, changes in palatability and in the incentive value assigned to rewarding events seem to be mediated by distinct neural processes.},
author = {Wassum, K M and Ostlund, S B and Maidment, N T and Balleine, B W},
doi = {10.1073/pnas.0905874106},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wassum et al. - 2009 - Distinct opioid circuits determine the palatability and the desirability of rewarding events.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {jul},
number = {30},
pages = {12512--7},
pmid = {19597155},
publisher = {National Academy of Sciences},
title = {{Distinct opioid circuits determine the palatability and the desirability of rewarding events.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19597155 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2718390},
volume = {106},
year = {2009}
}
@article{Joel2002,
abstract = {A large number of computational models of information processing in the basal ganglia have been developed in recent years. Prominent in these are actor–critic models of basal ganglia functioning, which build on the strong resemblance between dopamine neuron activity and the temporal difference prediction error signal in the critic, and between dopamine-dependent long-term synaptic plasticity in the striatum and learning guided by a prediction error signal in the actor. We selectively review several actor–critic models of the basal ganglia with an emphasis on two important aspects: the way in which models of the critic reproduce the temporal dynamics of dopamine firing, and the extent to which models of the actor take into account known basal ganglia anatomy and physiology. To complement the efforts to relate basal ganglia mechanisms to reinforcement learning (RL), we introduce an alternative approach to modeling a critic network, which uses Evolutionary Computation techniques to ‘evolve' an optimal RL mechanism, and relate the evolved mechanism to the basic model of the critic. We conclude our discussion of models of the critic by a critical discussion of the anatomical plausibility of implementations of a critic in basal ganglia circuitry, and conclude that such implementations build on assumptions that are inconsistent with the known anatomy of the basal ganglia. We return to the actor component of the actor–critic model, which is usually modeled at the striatal level with very little detail. We describe an alternative model of the basal ganglia which takes into account several important, and previously neglected, anatomical and physiological characteristics of basal ganglia–thalamocortical connectivity and suggests that the basal ganglia performs reinforcement-biased dimensionality reduction of cortical inputs. We further suggest that since such selective encoding may bias the representation at the level of the frontal cortex towards the selection of rewarded plans and actions, the reinforcement-driven dimensionality reduction framework may serve as a basis for basal ganglia actor models. We conclude with a short discussion of the dual role of the dopamine signal in RL and in behavioral switching.},
author = {Joel, Daphna and Niv, Yael and Ruppin, Eytan},
doi = {10.1016/S0893-6080(02)00047-3},
issn = {0893-6080},
journal = {Neural Networks},
month = {jun},
number = {4-6},
pages = {535--547},
publisher = {Pergamon},
title = {{Actor–critic models of the basal ganglia: new anatomical and computational perspectives}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608002000473},
volume = {15},
year = {2002}
}
@article{Hearst,
author = {Hearst, E. and Jenkins, H. M.},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text.pdf:pdf},
title = {full text}
}
@article{Steinberg2013,
abstract = {Situations in which rewards are unexpectedly obtained or withheld represent opportunities for new learning. Often, this learning includes identifying cues that predict reward availability. Unexpected rewards strongly activate midbrain dopamine neurons. This phasic signal is proposed to support learning about antecedent cues by signaling discrepancies between actual and expected outcomes, termed a reward prediction error. However, it is unknown whether dopamine neuron prediction error signaling and cue-reward learning are causally linked. To test this hypothesis, we manipulated dopamine neuron activity in rats in two behavioral procedures, associative blocking and extinction, that illustrate the essential function of prediction errors in learning. We observed that optogenetic activation of dopamine neurons concurrent with reward delivery, mimicking a prediction error, was sufficient to cause long-lasting increases in cue-elicited reward-seeking behavior. Our findings establish a causal role for temporally precise dopamine neuron signaling in cue-reward learning, bridging a critical gap between experimental evidence and influential theoretical frameworks.},
author = {Steinberg, Elizabeth E. and Keiflin, Ronald and Boivin, Josiah R. and Witten, Ilana B. and Deisseroth, Karl and Janak, Patricia H.},
doi = {10.1038/nn.3413},
isbn = {1546-1726},
issn = {1097-6256},
journal = {Nature Neuroscience},
pages = {966--973},
pmid = {23708143},
title = {{A causal link between prediction errors, dopamine neurons and learning}},
url = {http://www.nature.com/doifinder/10.1038/nn.3413},
volume = {16},
year = {2013}
}
@article{Floresco2006,
abstract = {The ability to behave in a flexible manner is an executive function mediated in part by different regions of the prefrontal cortex. The present study investigated the role of two major efferents of the prefrontal cortex, the nucleus accumbens (NAc) core and shell, in behavioral flexibility using a maze-based strategy set-shifting task. During initial discrimination training, rats learned to use either an egocentric response or a visual-cue discrimination strategy to obtain food reward. During the set shift, animals had to shift from the previously acquired response or visual-cue-based strategy and learn the alternate discrimination. Inactivation of the NAc core, induced by infusion of the GABA agonists baclofen and muscimol, did not impair initial acquisition of either a response or visual-cue discrimination but severely disrupted shifting from one strategy to another. Analysis of the type of errors revealed that impairments in set shifting were not attributable to increased perseveration but to a disruption of the acquisition and maintenance of a new strategy. In contrast, inactivation of the NAc shell did not impair acquisition of either a response or a visual-cue discrimination, or shifting from one strategy to another. However, inactivation of the NAc shell before initial discrimination training improved performance during the set shift relative to control animals. These data indicate that the NAc core and shell make dissociable contributions to behavioral flexibility during set shifting. The NAc core facilitates the acquisition and maintenance of novel behavioral strategies and elimination of inappropriate response options, whereas the shell may mediate learning about irrelevant stimuli.},
author = {Floresco, Stan B and Ghods-Sharifi, Sarvin and Vexelman, Claudia and Magyar, Orsolya},
doi = {10.1523/JNEUROSCI.4431-05.2006},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weiner et al. - 1996 - Differential involvement of the shell and core subterritories of the nucleus accumbens in latent inhibition and a.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Analysis of Variance,Animals,Appetitive Behavior,Appetitive Behavior: physiology,Baclofen,Baclofen: pharmacology,Behavior, Animal,Conditioning, Operant,Conditioning, Operant: drug effects,Conditioning, Operant: physiology,Discrimination Learning,Discrimination Learning: drug effects,Discrimination Learning: physiology,Extinction, Psychological,Extinction, Psychological: drug effects,GABA Agonists,GABA Agonists: pharmacology,Maze Learning,Maze Learning: drug effects,Maze Learning: physiology,Muscimol,Muscimol: pharmacology,Nucleus Accumbens,Nucleus Accumbens: anatomy {\&} histology,Nucleus Accumbens: drug effects,Nucleus Accumbens: physiology,Photic Stimulation,Photic Stimulation: methods,Rats,Rats, Long-Evans,Set (Psychology),Time Factors},
month = {mar},
number = {9},
pages = {2449--57},
pmid = {16510723},
title = {{Dissociable roles for the nucleus accumbens core and shell in regulating set shifting.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16510723},
volume = {26},
year = {2006}
}
@article{Mannella2013,
abstract = {Goal-directed behaviour is a fundamental means by which animals can flexibly solve the challenges posed by variable external and internal conditions. Recently, the processes and brain mechanisms underlying such behaviour have been extensively studied from behavioural, neuroscientific and computational perspectives. This research has highlighted the processes underlying goal-directed behaviour and associated brain systems including prefrontal cortex, basal ganglia and, in particular therein, the nucleus accumbens. This paper focusses on one particular process at the core of goal-directed behaviour: how motivational value is assigned to goals on the basis of internal states and environmental stimuli, and how this supports goal selection processes. Various biological and computational accounts have been given of this problem and of related multiple neural and behaviour phenomena, but we still lack an integrated hypothesis on the generation and use of value for goal selection. This paper proposes an hypothesis that aims to solve this problem and is based on this key elements: (a) amygdala and hippocampus establish the motivational value of stimuli and goals; (b) prefrontal cortex encodes various types of action outcomes; (c) nucleus accumbens integrates different sources of value, representing them in terms of a common currency with the aid of dopamine, and thereby plays a major role in selecting action outcomes within prefrontal cortex. The ‘goals' pursued by the organism are the outcomes selected by these processes. The hypothesis is developed in the context of a critical review of relevant biological and computational literature which offer it support. The paper shows how the hypothesis has the potential to integrate existing interpretations of motivational value and goal selection.},
author = {Mannella, Francesco and Gurney, Kevin and Baldassarre, Gianluca},
doi = {10.3389/fnbeh.2013.00135},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mannella, Gurney, Baldassarre - 2013 - The nucleus accumbens as a nexus between values and goals in goal-directed behavior a review and.pdf:pdf},
issn = {1662-5153},
journal = {Frontiers in Behavioral Neuroscience},
keywords = {amygdala (amg),appetitive and novelty  value,bio-behavioural and computational perspectives,goal selection,hippocampus (Hip),nucleus accumbens (NAcc),prefrontal cortex (PFC)},
pages = {135},
publisher = {Frontiers},
title = {{The nucleus accumbens as a nexus between values and goals in goal-directed behavior: a review and a new hypothesis}},
url = {http://journal.frontiersin.org/article/10.3389/fnbeh.2013.00135/abstract},
volume = {7},
year = {2013}
}
@article{Goto2008,
abstract = {The nucleus accumbens regulates goal-directed behaviors by integrating information from limbic structures and the prefrontal cortex. Here, we review recent studies in an attempt to provide an integrated view of the control of information processing in the nucleus accumbens in terms of the regulation of goal-directed behaviors and how disruption of these functions might underlie the pathological states in drug addiction and other psychiatric disorders. We propose a model that could account for the results of several studies investigating limbic-system interactions in the nucleus accumbens and their modulation by dopamine and provide testable hypotheses for how these might relate to the pathophysiology of major psychiatric disorders.},
author = {Goto, Yukiori and Grace, Anthony A.},
doi = {10.1016/j.tins.2008.08.002},
issn = {01662236},
journal = {Trends in Neurosciences},
month = {nov},
number = {11},
pages = {552--558},
pmid = {18786735},
title = {{Limbic and cortical information processing in the nucleus accumbens}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18786735 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2884964 http://linkinghub.elsevier.com/retrieve/pii/S0166223608001884},
volume = {31},
year = {2008}
}
@article{Maia2009,
author = {Maia, Tiago V.},
doi = {10.3758/CABN.9.4.343},
issn = {1530-7026},
journal = {Cognitive, Affective, {\&} Behavioral Neuroscience},
month = {dec},
number = {4},
pages = {343--364},
publisher = {Springer-Verlag},
title = {{Reinforcement learning, conditioning, and the brain: Successes and challenges}},
url = {http://www.springerlink.com/index/10.3758/CABN.9.4.343},
volume = {9},
year = {2009}
}
@book{hearst1974sign,
author = {Hearst, Eliot and Jenkins, Herbert M},
publisher = {Psychonomic Society},
title = {{Sign-tracking: The stimulus-reinforcer relation and directed action}},
year = {1974}
}
@article{Flagel2011,
author = {Flagel, Shelly B. and Clark, Jeremy J. and Robinson, Terry E. and Mayo, Leah and Czuj, Alayna and Willuhn, Ingo and Akers, Christina A. and Clinton, Sarah M. and Phillips, Paul E. M. and Akil, Huda},
doi = {10.1038/nature09588},
issn = {0028-0836},
journal = {Nature},
month = {jan},
number = {7328},
pages = {53--57},
publisher = {Nature Research},
title = {{A selective role for dopamine in stimulus–reward learning}},
url = {http://www.nature.com/doifinder/10.1038/nature09588},
volume = {469},
year = {2011}
}
@misc{VanDerMeer2010,
abstract = {BACKGROUND: Decisions can arise in different ways, such as a gut feeling, doing what worked last time, or planful deliberation. Different decision-making systems are dissociable behaviorally, map onto distinct brain systems, and require different computational demands. For instance, �model-free� decision strategies use prediction errors to estimate scalar action values from previous experience, while �model-based� strategies leverage internal forward models to generate and evaluate potentially rich outcome expectancies. Animal learning studies indicate that expectancies may arise from different sources, including not only forward models but also Pavlovian associations, and the flexibility with which such representations impact behavior may depend on how they are generated. In the light of these considerations, we review the results of van der Meer and Redish (2009a), who found that ventral striatal neurons that respond to reward delivery can also be activated at other points, notably at a decision point where hippocampal forward representations were also observed. These data suggest the possibility that ventral striatal reward representations contribute to model-based expectancies used in deliberative decision-making.},
author = {van der Meer, Matthijs A A and Redish, A David},
booktitle = {Frontiers in Neuroscience},
isbn = {1662-453X},
title = {{Expectancies in decision making, reinforcement learning, and ventral striatum}},
url = {http://www.frontiersin.org/Journal/Abstract.aspx?f=55{\&}name=neuroscience{\&}ART{\_}DOI=10.3389/neuro.01.006.2010},
volume = {3},
year = {2010}
}
@article{Sutton1998,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
author = {Sutton, R S and Barto, A G},
doi = {10.1109/TNN.1998.712192},
isbn = {0262193981},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
pages = {1054},
pmid = {18255791},
title = {{Reinforcement learning: an introduction.}},
volume = {9},
year = {1998}
}
@article{Averbeck2017,
abstract = {Reinforcement learning (RL) is the behavioral process of learning to associate rewards with actions or objects. Conceptual and theoretical accounts of RL have focused on the striatum. However, recent data shows that the amygdala also plays an important role in RL.},
author = {Averbeck, Bruno B and Costa, Vincent D},
doi = {10.1038/nn.4506},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Motivation,Reward},
month = {apr},
number = {4},
pages = {505--512},
publisher = {Nature Publishing Group},
title = {{Motivational neural circuits underlying reinforcement learning}},
url = {http://www.nature.com/articles/nn.4506},
volume = {20},
year = {2017}
}
@article{Schultz1997a,
author = {Schultz, W. and Dayan, P. and Montague, P. R.},
doi = {10.1126/science.275.5306.1593},
issn = {0036-8075},
journal = {Science},
month = {mar},
number = {5306},
pages = {1593--1599},
title = {{A Neural Substrate of Prediction and Reward}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.275.5306.1593},
volume = {275},
year = {1997}
}
@article{Niv2007,
abstract = {RATIONALE Dopamine neurotransmission has long been known to exert a powerful influence over the vigor, strength, or rate of responding. However, there exists no clear understanding of the computational foundation for this effect; predominant accounts of dopamine's computational function focus on a role for phasic dopamine in controlling the discrete selection between different actions and have nothing to say about response vigor or indeed the free-operant tasks in which it is typically measured. OBJECTIVES We seek to accommodate free-operant behavioral tasks within the realm of models of optimal control and thereby capture how dopaminergic and motivational manipulations affect response vigor. METHODS We construct an average reward reinforcement learning model in which subjects choose both which action to perform and also the latency with which to perform it. Optimal control balances the costs of acting quickly against the benefits of getting reward earlier and thereby chooses a best response latency. RESULTS In this framework, the long-run average rate of reward plays a key role as an opportunity cost and mediates motivational influences on rates and vigor of responding. We review evidence suggesting that the average reward rate is reported by tonic levels of dopamine putatively in the nucleus accumbens. CONCLUSIONS Our extension of reinforcement learning models to free-operant tasks unites psychologically and computationally inspired ideas about the role of tonic dopamine in striatum, explaining from a normative point of view why higher levels of dopamine might be associated with more vigorous responding.},
author = {Niv, Yael and Daw, Nathaniel D. and Joel, Daphna and Dayan, Peter},
doi = {10.1007/s00213-006-0502-4},
issn = {0033-3158},
journal = {Psychopharmacology},
month = {mar},
number = {3},
pages = {507--520},
pmid = {17031711},
title = {{Tonic dopamine: opportunity costs and the control of response vigor}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17031711 http://link.springer.com/10.1007/s00213-006-0502-4},
volume = {191},
year = {2007}
}
@article{Estes1943,
author = {Estes, W. K.},
doi = {10.1037/h0058316},
issn = {0022-1015},
journal = {Journal of Experimental Psychology},
number = {2},
pages = {150--155},
title = {{Discriminative conditioning. I. A discriminative property of conditioned anticipation.}},
url = {http://content.apa.org/journals/xge/32/2/150},
volume = {32},
year = {1943}
}
@article{Lee2012,
abstract = {Reinforcement learning is an adaptive process in which an animal uti-lizes its previous experience to improve the outcomes of future choices. Computational theories of reinforcement learning play a central role in the newly emerging areas of neuroeconomics and decision neuro-science. In this framework, actions are chosen according to their value functions, which describe how much future reward is expected from each action. Value functions can be adjusted not only through reward and penalty, but also by the animal's knowledge of its current environment. Studies have revealed that a large proportion of the brain is involved in representing and updating value functions and using them to choose an action. However, how the nature of a behavioral task affects the neural mechanisms of reinforcement learning remains incompletely under-stood. Future studies should uncover the principles by which different computational elements of reinforcement learning are dynamically co-ordinated across the entire brain.},
author = {Lee, Daeyeol and Seo, Hyojung and Jung, Min Whan},
doi = {10.1146/annurev-neuro-062111-150512},
journal = {Annu. Rev. Neurosci},
keywords = {neuroeconomics,prefrontal cortex,reward,striatum,uncertainty},
pages = {287--308},
title = {{Neural Basis of Reinforcement Learning and Decision Making}},
url = {http://www.annualreviews.org/doi/pdf/10.1146/annurev-neuro-062111-150512},
volume = {35},
year = {2012}
}
@article{Yang1984,
abstract = {Extracellular single unit recordings were obtained from neurones in the nucleus accumbens of urethane anaesthetized rats. Single pulse stimulation (300-800 microA, 0.15 ms, 0.5-1.5 Hz) of the ventral subiculum of the hippocampus strongly excited silent and spontaneously active (3-6 spikes/s) medial accumbens neurones. The majority of neurones excited by hippocampal stimulation were quiescent and identified only by the elicited action potentials. Neurones on the dorso-medial border of the nucleus accumbens and adjacent lateral septum, with a faster spontaneous discharge rate (8-12 spikes/s), were inhibited by hippocampal stimulation. In the ventral border of the accumbens and the olfactory tubercle, hippocampal stimulation also inhibited the fast-firing (greater than 20 spikes/s) neurones. When trains of 10 conditioning pulses (300-800 microA, 0.15 ms, 10 Hz) were delivered to the ventral tegmental area (VTA) 100 ms before each single-pulse stimulation of the hippocampus, the excitatory responses of the silent and spontaneously active accumbens neurones were attenuated. The possibility of this relatively prolonged attenuation effect being dopamine-mediated was supported by several lines of evidence. Dopamine, applied iontophoretically, reduced markedly the excitatory response of accumbens neurones to hippocampal stimulation. Iontophoretically applied dopamine mimicked the attenuating effect produced by VTA conditioning stimulation in the same neurone. The attenuating effects of VTA conditioning stimulation on the activation of accumbens neurones by hippocampal stimulation was reduced by: (1) administration of 6-hydroxydopamine to the VTA 2 days and 7-9 days prior to the recording session, (2) the intraperitoneal injection of haloperidol 1 h before the recording session, and (3) the iontophoretic application of trifluoperazine to accumbens neurones. These observations support the hypothesis that the attenuating effects of the mesolimbic dopamine system on limbic inputs to the nucleus accumbens may have a role in limbic-motor integration.},
author = {Yang, C R and Mogenson, G J and Witter, MP. and Humby, T. and Hall, FS. and Robbins, TW. and Brewer, WJ. and Nelson, HE. and Robbins, TW. and Barnes, TR.},
doi = {10.1016/0006-8993(84)90623-1},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 1984 - Electrophysiological responses of neurones in the nucleus accumbens to hippocampal stimulation and the attenuation.pdf:pdf},
issn = {0006-8993},
journal = {Brain research},
month = {dec},
number = {1},
pages = {69--84},
pmid = {6151418},
publisher = {Society for Neuroscience},
title = {{Electrophysiological responses of neurones in the nucleus accumbens to hippocampal stimulation and the attenuation of the excitatory responses by the mesolimbic dopaminergic system.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6151418},
volume = {324},
year = {1984}
}
@article{Costa2016,
author = {Costa, Vincent D. and {Dal Monte}, Olga and Lucas, Daniel R. and Murray, Elisabeth A. and Averbeck, Bruno B.},
doi = {10.1016/j.neuron.2016.09.025},
issn = {08966273},
journal = {Neuron},
month = {oct},
number = {2},
pages = {505--517},
title = {{Amygdala and Ventral Striatum Make Distinct Contributions to Reinforcement Learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627316305840},
volume = {92},
year = {2016}
}
@article{Aitken2016,
author = {Aitken, Tara J. and Greenfield, Venuz Y. and Wassum, Kate M.},
doi = {10.1111/jnc.13494},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aitken, Greenfield, Wassum - 2016 - Nucleus accumbens core dopamine signaling tracks the need-based motivational value of food-paired cu.pdf:pdf},
issn = {00223042},
journal = {Journal of Neurochemistry},
keywords = {Pavlovian‐to‐instrumental transfer,hunger,mesolimbic dopamine,reward,satiety,voltammetry},
month = {mar},
number = {5},
pages = {1026--1036},
title = {{Nucleus accumbens core dopamine signaling tracks the need-based motivational value of food-paired cues}},
url = {http://doi.wiley.com/10.1111/jnc.13494},
volume = {136},
year = {2016}
}
@article{Berridge2012,
abstract = {Reward contains separable psychological components of learning, incentive motivation and pleasure. Most computational models have focused only on the learning component of reward, but the motivational component is equally important in reward circuitry, and even more directly controls behavior. Modeling the motivational component requires recognition of additional control factors besides learning. Here I discuss how mesocorticolimbic mechanisms generate the motivation component of incentive salience. Incentive salience takes Pavlovian learning and memory as one input and as an equally important input takes neurobiological state factors (e.g. drug states, appetite states, satiety states) that can vary independently of learning. Neurobiological state changes can produce unlearned fluctuations or even reversals in the ability of a previously learned reward cue to trigger motivation. Such fluctuations in cue-triggered motivation can dramatically depart from all previously learned values about the associated reward outcome. Thus, one consequence of the difference between incentive salience and learning can be to decouple cue-triggered motivation of the moment from previously learned values of how good the associated reward has been in the past. Another consequence can be to produce irrationally strong motivation urges that are not justified by any memories of previous reward values (and without distorting associative predictions of future reward value). Such irrationally strong motivation may be especially problematic in addiction. To understand these phenomena, future models of mesocorticolimbic reward function should address the neurobiological state factors that participate to control generation of incentive salience.},
author = {Berridge, Kent C},
doi = {10.1111/j.1460-9568.2012.07990.x},
issn = {1460-9568},
journal = {The European journal of neuroscience},
month = {apr},
number = {7},
pages = {1124--43},
pmid = {22487042},
publisher = {NIH Public Access},
title = {{From prediction error to incentive salience: mesolimbic computation of reward motivation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22487042 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3325516},
volume = {35},
year = {2012}
}
@article{Ambroggi2008,
abstract = {Both the nucleus accumbens (NAc) and basolateral amygdala (BLA) contribute to learned behavioral choice. Neurons in both structures that encode reward-predictive cues may underlie the decision to respond to such cues, but the neural circuits by which the BLA influences reward-seeking behavior have not been established. Here, we test the hypothesis that the BLA drives NAc neuronal responses to reward-predictive cues. First, using a disconnection experiment, we show that the BLA and dopamine projections to the NAc interact to promote the reward-seeking behavioral response. Next, we demonstrate that BLA neuronal responses to cues precede those of NAc neurons and that cue-evoked excitation of NAc neurons depends on BLA input. These results indicate that BLA input is required for dopamine to enhance the cue-evoked firing of NAc neurons and that this enhanced firing promotes reward-seeking behavior.},
author = {Ambroggi, Frederic and Ishikawa, Akinori and Fields, Howard L. and Nicola, Saleem M.},
doi = {10.1016/j.neuron.2008.07.004},
issn = {08966273},
journal = {Neuron},
month = {aug},
number = {4},
pages = {648--661},
pmid = {18760700},
title = {{Basolateral Amygdala Neurons Facilitate Reward-Seeking Behavior by Exciting Nucleus Accumbens Neurons}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18760700 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2603341 http://linkinghub.elsevier.com/retrieve/pii/S0896627308005734},
volume = {59},
year = {2008}
}
@article{Hamid2015,
author = {Hamid, Arif A and Pettibone, Jeffrey R and Mabrouk, Omar S and Hetrick, Vaughn L and Schmidt, Robert and {Vander Weele}, Caitlin M and Kennedy, Robert T and Aragona, Brandon J and Berke, Joshua D},
doi = {10.1038/nn.4173},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {nov},
number = {1},
pages = {117--126},
publisher = {Nature Research},
title = {{Mesolimbic dopamine signals the value of work}},
url = {http://www.nature.com/doifinder/10.1038/nn.4173},
volume = {19},
year = {2015}
}
@article{Schultz2016,
abstract = {Phasic signalling by midbrain dopamine neurons is thought to contribute to reward processing by encoding a reward prediction error. Schultz describes recent work suggesting that there are two distinct components of the phasic dopamine response and considers the probable functional role of each response component.},
author = {Schultz, Wolfram},
doi = {10.1038/nrn.2015.26},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Learning algorithms,Motivation,Reward},
month = {feb},
number = {3},
pages = {183--195},
publisher = {Nature Publishing Group},
title = {{Dopamine reward prediction-error signalling: a two-component response}},
url = {http://www.nature.com/doifinder/10.1038/nrn.2015.26},
volume = {17},
year = {2016}
}
@article{Kalivas2005,
abstract = {OBJECTIVE: A primary behavioral pathology in drug addiction is the overpowering motivational strength and decreased ability to control the desire to obtain drugs. In this review the authors explore how advances in neurobiology are approaching an understanding of the cellular and circuitry underpinnings of addiction, and they describe the novel pharmacotherapeutic targets emerging from this understanding. METHOD: Findings from neuroimaging of addicts are integrated with cellular studies in animal models of drug seeking. RESULTS: While dopamine is critical for acute reward and initiation of addiction, end-stage addiction results primarily from cellular adaptations in anterior cingulate and orbitofrontal glutamatergic projections to the nucleus accumbens. Pathophysiological plasticity in excitatory transmission reduces the capacity of the prefrontal cortex to initiate behaviors in response to biological rewards and to provide executive control over drug seeking. Simultaneously, the prefrontal cortex is hyper...},
author = {Kalivas, Peter W. and Volkow, Nora D.},
doi = {10.1176/appi.ajp.162.8.1403},
issn = {0002-953X},
journal = {American Journal of Psychiatry},
month = {aug},
number = {8},
pages = {1403--1413},
publisher = {American Psychiatric Publishing},
title = {{The Neural Basis of Addiction: A Pathology of Motivation and Choice}},
url = {http://psychiatryonline.org/doi/abs/10.1176/appi.ajp.162.8.1403},
volume = {162},
year = {2005}
}
@article{Weiner1996,
abstract = {Latent inhibition (LI) consists of retardation in conditioning to a stimulus as a consequence of its prior non-reinforced pre-exposure. In view of findings that LI is disrupted in acute schizophrenic patients and evidence from animal experiments pointing to the involvement of the mesolimbic dopamine (DA) system in this phenomenon, the present study investigated the effects of electrolytic lesions to the shell and core subterritories of the nucleus accumbens on LI in rats (Expt. 1). LI was indexed by the amount of suppression of drinking in the presence of a tone that was either pre-exposed or not prior to its pairing with reinforcement (a foot shock). Expt.2 tested the effects of the DA antagonist, haloperidol, on LI in shell- and core-lesioned animals. Expt. 3 tested the effects of shell and core lesions on spontaneous and amphetamine-induced locomotion. In Expt. 1, LI, i.e., lower suppression of drinking in the pre-exposed as compared to the non-pre-exposed animals, was obtained in the sham-operated condition. Core and shell lesions produced distinct effects on LI. Animals with core lesions developed LI, but exhibited an overall lower suppression of drinking in comparison to the sham-operated animals. In contrast, shell lesions led to a disappearance of LI. Expt. 2 replicated the differential effects of shell and core lesions on LI, although in this experiment, core lesion did not attenuate suppression of drinking. Haloperidol prevented shell-induced abolition of LI. In Expt. 3, shell- but not core-lesioned animals were more active than sham controls following amphetamine administration. These results provide evidence for functional differences between the shell and core subregions, as well as for the involvement of the mesolimbic DA system in LI.},
author = {Weiner, I and Gal, G and Rawlins, J N and Feldon, J},
doi = {10.1016/S0166-4328(96)00051-4},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weiner et al. - 1996 - Differential involvement of the shell and core subterritories of the nucleus accumbens in latent inhibition and a.pdf:pdf},
issn = {0166-4328},
journal = {Behavioural brain research},
month = {nov},
number = {1-2},
pages = {123--33},
pmid = {8950008},
publisher = {Society for Neuroscience},
title = {{Differential involvement of the shell and core subterritories of the nucleus accumbens in latent inhibition and amphetamine-induced activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8950008},
volume = {81},
year = {1996}
}
@article{Strait2015,
abstract = {The ventral striatum (VS), like its cortical afferents, is closely associated with processing of rewards, but the relative contributions of striatal and cortical reward systems remains unclear. Most theories posit distinct roles for these structures, despite their similarities. We compared responses of VS neurons to those of ventromedial prefrontal cortex (vmPFC) Area 14 neurons, recorded in a risky choice task. Five major response patterns observed in vmPFC were also observed in VS: (1) offer value encoding, (2) value difference encoding, (3) preferential encoding of chosen relative to unchosen value, (4) a correlation between residual variance in responses and choices, and (5) prominent encoding of outcomes. We did observe some differences as well; in particular, preferential encoding of the chosen option was stronger and started earlier in VS than in vmPFC. Nonetheless, the close match between vmPFC and VS suggests that cortex and its striatal targets make overlapping contributions to economic choice.},
author = {Strait, Caleb E and Sleezer, Brianna J and Hayden, Benjamin Y},
doi = {10.1371/journal.pbio.1002173},
issn = {1545-7885},
journal = {PLoS biology},
month = {jun},
number = {6},
pages = {e1002173},
pmid = {26086735},
publisher = {Public Library of Science},
title = {{Signatures of Value Comparison in Ventral Striatum Neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26086735 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4472856},
volume = {13},
year = {2015}
}
@article{Schultz1997,
abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
author = {Schultz, W and Dayan, P and Montague, P R},
doi = {10.1126/SCIENCE.275.5306.1593},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
month = {mar},
number = {5306},
pages = {1593--9},
pmid = {9054347},
publisher = {American Association for the Advancement of Science},
title = {{A neural substrate of prediction and reward.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9054347},
volume = {275},
year = {1997}
}
@article{Corbit2011,
abstract = {Tests of Pavlovian-instrumental transfer (PIT) demonstrate that reward-predictive stimuli can exert a powerful motivational influence on the performance of instrumental actions. Recent evidence suggests that predictive stimuli produce this effect through either the general arousal (general PIT) or the specific predictions (outcome-specific PIT) produced by their association with reward. In two experiments, we examined the effects of pretraining lesions (Experiment 1) or muscimol-induced inactivation (Experiment 2) of either the core or shell regions of the nucleus accumbens (NAC) on these forms of PIT. Rats received Pavlovian training in which three auditory stimuli each predicted the delivery of a distinct food outcome. Separately, the rats were trained to perform two instrumental actions, each of which earned one of the outcomes used in Pavlovian conditioning. Finally, the effects of the three stimuli on performance of the two actions were assessed in extinction. Here we report evidence of a double dissociation between general and outcome-specific PIT at the level of the accumbens. Shell lesions eliminated outcome-specific PIT but spared general PIT, whereas lesions of the core abolished general PIT but spared outcome-specific PIT. Importantly, the infusion of muscimol into core or shell made immediately before the PIT tests produced a similar pattern of results. These results suggest that whereas the NAC core mediates the general excitatory effects of reward-related cues, the NAC shell mediates the effect of outcome-specific reward predictions on instrumental performance, and thereby serve to clarify reported discrepancies regarding the role of the NAC core and shell in PIT.},
author = {Corbit, L. H. and Balleine, B. W.},
doi = {10.1523/JNEUROSCI.2711-11.2011},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {aug},
number = {33},
pages = {11786--11794},
pmid = {21849539},
title = {{The General and Outcome-Specific Forms of Pavlovian-Instrumental Transfer Are Differentially Mediated by the Nucleus Accumbens Core and Shell}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21849539 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3208020 http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2711-11.2011},
volume = {31},
year = {2011}
}
@article{Khamassi2012,
abstract = {Behavior in spatial navigation is often organized into map-based (place-driven) vs. map-free (cue-driven) strategies; behavior in operant conditioning research is often organized into goal-directed vs. habitual strategies. Here we attempt to unify the two. We review one powerful theory for distinct forms of learning during instrumental conditioning, namely model-based (maintaining a representation of the world) and model-free (reacting to immediate stimuli) learning algorithms. We extend these lines of argument to propose an alternative taxonomy for spatial navigation, showing how various previously identified strategies can be distinguished as "model-based" or "model-free" depending on the usage of information and not on the type of information (e.g., cue vs. place). We argue that identifying "model-free" learning with dorsolateral striatum and "model-based" learning with dorsomedial striatum could reconcile numerous conflicting results in the spatial navigation literature. From this perspective, we further propose that the ventral striatum plays key roles in the model-building process. We propose that the core of the ventral striatum is positioned to learn the probability of action selection for every transition between states of the world. We further review suggestions that the ventral striatal core and shell are positioned to act as "critics" contributing to the computation of a reward prediction error for model-free and model-based systems, respectively.},
author = {Khamassi, Mehdi and Humphries, Mark D},
doi = {10.3389/fnbeh.2012.00079},
issn = {1662-5153},
journal = {Frontiers in behavioral neuroscience},
keywords = {action-outcome,habit,nucleus accumbens,reinforcement learning,stimulus-response},
pages = {79},
pmid = {23205006},
publisher = {Frontiers Media SA},
title = {{Integrating cortico-limbic-basal ganglia architectures for learning model-based and model-free navigation strategies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23205006 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3506961},
volume = {6},
year = {2012}
}
@article{Bornstein2011b,
abstract = {The basal ganglia, in particular the striatum, are central to theories of behavioral control, and often identified as a seat of action selection. Reinforcement learning (RL) models. - which have driven much recent experimental work on this region. - cast striatum as a dynamic controller, integrating sensory and motivational information to construct efficient and enriching behavioral policies. Befitting this informationally central role, the BG sit at the nexus of multiple anatomical 'loops' of synaptic projections, connecting a wide range of cortical and subcortical structures. Numerous pioneering anatomical studies conducted over the past several decades have meticulously catalogued these loops, and labeled them according to the inferred functions of the connected regions. The specific cotermina of the projections are highly localized to several different subregions of the striatum, leading to the suggestion that these subregions perform complementary but distinct functions. However, until recently, the dominant computational framework outlined only a bipartite, dorsal/ventral, division of striatum. We review recent computational and experimental advances that argue for a more finely fractionated delineation. In particular, experimental data provide extensive insight into unique functions subserved by the dorsomedial striatum (DMS). These functions appear to correspond well with theories of a 'model-based' RL subunit, and may also shed light on the suborganization of ventral striatum. Finally, we discuss the limitations of these ideas and how they point the way toward future refinements of neurocomputational theories of striatal function, bringing them into contact with other areas of computational theory and other regions of the brain. {\textcopyright} 2011 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Bornstein, Aaron M. and Daw, Nathaniel D.},
doi = {10.1016/j.conb.2011.02.009},
eprint = {NIHMS150003},
isbn = {1873-6882 (Electronic)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {jun},
number = {3},
pages = {374--380},
pmid = {21429734},
title = {{Multiplicity of control in the basal ganglia: Computational roles of striatal subregions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438811000365},
volume = {21},
year = {2011}
}
@article{Robinson2009,
abstract = {BACKGROUND If presentation of a stimulus (conditional stimulus, CS) reliably predicts delivery of a reward, the CS will come to evoke a conditional response (CR) through Pavlovian learning, and the CS may also acquire incentive motivational properties. Thus, CSs can have both predictive and incentive properties. We ask here whether it is possible to dissociate the predictive versus incentive properties of a CS in rats by considering individual differences in the nature of the CR. METHODS We used Pavlovian procedures to study the ability of a localizable CS (an illuminated lever) to acquire two properties of an incentive stimulus-the ability to attract and the ability to act as a conditional reinforcer. RESULTS For some rats, the CS evoked a "sign-tracking" CR, consisting of approach toward and engagement with the CS itself. For other rats, the CS instead produced a "goal-tracking" CR: approach was directed away from the CS toward the site of food delivery. For sign-trackers (but not goal-trackers) the CS also acted as an effective conditional reinforcer. CONCLUSIONS The predictive and incentive properties of a CS can be dissociated by considering individual differences in the CR. In a given animal, a cue that is predictive of reward, supporting Pavlovian learning, may or may not be attributed with incentive salience. This procedure may provide a powerful means to test hypotheses regarding the role of neural systems in learning versus incentive motivational functions and to study individual variation in the extent to which reward-associated stimuli act as incentive stimuli.},
author = {Robinson, Terry E. and Flagel, Shelly B.},
doi = {10.1016/j.biopsych.2008.09.006},
issn = {00063223},
journal = {Biological Psychiatry},
month = {may},
number = {10},
pages = {869--873},
pmid = {18930184},
title = {{Dissociating the Predictive and Incentive Motivational Properties of Reward-Related Cues Through the Study of Individual Differences}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18930184 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2737368 http://linkinghub.elsevier.com/retrieve/pii/S0006322308010949},
volume = {65},
year = {2009}
}
@article{Berridge2007,
author = {Berridge, Kent C.},
doi = {10.1007/s00213-006-0578-x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berridge - 2007 - The debate over dopamine's role in reward the case for incentive salience.pdf:pdf},
issn = {0033-3158},
journal = {Psychopharmacology},
month = {mar},
number = {3},
pages = {391--431},
publisher = {Springer-Verlag},
title = {{The debate over dopamine's role in reward: the case for incentive salience}},
url = {http://link.springer.com/10.1007/s00213-006-0578-x},
volume = {191},
year = {2007}
}
@article{Aggarwal2012a,
abstract = {In the past few decades there has been remarkable convergence of machine learning with neurobiological understanding of reinforcement learning mechanisms, exemplified by temporal difference (TD) learning models. The anatomy of the basal ganglia provides a number of potential substrates for instantiation of the TD mechanism. In contrast to the traditional concept of direct and indirect pathway outputs from the striatum, we emphasize that projection neurons of the striatum are branched and individual striatofugal neurons innervate both globus pallidus externa and globus pallidus interna/substantia nigra (GPi/SNr). This suggests that the GPi/SNr has the necessary inputs to operate as the source of a TD signal. We also discuss the mechanism for the timing processes necessary for learning in the TD framework. The TD framework has been particularly successful in analysing electrophysiogical recordings from dopamine (DA) neurons during learning, in terms of reward prediction error. However, present understanding of the neural control of DA release is limited, and hence the neural mechanisms involved are incompletely understood. Inhibition is very conspicuously present among the inputs to the DA neurons, with inhibitory synapses accounting for the majority of synapses on DA neurons. Furthermore, synchronous firing of the DA neuron population requires disinhibition and excitation to occur together in a coordinated manner. We conclude that the inhibitory circuits impinging directly or indirectly on the DA neurons play a central role in the control of DA neuron activity and further investigation of these circuits may provide important insight into the biological mechanisms of reinforcement learning.},
author = {Aggarwal, Mayank and Hyland, Brian I and Wickens, Jeffery R},
doi = {10.1111/j.1460-9568.2012.08055.x},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal, Hyland, Wickens - Unknown - Neural control of dopamine neurotransmission implications for reinforcement learning.pdf:pdf},
isbn = {1460-9568},
issn = {0953816X},
journal = {European Journal of Neuroscience},
keywords = {Basal ganglia,GABA,Striatum,Temporal difference},
number = {7},
pages = {1115--1123},
pmid = {22487041},
title = {{Neural control of dopamine neurotransmission: Implications for reinforcement learning}},
url = {https://s3.amazonaws.com/objects.readcube.com/articles/downloaded/wiley/f1b7d51b5e40ce16bb3a504630a2333c8920fdfbbb477143fd37672b602018d2.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256{\&}X-Amz-Credential=AKIAIS5LBPCM5JPOCDGQ{\%}2F20170321{\%}2Fus-east-1{\%}2Fs3{\%}2Faws4{\_}request{\&}},
volume = {35},
year = {2012}
}
@article{Chang2013,
abstract = {Certain Pavlovian conditioned stimuli (CSs) paired with food unconditioned stimuli (USs) come to elicit approach and even consumption-like behaviors in rats (sign-tracking). We investigated the effects of lesions of the nucleus accumbens core (ACbC) or shell (ACbS) on the acquisition of sign-tracking in a discriminative autoshaping procedure in which presentation of one lever CS was followed by delivery of sucrose, and another was not. Although we previously found that bilateral lesions of the whole ACb disrupted the initial acquisition of sign-tracking, neither ACbC or ACbS lesions affected the rate or percentage of trials in which rats pressed the CS+. In addition, detailed video analysis showed no effect of either lesion on the topography of the sign-tracking conditioned response (CR). These and other results from lesion studies of autoshaping contrast with those from previous sign-tracking experiments that used purely visual cues (Parkinson et al., 2000a,b), suggesting that the neural circuitry involved in assigning incentive value depends upon the nature of the CS.},
author = {Chang, Stephen E. and Holland, Peter C.},
doi = {10.1016/j.bbr.2013.07.046},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {ACbC,ACbS,Autoshaping,BLA,CR,CS,CeA,DA,Incentive salience,Nucleus accumbens core,Nucleus accumbens shell,US,VTA,amygdala central nucleus,basolateral amygdala,conditioned response,conditioned stimulus,dopamine,nucleus accumbens core,nucleus accumbens shell,unconditioned stimulus,ventral tegmental area},
month = {nov},
pages = {36--42},
pmid = {23933141},
title = {{Effects of nucleus accumbens core and shell lesions on autoshaped lever-pressing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23933141 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3815957 http://linkinghub.elsevier.com/retrieve/pii/S0166432813004580},
volume = {256},
year = {2013}
}
@article{Zaehle2013,
abstract = {Theoretical models and empirical work indicate a critical role of the NAcc in salience processing. For instance, the NAcc not only responds to appetitive and aversive information, but it also signals novelty, contextual deviance, and action monitoring. However, because most studies have investigated only one specific type of salience independently, it remains unclear how the NAcc concurrently differentiates between different forms of salience. To investigate this issue, we used intracranial electroencephalography in human epilepsy patients together with a previously established visual oddball paradigm. Here, three different oddball categories (novel, neutral, and target images) were infrequently presented among a standard scene image, and subjects responded to the target via button press. This task allowed us to differentiate "item novelty" (new vs neutral oddballs) from "contextual deviance" (neutral oddballs vs standard images) and "targetness" (target vs neutral oddballs). Time-frequency analysis revealed a dissociation between item novelty and contextual deviance on the basis of decreases in either $\theta$ (4-8 Hz) or $\beta$ power (20-30 Hz). Targetness, on the other hand, was signaled by positive deflections in the stimulus-locked local field potentials, which, importantly, correlated with subjects' reaction times. These findings indicate that, in an ongoing stream of information, the NAcc differentiates between types of salience by distinct neural mechanisms to guide goal-directed behavior.},
author = {Zaehle, Tino and Bauch, Eva M and Hinrichs, Hermann and Schmitt, Friedhelm C and Voges, J{\"{u}}rgen and Heinze, Hans-Jochen and Bunzeck, Nico and Lenartz, D. and Sturm, V. and Ranganath, C.},
doi = {10.1523/JNEUROSCI.5276-12.2013},
file = {:C$\backslash$:/Users/mvdmlab/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaehle et al. - 2013 - Nucleus accumbens activity dissociates different forms of salience evidence from human intracranial recordings.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {may},
number = {20},
pages = {8764--71},
pmid = {23678119},
publisher = {Society for Neuroscience},
title = {{Nucleus accumbens activity dissociates different forms of salience: evidence from human intracranial recordings.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23678119},
volume = {33},
year = {2013}
}
@article{VanderMeer2010,
author = {van der Meer, Matthijs A.A. and Johnson, Adam and Schmitzer-Torbert, Neil C. and Redish, A. David},
doi = {10.1016/j.neuron.2010.06.023},
issn = {08966273},
journal = {Neuron},
month = {jul},
number = {1},
pages = {25--32},
title = {{Triple Dissociation of Information Processing in Dorsal Striatum, Ventral Striatum, and Hippocampus on a Learned Spatial Decision Task}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627310005076},
volume = {67},
year = {2010}
}
